#!/usr/bin/env python3
"""
Test DEBUG COMPLET - Configuration GPU avec CUDA_VISIBLE_DEVICES='1'
Objectif: D√©terminer si utiliser cuda:0 ou cuda:1 avec CUDA_VISIBLE_DEVICES='1'
"""

import os
import torch

print("üîç TEST DEBUG CONFIGURATION GPU")
print("="*60)

# Test 1: Sans CUDA_VISIBLE_DEVICES
print("\n1Ô∏è‚É£ TEST SANS CUDA_VISIBLE_DEVICES:")
if 'CUDA_VISIBLE_DEVICES' in os.environ:
    del os.environ['CUDA_VISIBLE_DEVICES']

import importlib
importlib.reload(torch.cuda)

if torch.cuda.is_available():
    device_count = torch.cuda.device_count()
    print(f"   Devices disponibles: {device_count}")
    for i in range(device_count):
        gpu_name = torch.cuda.get_device_name(i)
        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
        print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")

# Test 2: Avec CUDA_VISIBLE_DEVICES='1'
print("\n2Ô∏è‚É£ TEST AVEC CUDA_VISIBLE_DEVICES='1':")
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
importlib.reload(torch.cuda)

if torch.cuda.is_available():
    device_count = torch.cuda.device_count()
    print(f"   Devices visibles: {device_count}")
    for i in range(device_count):
        gpu_name = torch.cuda.get_device_name(i)
        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
        print(f"   GPU visible {i}: {gpu_name} ({gpu_memory:.1f}GB)")
    
    # Test allocation sur device 0 visible
    try:
        x = torch.randn(1000, 1000).cuda(0)
        print(f"   ‚úÖ Allocation cuda:0 r√©ussie - GPU: {torch.cuda.get_device_name(0)}")
        del x
        torch.cuda.empty_cache()
    except Exception as e:
        print(f"   ‚ùå Allocation cuda:0 √©chou√©: {e}")
    
    # Test allocation sur device 1 (si disponible)
    if device_count > 1:
        try:
            x = torch.randn(1000, 1000).cuda(1)
            print(f"   ‚úÖ Allocation cuda:1 r√©ussie - GPU: {torch.cuda.get_device_name(1)}")
            del x
            torch.cuda.empty_cache()
        except Exception as e:
            print(f"   ‚ùå Allocation cuda:1 √©chou√©: {e}")
    else:
        try:
            x = torch.randn(1000, 1000).cuda(1)
            print(f"   ‚úÖ Allocation cuda:1 r√©ussie")
            del x
            torch.cuda.empty_cache()
        except Exception as e:
            print(f"   ‚ùå Allocation cuda:1 √©chou√©: {e}")

print("\n" + "="*60)
print("üéØ CONCLUSION:")
print("   - Device 0 visible = Quelle GPU physique ?")
print("   - cuda:1 fonctionne-t-il avec CUDA_VISIBLE_DEVICES='1' ?")
print("="*60) 