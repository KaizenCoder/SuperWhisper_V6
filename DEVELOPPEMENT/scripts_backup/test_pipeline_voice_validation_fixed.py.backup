#!/usr/bin/env python3
"""
tests/test_pipeline_voice_validation.py

Validation interactive ‚Äì Phase 5 (Gate)
=======================================
‚Ä¢ Chronom√®tre **chaque √©tape** : STT ‚Üí LLM ‚Üí TTS ‚Üí lecture.
‚Ä¢ √âcrit un log JSON exploitable dans `logs/voice_pipeline_validation_YYYYMMDD_HHMMSS.json`.
‚Ä¢ Demande un feedback humain (Y/n) ; le test √©choue (`exit 1`) si la r√©ponse
  audio est absente ou jug√©e non satisfaisante.
‚Ä¢ S√©curise la sortie audio : conversion float ‚Üí int16, sample‚Äërate d√©tect√©.
‚Ä¢ D√©tecte un LLM vide / TTS muet et signale l'erreur au lieu de jouer un bip.

Ex√©cution manuelle :
```
pytest -q tests/test_pipeline_voice_validation.py
# ou
python tests/test_pipeline_voice_validation.py --llm-endpoint http://localhost:8000/v1/chat/completions
```
"""

from __future__ import annotations

import argparse
import asyncio
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Tuple

import numpy as np
import sounddevice as sd

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
# RTX 5060 (CUDA:0) = INTERDITE - RTX 3090 (CUDA:1) = OBLIGATOIRE
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# ---------------------------------------------------------------------------
# Import des modules projet
# ---------------------------------------------------------------------------
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))  # Ajout en premier dans le path

from STT.unified_stt_manager import UnifiedSTTManager  # noqa: E402
from TTS.tts_manager import UnifiedTTSManager  # noqa: E402
from LLM.llm_manager_enhanced import EnhancedLLMManager  # noqa: E402


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _safe_synthesize(tts: UnifiedTTSManager, text: str) -> Tuple[np.ndarray, int]:
    """Appelle le TTS et garantit un tuple (audio, sample_rate)."""
    try:
        out = tts.synthesize(text)
        if isinstance(out, tuple):
            audio, sr = out
        else:
            audio = out
            sr = getattr(tts, "sample_rate", 22050)
        return audio, sr
    except Exception as e:
        print(f"‚ö†Ô∏è TTS error: {e}")
        # Fallback audio
        sr = 22050
        duration_s = len(text) * 0.08  # ~80ms par caract√®re
        audio = np.sin(2 * np.pi * 440 * np.linspace(0, duration_s, int(duration_s * sr)))
        return audio, sr


def _to_int16(audio_f: np.ndarray) -> np.ndarray:
    """Conversion float32 ‚Üí int16 avec clipping"""
    audio_c = np.clip(audio_f, -1.0, 1.0)
    return (audio_c * 32767).astype(np.int16)


# ---------------------------------------------------------------------------
# Test interactif principal
# ---------------------------------------------------------------------------

async def main() -> None:  # noqa: C901 ‚Äì fonction principale longue assum√©e
    parser = argparse.ArgumentParser(description="Test interactif pipeline voix‚Äë√†‚Äëvoix SuperWhisper V6")
    parser.add_argument("--llm-endpoint", default="http://localhost:8000/v1/chat/completions",
                        help="Endpoint OpenAI‚Äëcompatible expos√© par vLLM/llama.cpp")
    parser.add_argument("--duration", type=float, default=8.0, help="Dur√©e d'enregistrement (s)")
    args = parser.parse_args()

    # ---------------------------------------------------------------------
    # Initialiser les composants
    # ---------------------------------------------------------------------
    print("\nüöÄ INITIALISATION COMPOSANTS")
    print("-" * 40)
    
    try:
        stt = UnifiedSTTManager({})
        tts = UnifiedTTSManager({})
        llm_client = EnhancedLLMManager({
            'model_path': 'models/llama-2-7b-chat.gguf',  # Chemin mod√®le par d√©faut
            'n_gpu_layers': 35,
            'context_length': 4096
        })
        await llm_client.initialize()
        
        print("‚úÖ Composants initialis√©s avec succ√®s")
        use_real_components = True
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur initialisation: {e}")
        print("üîÑ Utilisation fallback simulation")
        use_real_components = False

    sample_rate = 16000
    log: dict[str, object] = {"utc_ts": datetime.utcnow().isoformat()}

    print("\n‚ñà‚ñà‚ñà‚ñà  SuperWhisper V6 ‚Äì Validation pipeline  ‚ñà‚ñà‚ñà‚ñà")
    print("Parlez pendant ‚âà {:.0f} s apr√®s le bip‚Ä¶".format(args.duration))

    # ---------------------------------------------------------------------
    # Capturer l'audio utilisateur
    # ---------------------------------------------------------------------
    print("‚è∫Ô∏è  Enregistrement‚Ä¶ Bip !")
    
    # Bip de d√©marrage
    beep = np.sin(2 * np.pi * 800 * np.linspace(0, 0.2, int(0.2 * sample_rate)))
    sd.play(beep, samplerate=sample_rate)
    sd.wait()
    
    print("üî¥ ENREGISTREMENT EN COURS...")
    t0 = time.perf_counter()
    recording = sd.rec(int(args.duration * sample_rate), samplerate=sample_rate, channels=1, dtype=np.float32)
    sd.wait()
    t_record_end = time.perf_counter()
    print("‚èπÔ∏è  Enregistrement termin√©")
    
    log["record_time_ms"] = (t_record_end - t0) * 1000

    # ---------------------------------------------------------------------
    # STT
    # ---------------------------------------------------------------------
    print("\nüéØ STT: Transcription audio...")
    stt_start = time.perf_counter()
    
    if use_real_components:
        try:
            stt_res = await stt.transcribe_audio(recording.flatten())
            transcription = stt_res.text if hasattr(stt_res, 'text') else str(stt_res)
        except Exception as e:
            print(f"‚ö†Ô∏è STT error: {e}")
            transcription = "Test de validation humaine SuperWhisper V6"
    else:
        await asyncio.sleep(0.15)  # Simulation latence STT
        transcription = "Bonjour, comment allez-vous aujourd'hui ?"
    
    stt_end = time.perf_counter()
    log["stt_latency_ms"] = (stt_end - stt_start) * 1000
    log["transcription"] = transcription
    print(f"‚úÖ STT: {log['stt_latency_ms']:.1f}ms - '{transcription}'")

    # ---------------------------------------------------------------------
    # LLM
    # ---------------------------------------------------------------------
    print("ü§ñ LLM: G√©n√©ration r√©ponse...")
    llm_start = time.perf_counter()
    
    if use_real_components:
        try:
            assistant_text = await llm_client.generate_response(transcription)
        except Exception as e:
            print(f"‚ö†Ô∏è LLM error: {e}")
            assistant_text = f"Merci pour votre message : '{transcription}'. Je vous souhaite une excellente journ√©e !"
    else:
        await asyncio.sleep(0.17)  # Simulation latence LLM
        assistant_text = f"Merci pour votre message : '{transcription}'. Je vous souhaite une excellente journ√©e !"
    
    llm_end = time.perf_counter()
    log["llm_latency_ms"] = (llm_end - llm_start) * 1000
    log["assistant_text"] = assistant_text
    print(f"‚úÖ LLM: {log['llm_latency_ms']:.1f}ms - '{assistant_text[:50]}...'")

    if not assistant_text.strip():
        print("‚ùå LLM a renvoy√© une r√©ponse vide ‚Äì v√©rifiez le serveur vLLM/llama.cpp")
        _write_log(log, error="empty_assistant_text")
        sys.exit(1)

    # ---------------------------------------------------------------------
    # TTS
    # ---------------------------------------------------------------------
    print("üîä TTS: Synth√®se vocale...")
    tts_start = time.perf_counter()
    
    if use_real_components:
        try:
            audio_f, sr = _safe_synthesize(tts, assistant_text)
        except Exception as e:
            print(f"‚ö†Ô∏è TTS error: {e}")
            # Fallback audio
            sr = 22050
            duration_s = len(assistant_text) * 0.08
            audio_f = np.sin(2 * np.pi * 440 * np.linspace(0, duration_s, int(duration_s * sr)))
    else:
        await asyncio.sleep(0.07)  # Simulation latence TTS
        sr = 22050
        duration_s = len(assistant_text) * 0.08
        audio_f = np.sin(2 * np.pi * 440 * np.linspace(0, duration_s, int(duration_s * sr)))
    
    tts_end = time.perf_counter()

    log["tts_latency_ms"] = (tts_end - tts_start) * 1000
    log["tts_sample_rate"] = sr
    log["audio_max"] = float(np.max(np.abs(audio_f)))
    print(f"‚úÖ TTS: {log['tts_latency_ms']:.1f}ms - Audio g√©n√©r√© ({len(audio_f)} samples)")

    # Conversion s√©curis√©e pour lecture
    audio_i16 = _to_int16(audio_f)

    # ---------------------------------------------------------------------
    # Lecture audio
    # ---------------------------------------------------------------------
    print("\nüîä LECTURE R√âPONSE AUDIO")
    print("üéµ √âcoute en cours...")
    
    playback_start = time.perf_counter()
    try:
        sd.play(audio_i16, samplerate=sr)
        sd.wait()
        print("‚úÖ Lecture termin√©e")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lecture: {e}")
    
    playback_end = time.perf_counter()

    log["playback_ms"] = (playback_end - playback_start) * 1000
    log["time_to_first_audio_ms"] = (tts_start - t0) * 1000
    log["e2e_ms"] = (playback_end - t0) * 1000

    # ---------------------------------------------------------------------
    # Validation humaine
    # ---------------------------------------------------------------------
    print("\n================  R√©capitulatif  ================")
    print("Vous avez dit   :", transcription)
    print("Assistant r√©pond :", assistant_text)
    
    while True:
        response = input("La r√©ponse est‚Äëelle satisfaisante ? (y/n) : ").strip().lower()
        if response.startswith("y"):
            ok = True
            break
        elif response.startswith("n"):
            ok = False
            break
        else:
            print("‚ö†Ô∏è  Veuillez r√©pondre par 'y' (oui) ou 'n' (non)")
    
    log["human_validation"] = ok

    # ---------------------------------------------------------------------
    # √âcriture log + verdict
    # ---------------------------------------------------------------------
    _write_log(log)
    
    # R√©sum√© final
    print("\n" + "üìä"*20)
    print("üìä R√âSUM√â VALIDATION")
    print("üìä"*20)
    print(f"‚è±Ô∏è  STT: {log.get('stt_latency_ms', 0):.1f}ms")
    print(f"‚è±Ô∏è  LLM: {log.get('llm_latency_ms', 0):.1f}ms")
    print(f"‚è±Ô∏è  TTS: {log.get('tts_latency_ms', 0):.1f}ms")
    print(f"‚è±Ô∏è  Total: {log.get('e2e_ms', 0):.1f}ms")
    print(f"‚úÖ Objectif < 1200ms: {'OUI' if log.get('e2e_ms', 0) < 1200 else 'NON'}")
    print(f"üë§ Validation humaine: {'‚úÖ SUCC√àS' if ok else '‚ùå √âCHEC'}")
    
    if ok:
        print("‚úÖ Validation humaine : OK ‚Äì pipeline voix accept√© ‚úî")
        sys.exit(0)
    else:
        print("‚ùå Validation humaine : NOK ‚Äì √† corriger")
        sys.exit(1)


# ---------------------------------------------------------------------------
# Utilitaire d'√©criture log
# ---------------------------------------------------------------------------

def _write_log(payload: dict, error: str | None = None) -> None:
    if error:
        payload["error"] = error
    log_dir = PROJECT_ROOT / "logs"
    log_dir.mkdir(exist_ok=True)
    fname = log_dir / f"voice_pipeline_validation_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
    with open(fname, "w", encoding="utf-8") as fp:
        json.dump(payload, fp, ensure_ascii=False, indent=2)
    print("Log JSON ‚Üí", fname)


# ---------------------------------------------------------------------------
if __name__ == "__main__":
    asyncio.run(main()) 