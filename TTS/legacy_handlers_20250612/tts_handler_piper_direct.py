# TTS/tts_handler_piper_direct.py
import os
import tempfile
import json
import numpy as np
import sounddevice as sd
import soundfile as sf
import onnxruntime

class TTSHandlerPiperDirect:
    def __init__(self, config):
        self.config = config
        
        # Chemin vers le mod√®le fran√ßais local  
        self.model_path = config.get('model_path', 'D:\\TTS_Voices\\piper\\fr_FR-siwis-medium.onnx')
        self.use_gpu = config.get('use_gpu', True)
        self.sample_rate = config.get('sample_rate', 22050)
        
        # Param√®tres de synth√®se
        self.noise_scale = config.get('noise_scale', 0.667)
        self.noise_scale_w = config.get('noise_scale_w', 0.8)
        self.length_scale = config.get('length_scale', 1.0)
        
        # Charger le mod√®le ONNX
        try:
            print(f"üîÑ Chargement du mod√®le Piper: {self.model_path}")
            
            # Configuration ONNX Runtime
            sess_options = onnxruntime.SessionOptions()
            
            if self.use_gpu:
                # Essayer d'utiliser CUDA si disponible
                providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            else:
                providers = ['CPUExecutionProvider']
            
            self.model = onnxruntime.InferenceSession(
                str(self.model_path), 
                sess_options=sess_options,
                providers=providers
            )
            
            # V√©rifier le provider utilis√©
            provider_used = self.model.get_providers()[0]
            print(f"‚úÖ TTS Handler Piper Direct initialis√© - Mod√®le: {self.model_path}")
            print(f"üöÄ Provider ONNX: {provider_used}")
            
        except Exception as e:
            print(f"‚ùå Erreur chargement mod√®le Piper: {e}")
            raise

    def text_to_phonemes(self, text):
        """
        Conversion am√©lior√©e du texte en phon√®mes.
        G√©n√®re un mapping plus r√©aliste pour tester la synth√®se.
        """
        # Mappage plus √©tendu avec pad et tokens sp√©ciaux
        chars = "_ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!'(),-.:;? √†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ø√ß"
        char_to_id = {char: i for i, char in enumerate(chars)}
        
        # Remplacer les caract√®res non reconnus par des espaces
        text = ''.join(char if char in char_to_id else ' ' for char in text)
        
        # Convertir en IDs avec un mapping plus r√©aliste
        phoneme_ids = []
        for char in text:
            if char in char_to_id:
                phoneme_ids.append(char_to_id[char])
            else:
                phoneme_ids.append(0)  # padding
        
        # Ensure minimum length and add padding
        if len(phoneme_ids) < 10:
            phoneme_ids.extend([0] * (10 - len(phoneme_ids)))
            
        return phoneme_ids

    def synthesize_audio(self, phoneme_ids):
        """Synth√®se audio √† partir des IDs de phon√®mes"""
        
        # Pr√©parer les entr√©es pour le mod√®le ONNX
        text = np.expand_dims(np.array(phoneme_ids, dtype=np.int64), 0)
        text_lengths = np.array([text.shape[1]], dtype=np.int64)
        scales = np.array(
            [self.noise_scale, self.length_scale, self.noise_scale_w],
            dtype=np.float32,
        )
        
        # Debug: afficher les dimensions
        print(f"   üîç Debug - text shape: {text.shape}, lengths: {text_lengths}")
        
        # Pr√©parer les inputs pour le mod√®le
        inputs = {
            "input": text,
            "input_lengths": text_lengths,
            "scales": scales
        }
        
        # Ajouter sid si n√©cessaire (v√©rifions les inputs du mod√®le)
        input_names = [inp.name for inp in self.model.get_inputs()]
        if "sid" in input_names:
            inputs["sid"] = np.array([0], dtype=np.int64)  # speaker ID par d√©faut
        
        print(f"   üîç Debug - Model inputs: {input_names}")
        print(f"   üîç Debug - Our inputs: {list(inputs.keys())}")
        
        # Inf√©rence
        audio = self.model.run(None, inputs)[0]
        print(f"   üîç Debug - Raw audio shape: {audio.shape}")
        
        # Squeeze les dimensions inutiles
        if len(audio.shape) > 1:
            audio = audio.squeeze()
        
        print(f"   üîç Debug - Squeezed audio shape: {audio.shape}")
        
        # V√©rifier que nous avons bien de l'audio
        if audio.size == 0:
            raise ValueError("Aucun audio g√©n√©r√© par le mod√®le")
        
        return audio

    def audio_float_to_int16(self, audio):
        """Convertir l'audio float32 en int16"""
        # V√©rifier le type et la forme
        print(f"   üîç Debug - Audio type: {type(audio)}, dtype: {audio.dtype}")
        
        # S'assurer que l'audio est en float32
        if audio.dtype != np.float32:
            audio = audio.astype(np.float32)
        
        # Normaliser et convertir
        audio = np.clip(audio, -1.0, 1.0)
        audio_int16 = (audio * 32767).astype(np.int16)
        
        print(f"   üîç Debug - Final audio: {audio_int16.shape}, range: [{audio_int16.min()}, {audio_int16.max()}]")
        
        return audio_int16

    def speak(self, text):
        """Synth√©tise et joue le texte avec Piper (100% local)."""
        print("üîä Synth√®se vocale Piper Direct en cours...")
        print(f"   Texte: '{text}'")
        
        try:
            # √âtape 1: Conversion texte ‚Üí phon√®mes
            phoneme_ids = self.text_to_phonemes(text)
            print(f"   üìù Phon√®mes g√©n√©r√©s: {len(phoneme_ids)} IDs")
            
            # √âtape 2: Synth√®se audio
            audio_raw = self.synthesize_audio(phoneme_ids)
            print(f"   üéµ Audio brut g√©n√©r√©: {audio_raw.shape} √©chantillons")
            
            # √âtape 3: Conversion du format
            audio = self.audio_float_to_int16(audio_raw)
            print(f"   üîß Audio converti: {len(audio)} √©chantillons int16")
            
            # √âtape 4: Sauvegarde et lecture directe
            if len(audio) > 0:
                # Lecture directe avec sounddevice (√©vite le probl√®me de fichier)
                print(f"   üîä Lecture audio directe...")
                audio_float = audio.astype(np.float32) / 32767.0  # Conversion pour sounddevice
                sd.play(audio_float, self.sample_rate)
                sd.wait()  # Attendre la fin de la lecture
                
                print(f"   ‚úÖ Synth√®se termin√©e - {len(audio)} √©chantillons")
            else:
                print("   ‚ö†Ô∏è Aucun audio g√©n√©r√©")
                
        except Exception as e:
            print(f"‚ùå Erreur synth√®se Piper Direct: {e}")
            import traceback
            traceback.print_exc()
            
        print("üîä Fin de la synth√®se.")

    def test_synthesis(self):
        """Test rapide de synth√®se."""
        test_text = "Bonjour, je suis LUXA, votre assistant vocal local."
        print(f"üß™ Test de synth√®se: '{test_text}'")
        self.speak(test_text) 