#!/usr/bin/env python3
"""
Diagnostic STT Simple - SuperWhisper V6 Phase 4
üîß DIAGNOSTIC: Identifier le probl√®me VAD avec m√©thode synchrone

Mission: Identifier pr√©cis√©ment o√π se bloque la transcription
"""

import os
import sys
import time
import numpy as np
from pathlib import Path

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üîß Diagnostic STT Simple - Configuration GPU RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

def validate_rtx3090():
    """Validation RTX 3090"""
    import torch
    if not torch.cuda.is_available():
        raise RuntimeError("üö´ CUDA non disponible")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:
        raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite")
    
    print(f"‚úÖ RTX 3090 valid√©e: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")

def test_audio_court():
    """Test avec audio court synth√©tique"""
    
    print("\n" + "="*50)
    print("üîß TEST 1 - AUDIO COURT SYNTH√âTIQUE")
    print("="*50)
    
    validate_rtx3090()
    
    # Import faster-whisper direct
    try:
        from faster_whisper import WhisperModel
        print("‚úÖ faster-whisper import√©")
    except ImportError:
        print("‚ùå faster-whisper non disponible")
        return False
    
    # Audio synth√©tique court (3 secondes)
    SAMPLE_RATE = 16000
    duration = 3.0
    samples = int(duration * SAMPLE_RATE)
    
    # G√©n√©rer audio simple
    t = np.linspace(0, duration, samples)
    frequency = 440  # La 440Hz
    audio = 0.3 * np.sin(2 * np.pi * frequency * t).astype(np.float32)
    
    print(f"üìä Audio g√©n√©r√©: {len(audio)} samples, {duration}s")
    
    # Test faster-whisper direct
    print(f"üöÄ Initialisation faster-whisper...")
    model = WhisperModel("large-v2", device="cuda", compute_type="float16")
    print(f"‚úÖ Mod√®le charg√©")
    
    print(f"ü§ñ Transcription synchrone...")
    start_time = time.time()
    
    try:
        # Transcription SYNCHRONE avec param√®tres VAD corrig√©s
        vad_parameters = {
            "threshold": 0.3,                    
            "min_speech_duration_ms": 100,       
            "max_speech_duration_s": 60,         
            "min_silence_duration_ms": 1000,     
            "speech_pad_ms": 400                 
        }
        
        segments, info = model.transcribe(
            audio,
            language="fr",
            beam_size=5,
            best_of=5,
            vad_filter=True,
            vad_parameters=vad_parameters
        )
        
        duration_ms = (time.time() - start_time) * 1000
        
        # Collecter r√©sultats
        segments_list = list(segments)
        text = " ".join([seg.text for seg in segments_list])
        
        print(f"‚úÖ Transcription r√©ussie en {duration_ms:.0f}ms")
        print(f"üìù Texte: '{text}'")
        print(f"üìä Segments: {len(segments_list)}")
        print(f"‚ö° RTF: {(duration_ms/1000)/duration:.3f}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur transcription: {e}")
        return False

def test_audio_long():
    """Test avec audio long synth√©tique"""
    
    print("\n" + "="*50)
    print("üîß TEST 2 - AUDIO LONG SYNTH√âTIQUE")
    print("="*50)
    
    # Import faster-whisper direct
    from faster_whisper import WhisperModel
    
    # Audio synth√©tique long (30 secondes)
    SAMPLE_RATE = 16000
    duration = 30.0
    samples = int(duration * SAMPLE_RATE)
    
    # G√©n√©rer audio vari√© pour simuler parole
    t = np.linspace(0, duration, samples)
    
    # M√©lange de fr√©quences pour simuler parole
    audio = np.zeros(samples, dtype=np.float32)
    
    # Ajouter plusieurs segments avec pauses
    segment_duration = 3.0  # 3s par segment
    pause_duration = 1.0    # 1s de pause
    
    for i in range(6):  # 6 segments
        start_seg = int(i * (segment_duration + pause_duration) * SAMPLE_RATE)
        end_seg = int(start_seg + segment_duration * SAMPLE_RATE)
        
        if end_seg < len(audio):
            # Fr√©quence variable par segment
            freq = 440 + i * 50
            t_seg = np.linspace(0, segment_duration, end_seg - start_seg)
            audio[start_seg:end_seg] = 0.3 * np.sin(2 * np.pi * freq * t_seg)
    
    print(f"üìä Audio long g√©n√©r√©: {len(audio)} samples, {duration}s")
    
    # R√©utiliser le mod√®le (d√©j√† charg√©)
    model = WhisperModel("large-v2", device="cuda", compute_type="float16")
    
    print(f"ü§ñ Transcription audio long avec VAD corrig√©...")
    start_time = time.time()
    
    try:
        # Transcription avec param√®tres VAD corrig√©s
        vad_parameters = {
            "threshold": 0.3,                    
            "min_speech_duration_ms": 100,       
            "max_speech_duration_s": 60,         
            "min_silence_duration_ms": 1000,     
            "speech_pad_ms": 400                 
        }
        
        segments, info = model.transcribe(
            audio,
            language="fr",
            beam_size=5,
            vad_filter=True,
            vad_parameters=vad_parameters
        )
        
        duration_ms = (time.time() - start_time) * 1000
        
        # Collecter r√©sultats
        segments_list = list(segments)
        text = " ".join([seg.text for seg in segments_list])
        
        print(f"‚úÖ Transcription longue r√©ussie en {duration_ms:.0f}ms")
        print(f"üìù Texte: '{text}'")
        print(f"üìä Segments d√©tect√©s: {len(segments_list)}")
        print(f"‚ö° RTF: {(duration_ms/1000)/duration:.3f}")
        
        # Analyser segments VAD
        if segments_list:
            print(f"\nüîç ANALYSE SEGMENTS VAD:")
            for i, seg in enumerate(segments_list[:5]):  # Max 5 premiers
                print(f"   Seg {i+1}: {seg.start:.1f}s ‚Üí {seg.end:.1f}s ({seg.end-seg.start:.1f}s)")
                print(f"          Texte: '{seg.text}'")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur transcription longue: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_vad_validation():
    """Test final de validation VAD"""
    
    print("\n" + "="*50)
    print("üéØ TEST 3 - VALIDATION CORRECTION VAD")
    print("="*50)
    
    from faster_whisper import WhisperModel
    
    # Cr√©er un audio test de 30s avec beaucoup de segments
    SAMPLE_RATE = 16000
    duration = 30.0
    samples = int(duration * SAMPLE_RATE)
    
    audio = np.zeros(samples, dtype=np.float32)
    
    # 15 segments de 1s avec 1s de pause entre (simule phrase longue)
    for i in range(15):
        start_seg = int(i * 2 * SAMPLE_RATE)  # Tous les 2s
        end_seg = int(start_seg + 1 * SAMPLE_RATE)  # 1s de dur√©e
        
        if end_seg < len(audio):
            # Fr√©quence diff√©rente par "mot"
            freq = 200 + i * 30  # Variation fr√©quence
            t_seg = np.linspace(0, 1.0, end_seg - start_seg)
            audio[start_seg:end_seg] = 0.2 * np.sin(2 * np.pi * freq * t_seg)
    
    print(f"üìä Audio test validation: 15 segments sur {duration}s")
    
    model = WhisperModel("large-v2", device="cuda", compute_type="float16")
    
    # Test 1: Param√®tres VAD par d√©faut (probl√©matiques)
    print(f"\nüß™ Test VAD d√©faut (probl√©matique):")
    try:
        start_time = time.time()
        segments, info = model.transcribe(
            audio,
            language="fr",
            beam_size=5,
            vad_filter=True
            # Pas de vad_parameters = utilise d√©faut
        )
        
        duration_ms = (time.time() - start_time) * 1000
        segments_list = list(segments)
        
        print(f"   ‚è±Ô∏è Dur√©e: {duration_ms:.0f}ms")
        print(f"   üìä Segments d√©tect√©s: {len(segments_list)}")
        print(f"   ‚ö° RTF: {(duration_ms/1000)/duration:.3f}")
        
    except Exception as e:
        print(f"   ‚ùå Erreur VAD d√©faut: {e}")
    
    # Test 2: Param√®tres VAD corrig√©s (solution)
    print(f"\nüîß Test VAD corrig√© (solution):")
    try:
        vad_parameters = {
            "threshold": 0.3,                    
            "min_speech_duration_ms": 100,       
            "max_speech_duration_s": 60,         
            "min_silence_duration_ms": 1000,     
            "speech_pad_ms": 400                 
        }
        
        start_time = time.time()
        segments, info = model.transcribe(
            audio,
            language="fr",
            beam_size=5,
            vad_filter=True,
            vad_parameters=vad_parameters
        )
        
        duration_ms = (time.time() - start_time) * 1000
        segments_list = list(segments)
        
        print(f"   ‚è±Ô∏è Dur√©e: {duration_ms:.0f}ms")
        print(f"   üìä Segments d√©tect√©s: {len(segments_list)}")
        print(f"   ‚ö° RTF: {(duration_ms/1000)/duration:.3f}")
        
        # Succ√®s si d√©tecte plus de segments
        if len(segments_list) > 3:
            print(f"   ‚úÖ CORRECTION VAD FONCTIONNE!")
            print(f"   üéØ D√©tection am√©lior√©e: {len(segments_list)} segments")
            return True
        else:
            print(f"   ‚ö†Ô∏è Toujours insuffisant: {len(segments_list)} segments")
            return False
        
    except Exception as e:
        print(f"   ‚ùå Erreur VAD corrig√©: {e}")
        return False

def main():
    """Test diagnostic complet"""
    
    print("üîß DIAGNOSTIC STT SIMPLE - SUPERWHISPER V6 PHASE 4")
    print("Mission: Valider la correction VAD avec faster-whisper direct")
    
    try:
        # Test 1: Audio court
        success1 = test_audio_court()
        
        if success1:
            # Test 2: Audio long
            success2 = test_audio_long()
            
            if success2:
                # Test 3: Validation correction VAD
                success3 = test_vad_validation()
                
                if success3:
                    print(f"\nüéä CORRECTION VAD VALID√âE AVEC SUCC√àS!")
                    print(f"   ‚úÖ faster-whisper fonctionne correctement")
                    print(f"   ‚úÖ Param√®tres VAD corrig√©s op√©rationnels")
                    print(f"   ‚úÖ Pr√™t pour tests avec microphone r√©el")
                else:
                    print(f"\n‚ö†Ô∏è PROBL√àME PERSISTE DANS PARAM√àTRES VAD")
            else:
                print(f"\n‚ö†Ô∏è PROBL√àME D√âTECT√â AVEC AUDIO LONG")
        else:
            print(f"\n‚ùå PROBL√àME D√âTECT√â AVEC AUDIO COURT")
            
    except Exception as e:
        print(f"\n‚ùå Erreur diagnostic: {e}")
    
    print(f"\nüèÅ Diagnostic termin√©")

if __name__ == "__main__":
    main() 