#!/usr/bin/env python3
"""
Démonstration streaming microphone SuperWhisper V6
Solution des experts - Test simple et rapide
"""

import os
import sys
import asyncio
from pathlib import Path

# =============================================================================
# 🚨 CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation mémoire

print("🎮 Demo Streaming Microphone - Configuration GPU RTX 3090 (CUDA:1) forcée")
print(f"🔒 CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajouter le répertoire parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Imports après configuration GPU
import torch
from STT.unified_stt_manager import UnifiedSTTManager
from STT.streaming_microphone_manager import StreamingMicrophoneManager

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    if not torch.cuda.is_available():
        raise RuntimeError("🚫 CUDA non disponible - RTX 3090 requise")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"🚫 CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit être '1'")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 = ~24GB
        raise RuntimeError(f"🚫 GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
    
    print(f"✅ RTX 3090 validée: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")

async def main():
    """Démonstration principale"""
    print("🚀 Démonstration streaming microphone SuperWhisper V6")
    print("=" * 50)
    
    # Validation GPU RTX 3090
    try:
        validate_rtx3090_configuration()
    except Exception as e:
        print(f"❌ Erreur configuration GPU: {e}")
        return
    
    print("\n🔧 Initialisation des managers...")
    
    try:
        # Initialisation STT Manager
        stt_mgr = UnifiedSTTManager()
        print("✅ UnifiedSTTManager initialisé")
        
        # Initialisation Streaming Microphone Manager
        mic_mgr = StreamingMicrophoneManager(stt_mgr)
        print("✅ StreamingMicrophoneManager initialisé")
        
        print("\n🎤 Démarrage capture microphone...")
        print("Parlez maintenant! (Ctrl+C pour arrêter)")
        print("Objectif: Premier token < 800ms, RTF live ≈ 0.1")
        print("-" * 50)
        
        # Démarrage streaming
        await mic_mgr.run()
        
    except KeyboardInterrupt:
        print("\n🛑 Arrêt demandé par l'utilisateur")
    except Exception as e:
        print(f"\n❌ Erreur: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n🎯 Démonstration terminée")

if __name__ == "__main__":
    print("🎯 Démarrage démonstration streaming microphone...")
    
    try:
        asyncio.run(main())
        print("\n✅ Démonstration terminée avec succès")
    except KeyboardInterrupt:
        print("\n🛑 Démonstration interrompue")
    except Exception as e:
        print(f"\n💥 Erreur fatale: {e}")
        sys.exit(1) 