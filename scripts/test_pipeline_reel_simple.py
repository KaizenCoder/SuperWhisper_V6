#!/usr/bin/env python3
"""
ğŸ¤ TEST PIPELINE RÃ‰EL SIMPLE - SUPERWHISPER V6
==============================================
Test validation humaine RÃ‰ELLE avec PipelineOrchestrator existant

MISSION:
- Utiliser PipelineOrchestrator dÃ©jÃ  validÃ©
- Test microphone â†’ rÃ©ponse vocale
- Validation humaine expÃ©rience utilisateur

Usage: python scripts/test_pipeline_reel_simple.py

ğŸš¨ CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE

ğŸš¨ CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# ğŸš€ PORTABILITÃ‰ AUTOMATIQUE - EXÃ‰CUTABLE DEPUIS N'IMPORTE OÃ™
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour exÃ©cution portable"""
    # DÃ©terminer le rÃ©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le rÃ©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"ğŸ® GPU Configuration: RTX 3090 (CUDA:1) forcÃ©e")
    print(f"ğŸ“ Project Root: {project_root}")
    print(f"ğŸ’» Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import asyncio
import time
import logging
from pathlib import Path

# =============================================================================
# ğŸš¨ CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation mÃ©moire

print("ğŸ® GPU Configuration: RTX 3090 (CUDA:1) forcÃ©e")
print(f"ğŸ”’ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajout du chemin pour imports
sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent.parent / "PIPELINE"))

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger("pipeline_reel_simple")

async def test_pipeline_reel():
    """Test pipeline rÃ©el avec PipelineOrchestrator"""
    try:
        # Import de la fonction bootstrap validÃ©e
        from pipeline_orchestrator import _bootstrap
        
        logger.info("ğŸš€ DÃ‰MARRAGE TEST PIPELINE RÃ‰EL SIMPLE")
        logger.info("="*60)
        
        # Utiliser la fonction bootstrap qui gÃ¨re tout automatiquement
        logger.info("ğŸ”§ Bootstrap pipeline avec configuration validÃ©e...")
        pipeline = await _bootstrap(cfg_path="PIPELINE/config/pipeline.yaml")
        
        if pipeline is None:
            logger.error("âŒ Ã‰chec bootstrap pipeline")
            return False
        
        logger.info("âœ… Pipeline bootstrappÃ© avec succÃ¨s !")
        
        logger.info("âœ… Pipeline dÃ©marrÃ© avec succÃ¨s !")
        logger.info("\nğŸ¤ MODE TEST INTERACTIF")
        logger.info("Le pipeline est maintenant actif.")
        logger.info("Parlez dans votre microphone RODE NT-USB...")
        logger.info("Appuyez sur Ctrl+C pour arrÃªter")
        
        # Laisser le pipeline tourner
        try:
            while True:
                await asyncio.sleep(1)
                
                # Afficher mÃ©triques pÃ©riodiquement
                if hasattr(pipeline, 'metrics'):
                    metrics = pipeline.metrics
                    logger.info(f"ğŸ“Š Conversations: {len(pipeline.conversation_history)}")
                
        except KeyboardInterrupt:
            logger.info("\nğŸ›‘ ArrÃªt demandÃ© par utilisateur")
        
        # ArrÃªter pipeline
        logger.info("ğŸ”„ ArrÃªt pipeline...")
        await pipeline.stop()
        
        logger.info("âœ… Pipeline arrÃªtÃ© proprement")
        
        # Afficher rÃ©sultats
        if hasattr(pipeline, 'conversation_history') and pipeline.conversation_history:
            logger.info(f"\nğŸ“Š RÃ‰SULTATS TEST:")
            logger.info(f"ğŸ¤ Conversations: {len(pipeline.conversation_history)}")
            
            for i, conv in enumerate(pipeline.conversation_history[-3:], 1):  # 3 derniÃ¨res
                logger.info(f"  {i}. Input: '{conv.user_input[:50]}...'")
                logger.info(f"     RÃ©ponse: '{conv.assistant_response[:50]}...'")
                logger.info(f"     Latence: {conv.total_latency:.1f}ms")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erreur test pipeline: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Fonction principale"""
    try:
        success = await test_pipeline_reel()
        return 0 if success else 1
        
    except Exception as e:
        logger.error(f"âŒ Erreur main: {e}")
        return 1

if __name__ == "__main__":
    print("ğŸ¤ SuperWhisper V6 - Test Pipeline RÃ©el Simple")
    print("ğŸš¨ Utilise le PipelineOrchestrator validÃ©")
    print("ğŸš¨ Assurez-vous que:")
    print("  - Ollama server est dÃ©marrÃ©")
    print("  - Microphone RODE NT-USB est connectÃ©")
    print("  - Speakers/casque sont connectÃ©s")
    print()
    
    exit_code = asyncio.run(main())
    sys.exit(exit_code) 