# üìã PRD - HOMOG√âNISATION DU MAPPING GPU SUPERWHISPER V6

---

**Projet :** Correction et Homog√©nisation du Mapping GPU SuperWhisper V6  
**Version :** 2.0 [OPTIMIS√âE avec Memory Leak V4.0 + Parall√©lisation]  
**Date :** Juin 2025  
**Priorit√© :** CRITIQUE  
**Dur√©e estim√©e :** 12-16 heures (40 fichiers) [64% GAIN vs 33h s√©quentiel]  
**Dur√©e s√©quentielle :** 33 heures (baseline de r√©f√©rence)  

---

## üéØ CONTEXTE ET PROBL√âMATIQUE

### Situation Actuelle
Le projet SuperWhisper V6 pr√©sente une **m√©thodologie de s√©lection et contr√¥le GPU non homog√®ne** √† travers ses 89 fichiers Python/PowerShell. Cette h√©t√©rog√©n√©it√© g√©n√®re :

- **Risques de performance** : Utilisation accidentelle de RTX 5060 Ti (16GB) au lieu de RTX 3090 (24GB)
- **Instabilit√© syst√®me** : Mappings GPU incoh√©rents entre modules
- **Maintenance complexe** : Pas de standard unifi√© pour la s√©lection GPU
- **Erreurs silencieuses** : Aucune validation syst√©matique du GPU utilis√©

### D√©couverte Critique
L'analyse factuelle r√©v√®le que la **configuration GPU n√©cessite deux variables d'environnement** pour fonctionner correctement :
- `CUDA_VISIBLE_DEVICES='1'` seul ne suffit pas
- `CUDA_DEVICE_ORDER='PCI_BUS_ID'` est **obligatoire** pour respecter l'ordre physique des GPU

### Configuration Mat√©rielle
```
Configuration physique du syst√®me :
- GPU Bus PCI 0 : RTX 5060 Ti (16GB) ‚Üí STRICTEMENT INTERDITE
- GPU Bus PCI 1 : RTX 3090 (24GB) ‚Üí SEULE GPU AUTORIS√âE

‚ö†Ô∏è ATTENTION : Sans CUDA_DEVICE_ORDER='PCI_BUS_ID', PyTorch peut ordonner les GPU diff√©remment !
```

### Impact Business
- **Performance d√©grad√©e** sur les t√¢ches IA critiques
- **Risque de plantage** lors de traitement de gros volumes  
- **Incoh√©rence utilisateur** avec des temps de r√©ponse variables
- **Maintenance difficile** due aux standards non homog√®nes

---

## üéØ OBJECTIFS

### Objectif Principal
**Homog√©n√©iser et s√©curiser la s√©lection GPU** dans tous les scripts du projet pour garantir l'utilisation exclusive de la RTX 3090.

### Objectifs Sp√©cifiques
1. **Ajouter la configuration GPU compl√®te** dans les 40 scripts identifi√©s
2. **S'assurer de l'utilisation coh√©rente de `cuda:0`** dans le code (qui pointera vers RTX 3090)
3. **Impl√©menter une validation syst√©matique** de s√©lection GPU
4. **Garantir z√©ro r√©gression fonctionnelle**
5. **Documenter les standards** pour d√©veloppements futurs

---

## üéØ COMPR√âHENSION FACTUELLE CONFIRM√âE

### **Configuration Physique R√©elle Valid√©e :**
```bash
nvidia-smi --query-gpu=index,name,memory.total --format=csv
GPU 0: NVIDIA GeForce RTX 5060 Ti (16311 MiB = ~16GB) ‚ùå INTERDITE
GPU 1: NVIDIA GeForce RTX 3090 (24576 MiB = ~24GB)    ‚úÖ CIBLE
```

### **Logique CUDA_VISIBLE_DEVICES Confirm√©e :**
1. **`CUDA_VISIBLE_DEVICES='1'`** = Rendre visible UNIQUEMENT le GPU physique 1 (RTX 3090)
2. **PyTorch remapping automatique** = Le seul GPU visible devient `cuda:0` dans le code
3. **R√©sultat final** = `cuda:0` dans PyTorch pointe vers RTX 3090 ‚úÖ
4. **RTX 5060 Ti devient inaccessible** = Aucun risque d'utilisation accidentelle

### **Validation Obligatoire avec Script de Diagnostic :**
```python
# Utiliser OBLIGATOIREMENT ce script pour validation :
python "C:\Dev\SuperWhisper_V6\test_diagnostic_rtx3090.py"

# Le script DOIT confirmer :
# ‚úÖ CUDA_VISIBLE_DEVICES='1' configur√©
# ‚úÖ GPU 0 (apr√®s mapping) = RTX 3090 24GB
# ‚úÖ RTX 5060 Ti invisible/inaccessible
# ‚úÖ Configuration fonctionnelle valid√©e
```

### **Points Critiques de Compr√©hension :**
- **CUDA_VISIBLE_DEVICES='1'** ne change PAS l'ordre, il MASQUE le GPU 0
- **PyTorch voit 1 seul GPU** (RTX 3090) qu'il nomme automatiquement `cuda:0`
- **Le code utilise `cuda:0`** qui pointe maintenant vers RTX 3090
- **Aucune confusion possible** : RTX 5060 Ti est compl√®tement invisible

---

## üöÄ OPTIMISATIONS PERFORMANCE VALID√âES

### Memory Leak Solution V4.0 - Int√©gration Obligatoire
- **Script central** : `memory_leak_v4.py` (solution finalis√©e et valid√©e)
- **Memory leak prevention** : 0% memory leak d√©tect√© sur 10/10 stress tests
- **Context manager automatique** : `@gpu_test_cleanup()` pour tous tests GPU
- **Queue GPU exclusive** : S√©maphore multiprocess pour RTX 3090
- **Monitoring temps r√©el** : M√©moire, fragmentation, performance
- **Emergency recovery** : Reset automatique si memory leak critique
- **M√©triques Prometheus** : Monitoring centralis√© int√©gr√©

### Parall√©lisation Valid√©e - 64% Gain Performance
```
CONFIGURATION SYST√àME VALID√âE :
- RAM : 64GB (32+32GB DDR4-4800) ‚úÖ
- CPU : Intel Core Ultra 7 265K (20 threads logiques) ‚úÖ
- GPU : RTX 3090 (24GB VRAM) sur Bus PCI 1 ‚úÖ
- Memory Leak Solution : 10/10 tests r√©ussis ‚úÖ

GAINS PERFORMANCE CONFIRM√âS :
- Phase 1 (Pr√©paration) : 3h ‚Üí 1.5h (50% gain)
- Phase 2 (13 modules core) : 10h ‚Üí 3.5h (65% gain) 
- Phase 3 (27 scripts test) : 15h ‚Üí 4.5h (70% gain)
- Phase 4 (Tests syst√®me) : 3h ‚Üí 3h (s√©quentiel obligatoire)
- Phase 5 (Documentation) : 2h ‚Üí 1h (50% gain)

TOTAL : 33h ‚Üí 13.5h (59% gain valid√©)
```

### Architecture Technique Parall√©lisation
- **ThreadPool** : 8-10 workers CPU simultan√©s optimaux
- **GPU Queue** : Acc√®s RTX 3090 exclusif via s√©maphore multiprocess
- **Memory Management** : `memory_leak_v4.py` int√©gr√© √† chaque worker
- **Git Workflow** : Branches d√©di√©es par worker pour √©viter conflits
- **Monitoring centralis√©** : Prometheus metrics temps r√©el
- **Fallback automatique** : S√©quentiel si instabilit√© d√©tect√©e

### Contraintes et Limitations Parall√©lisation
- **GPU unique** : RTX 3090 = queue obligatoire, pas de parall√©lisme GPU pur
- **Memory leaks** : Surveillance continue requise entre workers
- **Conflits Git** : R√©solution manuelle si branches divergent
- **Ressources syst√®me** : 64GB RAM + 20 threads CPU requis minimum
- **Tests syst√®me** : Phase 4 reste s√©quentielle (validation int√©grit√©)

---

## üîß SP√âCIFICATIONS TECHNIQUES

### Configuration GPU Standard Obligatoire
```python
# STANDARD OBLIGATOIRE - √Ä INT√âGRER DANS CHAQUE SCRIPT
import os
import torch

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB sur Bus PCI 1
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Force l'ordre du bus physique
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'

print("üéÆ GPU Configuration: RTX 3090 (CUDA:0 apr√®s mapping)")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")
print(f"üîí CUDA_DEVICE_ORDER: {os.environ.get('CUDA_DEVICE_ORDER')}")
```

### Validation Obligatoire - AUCUNE EXCEPTION
```python
def validate_rtx3090_mandatory():
    """Validation syst√©matique - OBLIGATOIRE dans chaque script"""
    if not torch.cuda.is_available():
        raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
    
    # CONTR√îLE 1: Variables environnement
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    cuda_order = os.environ.get('CUDA_DEVICE_ORDER', '')
    
    if cuda_devices != '1':
        raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
    
    if cuda_order != 'PCI_BUS_ID':
        raise RuntimeError(f"üö´ CUDA_DEVICE_ORDER='{cuda_order}' incorrect - doit √™tre 'PCI_BUS_ID'")
    
    # CONTR√îLE 2: GPU physique d√©tect√© (apr√®s mapping, cuda:0 = RTX 3090)
    gpu_name = torch.cuda.get_device_name(0)
    if "RTX 3090" not in gpu_name:
        raise RuntimeError(f"üö´ GPU d√©tect√©: {gpu_name} - RTX 3090 requise")
    
    # CONTR√îLE 3: M√©moire GPU
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 ‚âà 24GB
        raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) insuffisante - RTX 3090 requise")
    
    print(f"‚úÖ RTX 3090 valid√©e: {gpu_name} ({gpu_memory:.1f}GB)")

# APPELER OBLIGATOIREMENT dans __main__ ou au d√©but du script
if __name__ == "__main__":
    validate_rtx3090_mandatory()
```

### Fichiers √† Corriger (40 identifi√©s - Liste Exhaustive)

#### Modules Core Critiques Initiaux (7)
- `benchmarks/benchmark_stt_realistic.py`
- `LLM/llm_manager_enhanced.py`  
- `LUXA_TTS/tts_handler_coqui.py`
- `Orchestrator/fallback_manager.py`
- `STT/vad_manager_optimized.py`
- `TTS/tts_handler_coqui.py`
- `TTS/tts_handler_piper_native.py`

#### Modules Core Suppl√©mentaires (6)
- `STT/stt_manager_robust.py`
- `STT/vad_manager.py`
- `TTS/tts_handler_piper_espeak.py`
- `TTS/tts_handler_piper_fixed.py`
- `TTS/tts_handler_piper_french.py`
- `utils/gpu_manager.py`

#### Scripts de Test Initiaux (13)
- `tests/test_double_check_corrections.py`
- `tests/test_double_check_validation_simple.py`
- `test_cuda_debug.py`
- `test_cuda.py`
- `test_espeak_french.py`
- `test_french_voice.py`
- `test_gpu_correct.py`
- `test_piper_native.py`
- `test_tts_fixed.py`
- `test_tts_long_feedback.py`
- `test_upmc_model.py`
- `test_validation_decouverte.py`
- `TTS/tts_handler_piper_rtx3090.py`

#### Tests Suppl√©mentaires (2)
- `tests/test_llm_handler.py`
- `tests/test_stt_handler.py`

#### Scripts de Validation Exhaustifs (12)
- `test_correction_validation_1.py`
- `test_correction_validation_2.py`
- `test_correction_validation_3.py`
- `test_correction_validation_4.py`
- `test_rtx3090_detection.py`
- `test_tts_rtx3090_performance.py`
- `test_validation_globale_finale.py`
- `test_validation_mvp_settings.py`
- `test_validation_rtx3090_detection.py`
- `test_validation_stt_manager_robust.py`
- `test_validation_tts_performance.py`
- `validate_gpu_config.py`

---

## üõ†Ô∏è M√âTHODOLOGIE DE CORRECTION

### Phase 1 : Pr√©paration et Analyse
1. **Analyse d√©taill√©e** de chaque fichier cible
2. **V√©rification de la configuration existante** (CUDA_VISIBLE_DEVICES et CUDA_DEVICE_ORDER)
3. **Cr√©ation de tests de r√©f√©rence** (version originale)
4. **Documentation des fonctionnalit√©s** existantes compl√®tes
5. **Sauvegarde versions originales** dans Git

### Phase 2 : Correction Syst√©matique
1. **Ajout/compl√©tion de la configuration GPU** :
   - `CUDA_VISIBLE_DEVICES='1'`
   - `CUDA_DEVICE_ORDER='PCI_BUS_ID'`
2. **V√©rification que le code utilise `cuda:0`** (mapp√© vers RTX 3090)
3. **Ajout de la validation obligatoire** RTX 3090
4. **Pr√©servation int√©grale** de toute la logique m√©tier
5. **Application du template standard** GPU

### Phase 3 : Validation Int√©grale - Z√âRO R√âGRESSION
Pour **CHAQUE fichier corrig√©** :

#### Test 1 : Configuration GPU (OBLIGATOIRE)
```python
def test_gpu_configuration():
    # √âTAPE 0: Script diagnostic OBLIGATOIRE POUR CHAQUE FICHIER
    import subprocess
    print("üîç DIAGNOSTIC RTX 3090 POUR CE FICHIER:")
    result = subprocess.run([
        "python", "C:\\Dev\\SuperWhisper_V6\\test_diagnostic_rtx3090.py"
    ], capture_output=True, text=True)
    
    print(result.stdout)
    assert result.returncode == 0, "√âCHEC: Script diagnostic RTX 3090"
    assert "RTX 3090 d√©tect√©: ‚úÖ OUI" in result.stdout, "√âCHEC: RTX 3090 non d√©tect√©e"
    print("‚úÖ Script diagnostic RTX 3090 valid√© pour ce fichier")
    
    # √âTAPE 1: V√©rifications environnement
    # V√©rifier CUDA_VISIBLE_DEVICES='1'
    # V√©rifier CUDA_DEVICE_ORDER='PCI_BUS_ID'
    # V√©rifier torch.cuda.get_device_name(0) contient "RTX 3090"
    # V√©rifier m√©moire GPU > 20GB
    # AUCUNE ASSOMPTION - CONTR√îLE FACTUEL OBLIGATOIRE
```

#### Test 2 : Fonctionnalit√© Int√©grale (OBLIGATOIRE)
```python
def test_all_functionalities():
    # Tester 100% des fonctions du module
    # Tester 100% des classes du module  
    # Tester tous les workflows d'usage
    # Comparer sorties avec version originale
    # V√©rifier performance identique ou meilleure
    # Valider gestion d'erreurs identique
```

#### Test 3 : Non-R√©gression (OBLIGATOIRE)
```python
def test_no_regression():
    # Benchmark performance vs version originale
    # Test m√©moire (pas de fuites)
    # Test stabilit√© sur dur√©e
    # Validation sorties bit-perfect si possible
```

### Phase 4 : Documentation et Standards
1. **Rapport de correction d√©taill√©** par fichier
2. **Standards GPU d√©finitifs** pour d√©veloppements futurs
3. **Guide de validation GPU** 
4. **Template de code** pour nouveaux d√©veloppements

---

## üîç CRIT√àRES D'ACCEPTATION STRICTS

### ‚úÖ Correction Valid√©e UNIQUEMENT Si
1. **Configuration GPU compl√®te** : CUDA_VISIBLE_DEVICES='1' ET CUDA_DEVICE_ORDER='PCI_BUS_ID'
2. **RTX 3090 d√©tect√©e et utilis√©e** : Validation factuelle obligatoire
3. **Code utilise `cuda:0`** de mani√®re coh√©rente (mapp√© vers RTX 3090)
4. **100% fonctionnalit√©s op√©rationnelles** : aucune r√©gression autoris√©e
5. **Performance maintenue** : identique ou am√©lior√©e (¬±2% max)
6. **Tests automatis√©s** : 100% passent
7. **Documentation** : compl√®te et valid√©e

### ‚ùå Correction Rejet√©e Si
- **Configuration incompl√®te** (manque CUDA_DEVICE_ORDER)
- **Mauvaise variable CUDA_VISIBLE_DEVICES** (diff√©rente de '1')
- **Une seule fonction** d√©faillante
- **R√©gression de performance** d√©tect√©e (>2%)
- **Validation GPU** √©choue
- **Tests automatis√©s** en √©chec
- **Comportement modifi√©** vs original

---

## üß∞ OUTILS ET TECHNOLOGIES REQUIS

### Langages
- **Python 3.8+** pour scripts de correction
- **PowerShell 7+** pour automation Windows

### Biblioth√®ques Python
- **PyTorch** pour validation GPU
- **pathlib** pour gestion fichiers
- **unittest/pytest** pour tests automatis√©s
- **psutil** pour monitoring syst√®me
- **memory_profiler** pour validation m√©moire

### Outils de D√©veloppement
- **Git** pour versioning et rollback s√©curis√©
- **Cursor/VS Code** pour √©dition
- **TaskMaster** pour gestion des t√¢ches structur√©es

### Validation et Tests
- **Scripts de test personnalis√©s** par fichier
- **Profiling m√©moire GPU** (nvidia-smi)
- **Benchmarks de performance** comparatifs
- **Tests de charge** pour validation stabilit√©

---

## ‚ö†Ô∏è RISQUES ET MITIGATION

| Risque | Impact | Probabilit√© | Mitigation |
|--------|--------|-------------|------------|
| Configuration GPU incompl√®te | **CRITIQUE** | √âlev√© | Double validation (CUDA_VISIBLE_DEVICES + CUDA_DEVICE_ORDER) |
| R√©gression fonctionnelle | **CRITIQUE** | Moyen | Tests exhaustifs avant/apr√®s + rollback Git |
| Performance d√©grad√©e | **√âLEV√â** | Faible | Benchmarks comparatifs + validation continue |
| Erreurs silencieuses | **√âLEV√â** | Moyen | Validation GPU obligatoire + tests automatis√©s |
| Mauvaise compr√©hension config | **√âLEV√â** | √âlev√© | Documentation claire + exemples concrets |

---

## üìà M√âTRIQUES DE SUCC√àS

### Objectifs Quantifiables
- **100%** des 40 fichiers avec configuration GPU compl√®te
- **100%** des fichiers utilisent RTX 3090 exclusivement
- **0** r√©gression fonctionnelle d√©tect√©e
- **100%** des tests automatis√©s passent
- **‚â•98%** de pr√©servation des performances
- **Standards GPU** document√©s et valid√©s

### Livrables Attendus
1. **40 fichiers avec configuration GPU homog√®ne**
2. **Code utilisant `cuda:0` de mani√®re coh√©rente**
3. **40 validations script diagnostic** "C:\Dev\SuperWhisper_V6\test_diagnostic_rtx3090.py"
4. **Standards GPU document√©s** 
5. **Guide de d√©veloppement** GPU
6. **Tests automatis√©s** pour validation continue
7. **Rapport de correction** d√©taill√©

---

## üéØ D√âFINITION DU SUCC√àS

**Le projet sera consid√©r√© comme r√©ussi quand :**
- Tous les scripts ont la configuration GPU compl√®te (CUDA_VISIBLE_DEVICES='1' + CUDA_DEVICE_ORDER='PCI_BUS_ID')
- Tous les scripts utilisent exclusivement la RTX 3090
- Le code utilise `cuda:0` de mani√®re coh√©rente
- Aucune r√©gression fonctionnelle n'est d√©tect√©e
- Les standards GPU sont adopt√©s pour les d√©veloppements futurs
- La validation GPU est automatis√©e et obligatoire
- La documentation est compl√®te et accessible

---

**Ce PRD garantit une approche m√©thodique, rigoureuse et sans risque pour l'homog√©nisation du mapping GPU, avec validation factuelle obligatoire √† chaque √©tape et pr√©servation int√©grale des fonctionnalit√©s existantes.** 