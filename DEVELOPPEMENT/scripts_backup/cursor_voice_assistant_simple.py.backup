#!/usr/bin/env python3
"""
Assistant vocal simplifi√© pour Cursor - Dict√©e de prompts
Version robuste avec multiples solutions de fallback
Inspir√© des scripts fonctionnels de SuperWhisper V6
"""

import asyncio
import pyaudio
import numpy as np
import pyautogui
import keyboard
import time
import os
import sys
import tempfile
from typing import Optional

print("üéôÔ∏è Assistant vocal pour Cursor - Version simplifi√©e")
print("üîß Configuration en cours...")

class SimpleCursorVoiceAssistant:
    """Assistant vocal simplifi√© avec fallback pour Cursor"""
    
    def __init__(self):
        self.recording = False
        self.audio_buffer = []
        self.current_method = None
        
        # Configuration audio
        self.sample_rate = 16000
        self.chunk_size = 1024
        self.format = pyaudio.paFloat32
        
        # PyAudio setup
        self.audio = pyaudio.PyAudio()
        self.stream = None
        
        # M√©thodes disponibles (par ordre de pr√©f√©rence)
        self.methods = [
            ("Windows SAPI", self._sapi_transcribe),
            ("Google TTS", self._gtts_transcribe),
            ("Edge TTS", self._edge_transcribe),
            ("Mode manuel", self._manual_mode)
        ]
        
    async def initialize(self):
        """Initialise l'assistant vocal"""
        print("üéôÔ∏è Initialisation de l'assistant vocal pour Cursor...")
        
        # Test des m√©thodes disponibles
        self.current_method = await self._find_best_method()
        
        # Stream audio
        self.stream = self.audio.open(
            format=self.format,
            channels=1,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size,
            stream_callback=self._audio_callback
        )
        
        print("‚úÖ Assistant vocal pr√™t !")
        print("üìå Raccourcis:")
        print("   - Ctrl+Shift+V : Commencer/arr√™ter la dict√©e")
        print("   - Ctrl+Shift+M : Changer de m√©thode de reconnaissance")
        print("   - Ctrl+Shift+Q : Quitter")
        print(f"üéØ M√©thode active: {self.current_method[0] if self.current_method else 'Aucune'}")
        
    async def _find_best_method(self):
        """Trouve la meilleure m√©thode de transcription disponible"""
        print("üîç Test des m√©thodes de reconnaissance vocale...")
        
        for name, method in self.methods:
            try:
                print(f"   Testing {name}...")
                if await self._test_method(method):
                    print(f"‚úÖ {name} disponible")
                    return (name, method)
                else:
                    print(f"‚ùå {name} non disponible")
            except Exception as e:
                print(f"‚ùå {name} √©chou√©: {e}")
        
        print("‚ö†Ô∏è Aucune m√©thode automatique disponible - Mode manuel activ√©")
        return ("Mode manuel", self._manual_mode)
    
    async def _test_method(self, method):
        """Test si une m√©thode de transcription fonctionne"""
        try:
            # Audio test court (1 seconde de silence)
            test_audio = np.zeros(16000, dtype=np.float32)
            result = await method(test_audio, test=True)
            return result is not None
        except:
            return False
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        """Callback pour capturer l'audio"""
        if self.recording:
            audio_chunk = np.frombuffer(in_data, dtype=np.float32)
            self.audio_buffer.extend(audio_chunk)
        return (in_data, pyaudio.paContinue)
    
    async def start_dictation(self):
        """D√©marre la dict√©e"""
        if self.recording:
            return
            
        print(f"üî¥ Dict√©e commenc√©e avec {self.current_method[0]}... Parlez maintenant!")
        self.recording = True
        self.audio_buffer = []
        
    async def stop_dictation(self):
        """Arr√™te la dict√©e et transcrit"""
        if not self.recording:
            return
            
        self.recording = False
        print("‚èπÔ∏è Dict√©e arr√™t√©e, transcription en cours...")
        
        if len(self.audio_buffer) > 0:
            # Convertir en numpy array
            audio_data = np.array(self.audio_buffer, dtype=np.float32)
            
            # Transcription avec la m√©thode active
            if self.current_method:
                try:
                    text = await self.current_method[1](audio_data)
                    
                    if text and text.strip():
                        print(f"üìù Transcrit: {text}")
                        
                        # Ins√©rer le texte √† la position du curseur dans Cursor
                        await asyncio.sleep(0.1)  # Petit d√©lai pour assurer le focus
                        pyautogui.typewrite(text)
                        
                        print("‚úÖ Texte ins√©r√© dans Cursor")
                    else:
                        print("‚ùå Transcription vide ou √©chou√©e")
                        
                except Exception as e:
                    print(f"‚ùå Erreur transcription: {e}")
            else:
                print("‚ùå Aucune m√©thode de transcription disponible")
        else:
            print("‚ö†Ô∏è Aucun audio captur√©")
    
    async def _sapi_transcribe(self, audio_data, test=False):
        """Transcription via Windows SAPI"""
        try:
            import win32com.client
            import speech_recognition as sr
            
            if test:
                # Test simple de disponibilit√©
                speaker = win32com.client.Dispatch("SAPI.SpVoice")
                return True
            
            # Utiliser speech_recognition pour la transcription
            r = sr.Recognizer()
            
            # Sauvegarder audio temporaire
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                import soundfile as sf
                sf.write(tmp.name, audio_data, 16000)
                
                with sr.AudioFile(tmp.name) as source:
                    audio = r.record(source)
                
                # Transcription en fran√ßais
                text = r.recognize_google(audio, language='fr-FR')
                os.unlink(tmp.name)
                return text
                
        except ImportError:
            if not test:
                print("üí° Installez: pip install pywin32 SpeechRecognition soundfile")
            return None
        except Exception as e:
            if not test:
                print(f"Erreur SAPI: {e}")
            return None
    
    async def _gtts_transcribe(self, audio_data, test=False):
        """Transcription via Google Speech Recognition"""
        try:
            import speech_recognition as sr
            
            if test:
                return True
            
            r = sr.Recognizer()
            
            # Sauvegarder audio temporaire  
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                import soundfile as sf
                sf.write(tmp.name, audio_data, 16000)
                
                with sr.AudioFile(tmp.name) as source:
                    audio = r.record(source)
                
                text = r.recognize_google(audio, language='fr-FR')
                os.unlink(tmp.name)
                return text
                
        except ImportError:
            if not test:
                print("üí° Installez: pip install SpeechRecognition soundfile")
            return None
        except Exception as e:
            if not test:
                print(f"Erreur Google: {e}")
            return None
    
    async def _edge_transcribe(self, audio_data, test=False):
        """Transcription via Azure Speech (si disponible)"""
        try:
            import azure.cognitiveservices.speech as speechsdk
            
            if test:
                return True
            
            # Note: N√©cessite une cl√© API Azure
            print("üí° Transcription Azure n√©cessite une cl√© API")
            return None
            
        except ImportError:
            return None
    
    async def _manual_mode(self, audio_data, test=False):
        """Mode manuel - guide l'utilisateur"""
        if test:
            return True
            
        print("üí° Mode manuel activ√©:")
        print("   1. Audio captur√© - utilisez Win+H pour la dict√©e Windows")
        print("   2. Ou tapez manuellement votre texte")
        print("   3. Appuyez sur Entr√©e quand termin√©")
        
        # Demander texte manuel
        try:
            text = input("üìù Votre texte: ")
            return text if text.strip() else None
        except:
            return None
    
    async def toggle_dictation(self):
        """Bascule entre d√©marrer/arr√™ter la dict√©e"""
        if self.recording:
            await self.stop_dictation()
        else:
            await self.start_dictation()
    
    async def change_method(self):
        """Change la m√©thode de reconnaissance"""
        print("\nüîÑ Changement de m√©thode...")
        # Trouver la prochaine m√©thode disponible
        current_index = next((i for i, (name, _) in enumerate(self.methods) 
                            if name == self.current_method[0]), -1)
        
        # Essayer les m√©thodes suivantes
        for i in range(len(self.methods)):
            next_index = (current_index + 1 + i) % len(self.methods)
            name, method = self.methods[next_index]
            
            if await self._test_method(method):
                self.current_method = (name, method)
                print(f"‚úÖ M√©thode chang√©e: {name}")
                return
        
        print("‚ö†Ô∏è Aucune autre m√©thode disponible")
    
    def setup_hotkeys(self):
        """Configure les raccourcis clavier"""
        # Ctrl+Shift+V pour basculer la dict√©e
        keyboard.add_hotkey('ctrl+shift+v', 
                          lambda: asyncio.create_task(self.toggle_dictation()))
        
        # Ctrl+Shift+M pour changer de m√©thode
        keyboard.add_hotkey('ctrl+shift+m',
                          lambda: asyncio.create_task(self.change_method()))
        
        # Ctrl+Shift+Q pour quitter
        keyboard.add_hotkey('ctrl+shift+q', self.shutdown)
    
    async def run(self):
        """Boucle principale de l'assistant"""
        await self.initialize()
        self.setup_hotkeys()
        
        try:
            print("üéØ Assistant vocal actif - Pr√™t √† dicter dans Cursor!")
            print("üí° Placez votre curseur dans Cursor avant de dicter")
            
            # Boucle d'attente
            while True:
                await asyncio.sleep(0.1)
                
        except KeyboardInterrupt:
            pass
        finally:
            await self.shutdown()
    
    async def shutdown(self):
        """Ferme proprement l'assistant"""
        print("\nüõë Arr√™t de l'assistant vocal...")
        
        self.recording = False
        
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        
        self.audio.terminate()
        
        print("üëã Au revoir !")
        exit(0)

async def main():
    """Point d'entr√©e principal"""
    assistant = SimpleCursorVoiceAssistant()
    await assistant.run()

if __name__ == "__main__":
    print("üöÄ Lancement de l'assistant vocal simple pour Cursor...")
    asyncio.run(main()) 