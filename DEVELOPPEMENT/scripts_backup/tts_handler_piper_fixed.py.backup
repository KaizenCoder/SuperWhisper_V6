# TTS/tts_handler_piper_fixed.py
import os
import json
import numpy as np
import sounddevice as sd
import soundfile as sf
import onnxruntime

# Configuration RTX 3090 OBLIGATOIRE
os.environ['CUDA_VISIBLE_DEVICES'] = '1'  # RTX 3090 24GB
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'

class TTSHandlerPiperFixed:
    def __init__(self, config):
        self.config = config
        
        # Chemins mod√®le
        self.model_path = config.get('model_path', 'D:\\TTS_Voices\\piper\\fr_FR-siwis-medium.onnx')
        self.config_path = config.get('config_path', 'D:\\TTS_Voices\\piper\\fr_FR-siwis-medium.onnx.json')
        self.use_gpu = config.get('use_gpu', True)
        self.sample_rate = config.get('sample_rate', 22050)
        
        # Charger la configuration du mod√®le
        self._load_model_config()
        
        # Charger le mod√®le ONNX
        self._load_model()
        
    def _load_model_config(self):
        """Charger la configuration JSON du mod√®le Piper"""
        print(f"üìÑ Chargement config: {self.config_path}")
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            self.model_config = json.load(f)
            
        # Extraire les param√®tres
        audio_config = self.model_config.get('audio', {})
        self.sample_rate = audio_config.get('sample_rate', 22050)
        
        inference_config = self.model_config.get('inference', {})
        self.noise_scale = inference_config.get('noise_scale', 0.667)
        self.length_scale = inference_config.get('length_scale', 1.0)
        self.noise_w = inference_config.get('noise_w', 0.8)
        
        # Mapping phon√®me ‚Üí ID
        self.phoneme_id_map = self.model_config.get('phoneme_id_map', {})
        
        print(f"‚úÖ Config charg√©e: {len(self.phoneme_id_map)} phon√®mes")
        print(f"   Sample rate: {self.sample_rate}Hz")
        print(f"   Param√®tres: noise={self.noise_scale}, length={self.length_scale}, noise_w={self.noise_w}")
        
    def _load_model(self):
        """Charger le mod√®le ONNX avec RTX 3090"""
        print(f"üîÑ Chargement mod√®le RTX 3090: {self.model_path}")
        
        # Ajout des DLLs CUDA au PATH
        torch_lib_path = os.path.join(os.getcwd(), 'venv_piper312', 'Lib', 'site-packages', 'torch', 'lib')
        if os.path.exists(torch_lib_path):
            current_path = os.environ.get('PATH', '')
            if torch_lib_path not in current_path:
                os.environ['PATH'] = current_path + os.pathsep + torch_lib_path
        
        # Providers optimis√©s RTX 3090
        providers = []
        if self.use_gpu:
            providers.append(('CUDAExecutionProvider', {
                'device_id': 0,
                'arena_extend_strategy': 'kNextPowerOfTwo',
                'gpu_mem_limit': 8 * 1024 * 1024 * 1024,  # 8GB
                'cudnn_conv_algo_search': 'EXHAUSTIVE',
                'do_copy_in_default_stream': True,
            }))
        providers.append('CPUExecutionProvider')
        
        # Cr√©er session ONNX
        self.session = onnxruntime.InferenceSession(self.model_path, providers=providers)
        
        # V√©rifier providers
        current_providers = self.session.get_providers()
        print(f"üöÄ Providers: {current_providers}")
        
        if 'CUDAExecutionProvider' in current_providers:
            print("‚úÖ RTX 3090 CUDA activ√©")
        else:
            print("‚ö†Ô∏è Fallback CPU")
            
        # M√©tadonn√©es mod√®le
        self.model_inputs = [inp.name for inp in self.session.get_inputs()]
        self.model_outputs = [out.name for out in self.session.get_outputs()]
        
    def text_to_phonemes_simple(self, text):
        """Conversion texte ‚Üí phon√®mes simplifi√©e (pour test rapide)"""
        # Version simple sans espeak-ng pour test imm√©diat
        # Utilise un mapping basique mais avec les vrais IDs du mod√®le
        
        # Mapping simple fran√ßais 
        simple_mapping = {
            'b': 'b', 'o': 'o', 'n': 'n', 'j': 'j', 'u': 'u', 'r': 'r',
            's': 's', 'a': 'a', 'l': 'l', 't': 't', ' ': ' ', '!': '!',
            ',': ',', 'c': 'k', 'e': 'e', 'i': 'i', 'v': 'v', 'z': 'z',
            'm': 'm', '√†': 'a', '√©': 'e', '√®': '…õ', '√™': '…õ', '√ß': 's',
            'p': 'p', 'g': 'g', 'f': 'f', 'h': 'h', 'd': 'd', 'x': 'ks',
            'y': 'i', 'w': 'w', 'q': 'k', '.': '.', '?': '?', ':': ':'
        }
        
        phoneme_ids = []
        
        # Ajouter marqueur d√©but
        if "^" in self.phoneme_id_map:
            phoneme_ids.extend(self.phoneme_id_map["^"])
            
        # Convertir chaque caract√®re
        for char in text.lower():
            mapped_char = simple_mapping.get(char, char)
            
            if mapped_char in self.phoneme_id_map:
                phoneme_ids.extend(self.phoneme_id_map[mapped_char])
            elif ' ' in self.phoneme_id_map:
                phoneme_ids.extend(self.phoneme_id_map[' '])  # Espace par d√©faut
                
        # Ajouter marqueur fin
        if "$" in self.phoneme_id_map:
            phoneme_ids.extend(self.phoneme_id_map["$"])
            
        return phoneme_ids
        
    def synthesize(self, text):
        """Synth√®se vocale RTX 3090 avec vraie phon√©misation"""
        print(f"üîä Synth√®se Piper FIX√âE (RTX 3090)")
        print(f"   Texte: '{text}'")
        
        try:
            # 1. Conversion texte ‚Üí phon√®mes
            phoneme_ids = self.text_to_phonemes_simple(text)
            print(f"   üìù Phon√®mes: {len(phoneme_ids)} IDs - {phoneme_ids[:10]}...")
            
            # 2. Pr√©paration inputs ONNX
            input_ids = np.array([phoneme_ids], dtype=np.int64)
            input_lengths = np.array([len(phoneme_ids)], dtype=np.int64)
            scales = np.array([self.noise_scale, self.length_scale, self.noise_w], dtype=np.float32)
            
            # 3. Inf√©rence RTX 3090
            onnx_inputs = {
                'input': input_ids,
                'input_lengths': input_lengths,
                'scales': scales
            }
            
            outputs = self.session.run(None, onnx_inputs)
            audio_data = outputs[0]
            
            # 4. Post-processing
            audio_data = np.squeeze(audio_data)
            
            print(f"   üéµ Audio g√©n√©r√©: {audio_data.shape} √©chantillons")
            print(f"   üîç Range audio: [{audio_data.min():.3f}, {audio_data.max():.3f}]")
            
            # V√©rifier si audio contient du son
            if abs(audio_data.max()) < 0.001 and abs(audio_data.min()) < 0.001:
                print(f"   ‚ö†Ô∏è ATTENTION: Audio tr√®s faible, possible probl√®me phon√©misation")
            
            # Conversion pour lecture
            audio_int16 = (audio_data * 32767).clip(-32767, 32767).astype(np.int16)
            
            return audio_int16
            
        except Exception as e:
            print(f"‚ùå Erreur synth√®se: {e}")
            import traceback
            traceback.print_exc()
            return np.array([], dtype=np.int16)
    
    def speak(self, text):
        """Synth√®se et lecture audio RTX 3090"""
        audio_data = self.synthesize(text)
        
        if len(audio_data) > 0:
            print(f"   üîä Lecture audio...")
            sd.play(audio_data, samplerate=self.sample_rate)
            sd.wait()
            print(f"   ‚úÖ Lecture termin√©e")
        else:
            print(f"   ‚ùå Pas d'audio √† lire")
            
        return audio_data 