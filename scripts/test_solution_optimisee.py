#!/usr/bin/env python3
"""
Test Rapide - Solution STT Optimis√©e
üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
Test minimal pour validation avant benchmark complet

üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# üöÄ PORTABILIT√â AUTOMATIQUE - EX√âCUTABLE DEPUIS N'IMPORTE O√ô
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour ex√©cution portable"""
    # D√©terminer le r√©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le r√©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
    print(f"üìÅ Project Root: {project_root}")
    print(f"üíª Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
sys.path.insert(0, project_root)

import asyncio
import time
import numpy as np
import torch
from pathlib import Path

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    if not torch.cuda.is_available():
        raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 = ~24GB
        raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
    
    gpu_name = torch.cuda.get_device_name(0)
    print(f"‚úÖ RTX 3090 valid√©e: {gpu_name} ({gpu_memory:.1f}GB)")

def test_post_processor():
    """Test du post-processeur avec exemples r√©els"""
    print("\nüß™ TEST POST-PROCESSEUR")
    print("-" * 40)
    
    try:
        from STT.stt_postprocessor import STTPostProcessor
        
        processor = STTPostProcessor()
        
        # Exemples de transcriptions avec erreurs
        test_cases = [
            {
                "original": "super whispers utilise after whisper sur gpu rtx",
                "expected_improvements": ["SuperWhisper", "faster-whisper", "GPU", "RTX"]
            },
            {
                "original": "char √† la maison cr√©sentemps agorique",
                "expected_improvements": ["chat,", "chrysanth√®me", "algorithme"]
            },
            {
                "original": "sacrement modification dixi√®mement",
                "expected_improvements": ["cinqui√®mement", "sixi√®mement"]
            },
            {
                "original": "la tige artificielle dans le monde monarme",
                "expected_improvements": ["l'intelligence artificielle", "monde moderne"]
            }
        ]
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\n{i}. Test: '{test_case['original']}'")
            
            processed, metrics = processor.process(test_case['original'], 0.8)
            
            print(f"   R√©sultat: '{processed}'")
            print(f"   Corrections: {metrics['corrections_applied']}")
            print(f"   Boost confiance: +{metrics['confidence_boost']:.3f}")
            
            # V√©rification am√©liorations
            improvements_found = 0
            for expected in test_case['expected_improvements']:
                if expected.lower() in processed.lower():
                    improvements_found += 1
            
            success_rate = improvements_found / len(test_case['expected_improvements']) * 100
            print(f"   Am√©liorations: {improvements_found}/{len(test_case['expected_improvements'])} ({success_rate:.0f}%)")
            
            if success_rate >= 50:
                print("   ‚úÖ SUCC√àS")
            else:
                print("   ‚ö†Ô∏è PARTIEL")
        
        # Statistiques globales
        print(f"\nüìä Statistiques Post-Processeur:")
        stats = processor.get_statistics()
        for key, value in stats.items():
            if isinstance(value, dict):
                print(f"   {key}:")
                for subkey, subvalue in value.items():
                    print(f"     {subkey}: {subvalue}")
            else:
                print(f"   {key}: {value}")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Import Post-Processeur √©chou√©: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Erreur test post-processeur: {e}")
        return False

async def test_manager_optimise():
    """Test du manager optimis√© (si possible)"""
    print("\nüß† TEST MANAGER OPTIMIS√â")
    print("-" * 40)
    
    try:
        from STT.unified_stt_manager_optimized import OptimizedUnifiedSTTManager
        
        config = {
            'model': 'large-v2',
            'compute_type': 'float16'
        }
        
        print("üöÄ Initialisation manager optimis√©...")
        manager = OptimizedUnifiedSTTManager(config)
        
        # Test d'initialisation seulement (pas de transcription compl√®te)
        print("‚úÖ Manager cr√©√© avec succ√®s")
        print("‚ö†Ô∏è Test transcription n√©cessite faster-whisper install√©")
        
        return True
        
    except ImportError as e:
        print(f"‚ö†Ô∏è Import Manager Optimis√© √©chou√©: {e}")
        print("   (Normal si faster-whisper non install√©)")
        return False
    except Exception as e:
        print(f"‚ùå Erreur test manager: {e}")
        return False

def test_backend_optimise():
    """Test du backend optimis√© (si possible)"""
    print("\n‚öôÔ∏è TEST BACKEND OPTIMIS√â")
    print("-" * 40)
    
    try:
        from STT.backends.prism_stt_backend_optimized import OptimizedPrismSTTBackend
        
        config = {
            'model': 'large-v2',
            'compute_type': 'float16'
        }
        
        print("üöÄ Initialisation backend optimis√©...")
        print("‚ö†Ô∏è Test complet n√©cessite faster-whisper install√©")
        print("‚úÖ Import backend r√©ussi")
        
        return True
        
    except ImportError as e:
        print(f"‚ö†Ô∏è Import Backend Optimis√© √©chou√©: {e}")
        print("   (Normal si faster-whisper non install√©)")
        return False
    except Exception as e:
        print(f"‚ùå Erreur test backend: {e}")
        return False

async def main():
    """Test principal de la solution optimis√©e"""
    print("üéØ TEST SOLUTION STT OPTIMIS√âE - SUPERWHISPER V6")
    print("üö® GPU RTX 3090 OBLIGATOIRE")
    print("=" * 60)
    
    try:
        # 1. Validation GPU
        validate_rtx3090_configuration()
        
        # 2. Test post-processeur (critique)
        postproc_ok = test_post_processor()
        
        # 3. Test manager optimis√©
        manager_ok = await test_manager_optimise()
        
        # 4. Test backend optimis√©
        backend_ok = test_backend_optimise()
        
        # 5. R√©sum√©
        print("\n" + "="*60)
        print("üìä R√âSUM√â TEST SOLUTION OPTIMIS√âE")
        print("="*60)
        
        print(f"‚úÖ GPU RTX 3090: Valid√©e")
        print(f"{'‚úÖ' if postproc_ok else '‚ùå'} Post-Processeur: {'Fonctionnel' if postproc_ok else '√âchou√©'}")
        print(f"{'‚úÖ' if manager_ok else '‚ö†Ô∏è'} Manager Optimis√©: {'Fonctionnel' if manager_ok else 'Import requis'}")
        print(f"{'‚úÖ' if backend_ok else '‚ö†Ô∏è'} Backend Optimis√©: {'Fonctionnel' if backend_ok else 'Import requis'}")
        
        if postproc_ok and manager_ok and backend_ok:
            print("\nüéâ SOLUTION OPTIMIS√âE PR√äTE!")
            print("   ‚Üí Lancer benchmark complet: python scripts/benchmark_optimized_stt.py")
        elif postproc_ok:
            print("\n‚ö†Ô∏è D√âPENDANCES REQUISES")
            print("   ‚Üí Installer faster-whisper pour tests complets")
            print("   ‚Üí Post-processeur valid√© et fonctionnel")
        else:
            print("\n‚ùå PROBL√àME CRITIQUE")
            print("   ‚Üí V√©rifier imports et structure fichiers")
        
        return postproc_ok
        
    except Exception as e:
        print(f"\n‚ùå Erreur test solution: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # Ex√©cution test
    success = asyncio.run(main())
    
    if success:
        print(f"\n‚úÖ Test termin√© avec succ√®s")
    else:
        print(f"\n‚ùå Test √©chou√©") 