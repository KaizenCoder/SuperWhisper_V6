# ğŸ¯ PROMPT MAÃTRE - HOMOGÃ‰NISATION GPU SUPERWHISPER V6

**Mission :** Corriger la mÃ©thodologie de sÃ©lection et contrÃ´le GPU non homogÃ¨ne dans SuperWhisper V6  
**CriticitÃ© :** MAXIMALE - Impact direct sur performance et stabilitÃ© systÃ¨me  
**RÃ©sultat attendu :** 40 fichiers corrigÃ©s avec validation factuelle intÃ©grale et zÃ©ro rÃ©gression  

---

## ğŸª CONTEXTE CRITIQUE DE LA MISSION

### ProblÃ©matique IdentifiÃ©e
Le projet SuperWhisper V6 prÃ©sente une **mÃ©thodologie de sÃ©lection et contrÃ´le GPU non homogÃ¨ne** qui gÃ©nÃ¨re :
- **Risques de performance** : Utilisation accidentelle RTX 5060 Ti (16GB) au lieu de RTX 3090 (24GB)
- **InstabilitÃ© systÃ¨me** : Mappings GPU incohÃ©rents entre modules
- **Erreurs silencieuses** : Absence de validation systÃ©matique du GPU utilisÃ©

### Configuration MatÃ©rielle CRITIQUE
```
ğŸ® Configuration physique du systÃ¨me :
- GPU Bus PCI 0 : RTX 5060 Ti (16GB) âŒ STRICTEMENT INTERDITE
- GPU Bus PCI 1 : RTX 3090 (24GB) âœ… SEULE GPU AUTORISÃ‰E

âš ï¸ ATTENTION : PyTorch ordonne les GPU diffÃ©remment sans CUDA_DEVICE_ORDER='PCI_BUS_ID'
```

### DÃ©couverte Factuelle
**40 scripts identifiÃ©s** nÃ©cessitent une homogÃ©nÃ©isation :
- **Configuration requise** : 
  ```python
  os.environ['CUDA_VISIBLE_DEVICES'] = '1'  # SÃ©lectionne RTX 3090 sur bus PCI 1
  os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Force l'ordre physique
  ```
- **AprÃ¨s cette configuration** : `cuda:0` dans le code = RTX 3090 (remapping PyTorch)

---

## ğŸ¯ COMPRÃ‰HENSION FACTUELLE CONFIRMÃ‰E

### **Configuration Physique RÃ©elle ValidÃ©e :**
```bash
nvidia-smi --query-gpu=index,name,memory.total --format=csv
GPU 0: NVIDIA GeForce RTX 5060 Ti (16311 MiB = ~16GB) âŒ INTERDITE
GPU 1: NVIDIA GeForce RTX 3090 (24576 MiB = ~24GB)    âœ… CIBLE
```

### **Logique CUDA_VISIBLE_DEVICES ConfirmÃ©e :**
1. **`CUDA_VISIBLE_DEVICES='1'`** = Rendre visible UNIQUEMENT le GPU physique 1 (RTX 3090)
2. **PyTorch remapping automatique** = Le seul GPU visible devient `cuda:0` dans le code
3. **RÃ©sultat final** = `cuda:0` dans PyTorch pointe vers RTX 3090 âœ…
4. **RTX 5060 Ti devient inaccessible** = Aucun risque d'utilisation accidentelle

### **Validation Obligatoire avec Script de Diagnostic :**
```python
# Utiliser OBLIGATOIREMENT ce script pour validation :
python "C:\Dev\SuperWhisper_V6\test_diagnostic_rtx3090.py"

# Le script DOIT confirmer :
# âœ… CUDA_VISIBLE_DEVICES='1' configurÃ©
# âœ… GPU 0 (aprÃ¨s mapping) = RTX 3090 24GB
# âœ… RTX 5060 Ti invisible/inaccessible
# âœ… Configuration fonctionnelle validÃ©e
```

### **Points Critiques de ComprÃ©hension :**
- **CUDA_VISIBLE_DEVICES='1'** ne change PAS l'ordre, il MASQUE le GPU 0
- **PyTorch voit 1 seul GPU** (RTX 3090) qu'il nomme automatiquement `cuda:0`
- **Le code utilise `cuda:0`** qui pointe maintenant vers RTX 3090
- **Aucune confusion possible** : RTX 5060 Ti est complÃ¨tement invisible

---

## ğŸ¯ OBJECTIF DE LA MISSION

**HomogÃ©nÃ©iser et sÃ©curiser la sÃ©lection GPU** dans tous les scripts identifiÃ©s pour garantir l'utilisation exclusive de la RTX 3090, avec :
1. **Ajout de la configuration environnement complÃ¨te** dans chaque fichier
2. **Utilisation cohÃ©rente de `cuda:0`** dans le code (qui pointera vers RTX 3090)
3. **Validation factuelle obligatoire** pour chaque correction
4. **PrÃ©servation intÃ©grale** des fonctionnalitÃ©s (zÃ©ro rÃ©gression)
5. **Standardisation de la mÃ©thodologie** pour dÃ©veloppements futurs

---

## ğŸš€ NOUVELLES OPTIMISATIONS VALIDÃ‰ES

### Memory Leak Solution V4.0 - OBLIGATOIRE
- **Script central** : `memory_leak_v4.py` (solution finalisÃ©e)
- **Cleanup automatique** pour tous tests GPU avec context manager
- **Monitoring temps rÃ©el** : mÃ©moire, fragmentation, performance
- **Queue GPU exclusive** pour parallÃ©lisation sÃ©curisÃ©e
- **MÃ©triques Prometheus** intÃ©grÃ©es pour monitoring

### ParallÃ©lisation ValidÃ©e - 64% GAIN PERFORMANCE
- **Configuration systÃ¨me validÃ©e** : 64GB RAM + 20 CPU threads + RTX 3090
- **Gain performance confirmÃ©** : 33h â†’ 12-16h (64% plus rapide)
- **Architecture Ã©prouvÃ©e** : ThreadPool + GPU Queue + Memory Management automatique
- **Tests validÃ©s** : 10/10 stress tests rÃ©ussis, 0% memory leak dÃ©tectÃ©

### Integration Workflow Memory Leak Prevention
1. **Utiliser `@gpu_test_cleanup()`** pour TOUS les tests GPU
2. **Queue GPU exclusive** avec sÃ©maphore multiprocess
3. **Memory monitoring automatique** avec seuils paramÃ©trables
4. **Fallback sÃ©quentiel** en cas d'instabilitÃ© parallÃ©lisation
5. **Logs JSON** avec rollover automatique pour audit
6. **Emergency reset** automatique si memory leak critique

### Configuration Memory Management
```python
# Import obligatoire pour tous fichiers avec GPU
from memory_leak_v4 import gpu_test_cleanup, validate_no_memory_leak

# DÃ©corateur obligatoire pour TOUS tests GPU
@gpu_test_cleanup("nom_test_descriptif")
def your_gpu_test_function():
    device = "cuda:0"  # RTX 3090 aprÃ¨s mapping
    # Votre code GPU ici
    # Cleanup automatique Ã  la fin du context

# Validation obligatoire en fin de script
if __name__ == "__main__":
    validate_rtx3090_mandatory()  # Validation GPU
    # Tests...
    validate_no_memory_leak()     # Validation memory leak
```

### ParallÃ©lisation Architecture
- **Phase 2 + 3** : 13 modules core + 27 scripts test = **PARALLÃ‰LISABLES**
- **Queue GPU exclusive** : Un seul script accÃ¨de GPU Ã  la fois
- **Memory cleanup** : Automatique entre chaque script
- **Git branches** : DÃ©diÃ©es par thread pour Ã©viter conflits
- **Monitoring centralisÃ©** : MÃ©triques temps rÃ©el via Prometheus
- **Recovery automatique** : Emergency reset si memory leak dÃ©tectÃ©

---

## ğŸ› ï¸ OUTILS ET TECHNOLOGIES Ã€ UTILISER

### Outils de DÃ©veloppement
- **Git** : Versioning et rollback sÃ©curisÃ© (branche dÃ©diÃ©e obligatoire)
- **Python 3.8+** : Langage principal pour corrections et validations
- **PyTorch** : Validation GPU et dÃ©tection matÃ©riel
- **PowerShell 7+** : Automation scripts Windows
- **Cursor/VS Code** : Ã‰dition de code

### BibliothÃ¨ques Python Requises
```python
import os
import torch
import time
import psutil
from pathlib import Path
import unittest
```

### Outils de Validation
- **Scripts de test personnalisÃ©s** par fichier
- **nvidia-smi** : Monitoring GPU
- **memory_profiler** : Validation mÃ©moire
- **Benchmarks comparatifs** performance

---

## ğŸ“‹ LISTE EXHAUSTIVE DES FICHIERS Ã€ CORRIGER (40)

### Modules Core Critiques Initiaux (7)
```
ğŸ“ benchmarks/benchmark_stt_realistic.py
ğŸ“ LLM/llm_manager_enhanced.py
ğŸ“ LUXA_TTS/tts_handler_coqui.py
ğŸ“ Orchestrator/fallback_manager.py
ğŸ“ STT/vad_manager_optimized.py
ğŸ“ TTS/tts_handler_coqui.py
ğŸ“ TTS/tts_handler_piper_native.py
```

### Modules Core SupplÃ©mentaires (6)
```
ğŸ“ STT/stt_manager_robust.py
ğŸ“ STT/vad_manager.py
ğŸ“ TTS/tts_handler_piper_espeak.py
ğŸ“ TTS/tts_handler_piper_fixed.py
ğŸ“ TTS/tts_handler_piper_french.py
ğŸ“ utils/gpu_manager.py
```

### Scripts de Test Initiaux (13)
```
ğŸ“ tests/test_double_check_corrections.py
ğŸ“ tests/test_double_check_validation_simple.py
ğŸ“ test_cuda_debug.py
ğŸ“ test_cuda.py
ğŸ“ test_espeak_french.py
ğŸ“ test_french_voice.py
ğŸ“ test_gpu_correct.py
ğŸ“ test_piper_native.py
ğŸ“ test_tts_fixed.py
ğŸ“ test_tts_long_feedback.py
ğŸ“ test_upmc_model.py
ğŸ“ test_validation_decouverte.py
ğŸ“ TTS/tts_handler_piper_rtx3090.py
```

### Tests SupplÃ©mentaires (2)
```
ğŸ“ tests/test_llm_handler.py
ğŸ“ tests/test_stt_handler.py
```

### Scripts de Validation Exhaustifs (12)
```
ğŸ“ test_correction_validation_1.py
ğŸ“ test_correction_validation_2.py
ğŸ“ test_correction_validation_3.py
ğŸ“ test_correction_validation_4.py
ğŸ“ test_rtx3090_detection.py
ğŸ“ test_tts_rtx3090_performance.py
ğŸ“ test_validation_globale_finale.py
ğŸ“ test_validation_mvp_settings.py
ğŸ“ test_validation_rtx3090_detection.py
ğŸ“ test_validation_stt_manager_robust.py
ğŸ“ test_validation_tts_performance.py
ğŸ“ validate_gpu_config.py
```

---

## ğŸ”§ TEMPLATE DE CORRECTION OBLIGATOIRE V2.0 [avec Memory Leak V4.0]

### Configuration GPU + Memory Management - Ã€ INTÃ‰GRER DANS CHAQUE SCRIPT
```python
#!/usr/bin/env python3
"""
[Description du script]
ğŸš¨ CONFIGURATION GPU: RTX 3090 (CUDA:0) + Memory Leak Prevention V4.0 OBLIGATOIRE
"""

import os
import sys

# =============================================================================
# ğŸš¨ CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
# RTX 3090 (Bus PCI 1) = SEULE AUTORISÃ‰E - RTX 5060 Ti (Bus PCI 0) = INTERDITE
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB sur Bus PCI 1
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Force l'ordre du bus physique
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation mÃ©moire

print("ğŸ® GPU Configuration: RTX 3090 (CUDA:0 aprÃ¨s mapping)")
print(f"ğŸ”’ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")
print(f"ğŸ”’ CUDA_DEVICE_ORDER: {os.environ.get('CUDA_DEVICE_ORDER')}")

# =============================================================================
# ğŸš¨ MEMORY LEAK PREVENTION V4.0 - OBLIGATOIRE 
# =============================================================================
# Import du systÃ¨me de prÃ©vention memory leak validÃ©
try:
    from memory_leak_v4 import (
        configure_for_environment, 
        gpu_test_cleanup, 
        validate_no_memory_leak,
        emergency_gpu_reset
    )
    # Configuration environnement (dev/ci/production)
    configure_for_environment("dev")  # Adapter selon contexte
    print("âœ… Memory Leak Prevention V4.0 activÃ©")
except ImportError:
    print("âš ï¸ Memory Leak V4.0 non disponible - Continuer avec validation standard")
    gpu_test_cleanup = lambda name: lambda func: func  # Fallback

# Maintenant imports normaux...
import torch
# ... autres imports
```

### Fonction de Validation OBLIGATOIRE
```python
def validate_rtx3090_mandatory():
    """Validation systÃ©matique RTX 3090 - OBLIGATOIRE dans chaque script"""
    if not torch.cuda.is_available():
        raise RuntimeError("ğŸš« CUDA non disponible - RTX 3090 requise")
    
    # CONTRÃ”LE 1: Variables environnement
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    cuda_order = os.environ.get('CUDA_DEVICE_ORDER', '')
    
    if cuda_devices != '1':
        raise RuntimeError(f"ğŸš« CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit Ãªtre '1'")
    
    if cuda_order != 'PCI_BUS_ID':
        raise RuntimeError(f"ğŸš« CUDA_DEVICE_ORDER='{cuda_order}' incorrect - doit Ãªtre 'PCI_BUS_ID'")
    
    # CONTRÃ”LE 2: GPU physique dÃ©tectÃ© (aprÃ¨s mapping, cuda:0 = RTX 3090)
    gpu_name = torch.cuda.get_device_name(0)
    if "RTX 3090" not in gpu_name:
        raise RuntimeError(f"ğŸš« GPU dÃ©tectÃ©: {gpu_name} - RTX 3090 requise")
    
    # CONTRÃ”LE 3: MÃ©moire GPU
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 â‰ˆ 24GB
        raise RuntimeError(f"ğŸš« GPU ({gpu_memory:.1f}GB) insuffisante - RTX 3090 requise")
    
    print(f"âœ… RTX 3090 validÃ©e: {gpu_name} ({gpu_memory:.1f}GB)")

# APPELER OBLIGATOIREMENT dans __main__ ou au dÃ©but du script
if __name__ == "__main__":
    validate_rtx3090_mandatory()
```

---

## ğŸ”¬ MÃ‰THODOLOGIE DE CORRECTION - ENSEIGNEMENTS CRITIQUES

### LEÃ‡ON MAÃTRESSE : VALIDATION FACTUELLE OBLIGATOIRE
**âŒ ERREUR Ã€ Ã‰VITER :** Assumer que la configuration est correcte  
**âœ… MÃ‰THODE CORRECTE :** ContrÃ´ler factuellement Ã  chaque Ã©tape

### Processus de Correction par Fichier (50min/fichier core, 30min/test)

#### Ã‰tape 1 : PrÃ©paration (10min)
```bash
# Sauvegarder version originale
cp [fichier] docs/gpu-correction/backups/[fichier].backup

# Analyser le fichier
grep -n "cuda" [fichier]
grep -n "CUDA_VISIBLE_DEVICES" [fichier]
grep -n "CUDA_DEVICE_ORDER" [fichier]
grep -n "device" [fichier]
```

#### Ã‰tape 2 : Correction Configuration GPU (15min)
```python
# AJOUTS/MODIFICATIONS STANDARDS
# 1. Ajouter en dÃ©but de fichier (aprÃ¨s shebang et docstring) :
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'

# 2. Dans le code, utiliser :
device = "cuda:0"  # ou "cuda" (Ã©quivalent aprÃ¨s mapping)
torch.device("cuda:0")
torch.cuda.set_device(0)
device_map={"": 0}
gpu_device_index: 0
```

#### Ã‰tape 3 : Validation Factuelle OBLIGATOIRE (15min)
```python
def test_fichier_correction():
    """Test factuel - AUCUNE ASSOMPTION AUTORISÃ‰E"""
    
    # TEST 0: Script diagnostic OBLIGATOIRE POUR CHAQUE FICHIER
    import subprocess
    print("ğŸ” DIAGNOSTIC RTX 3090 POUR CE FICHIER:")
    result = subprocess.run([
        "python", "C:\\Dev\\SuperWhisper_V6\\test_diagnostic_rtx3090.py"
    ], capture_output=True, text=True)
    
    print(result.stdout)
    assert result.returncode == 0, "Ã‰CHEC: Script diagnostic RTX 3090"
    assert "RTX 3090 dÃ©tectÃ©: âœ… OUI" in result.stdout, "Ã‰CHEC: RTX 3090 non dÃ©tectÃ©e"
    print("âœ… Script diagnostic RTX 3090 validÃ© pour ce fichier")
    
    # TEST 1: Configuration environnement
    cuda_env = os.environ.get('CUDA_VISIBLE_DEVICES')
    cuda_order = os.environ.get('CUDA_DEVICE_ORDER')
    assert cuda_env == '1', f"Ã‰CHEC: CUDA_VISIBLE_DEVICES='{cuda_env}' au lieu de '1'"
    assert cuda_order == 'PCI_BUS_ID', f"Ã‰CHEC: CUDA_DEVICE_ORDER='{cuda_order}' au lieu de 'PCI_BUS_ID'"
    
    # TEST 2: GPU physique dÃ©tectÃ©
    gpu_name = torch.cuda.get_device_name(0)
    assert "RTX 3090" in gpu_name, f"Ã‰CHEC: GPU dÃ©tectÃ© '{gpu_name}' au lieu de RTX 3090"
    
    # TEST 3: MÃ©moire GPU
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    assert gpu_memory > 20, f"Ã‰CHEC: GPU {gpu_memory:.1f}GB au lieu de ~24GB"
    
    print(f"âœ… Configuration GPU validÃ©e: {gpu_name} ({gpu_memory:.1f}GB)")
```

#### Ã‰tape 4 : Test FonctionnalitÃ© IntÃ©grale (10min)
```python
def test_fonctionnalite_integrale():
    """Test TOUTES les fonctionnalitÃ©s - ZÃ‰RO RÃ‰GRESSION AUTORISÃ‰E"""
    
    # Importer le module corrigÃ©
    import [module_corrigÃ©]
    
    # Tester toutes les classes
    for classe in [module_corrigÃ©].get_classes():
        instance = classe()
        # Validation constructeur, mÃ©thodes, propriÃ©tÃ©s
    
    # Tester toutes les fonctions
    for fonction in [module_corrigÃ©].get_functions():
        # Validation avec paramÃ¨tres rÃ©els
        # Comparaison sorties avec version originale
    
    # Test performance (pas de rÃ©gression > 2%)
    performance_actuelle = benchmark_fonction()
    assert performance_actuelle >= performance_reference * 0.98
    
    print("âœ… Toutes fonctionnalitÃ©s validÃ©es - aucune rÃ©gression")
```

---

## âš ï¸ CRITÃˆRES D'ACCEPTATION STRICTS

### âœ… Correction VALIDÃ‰E UNIQUEMENT Si
1. **Configuration GPU complÃ¨te** : CUDA_VISIBLE_DEVICES='1' ET CUDA_DEVICE_ORDER='PCI_BUS_ID'
2. **RTX 3090 dÃ©tectÃ©e et utilisÃ©e** : Validation factuelle obligatoire
3. **100% des fonctionnalitÃ©s opÃ©rationnelles** : aucune rÃ©gression autorisÃ©e
4. **Performance maintenue** : identique ou amÃ©liorÃ©e (Â±2% maximum)
5. **Tests automatisÃ©s** : 100% passent
6. **Documentation** : rapport de correction complet

### âŒ Correction REJETÃ‰E Si
- **Configuration incomplÃ¨te** (manque CUDA_DEVICE_ORDER)
- **Une seule fonction** dÃ©faillante
- **RÃ©gression de performance** dÃ©tectÃ©e (>2%)
- **Validation GPU** Ã©choue
- **Tests automatisÃ©s** en Ã©chec
- **Comportement modifiÃ©** vs original

---

## ğŸ” TEMPLATES DE VALIDATION PAR TYPE DE FICHIER

### Pour Modules STT/VAD
```python
def test_stt_vad_module():
    # DIAGNOSTIC RTX 3090 OBLIGATOIRE
    import subprocess
    result = subprocess.run([
        "python", "C:\\Dev\\SuperWhisper_V6\\test_diagnostic_rtx3090.py"
    ], capture_output=True, text=True)
    assert result.returncode == 0, "Script diagnostic RTX 3090 Ã©chouÃ©"
    print("âœ… Diagnostic RTX 3090 validÃ© pour module STT/VAD")
    
    validate_rtx3090_mandatory()
    
    # Test spÃ©cifique STT/VAD
    vad = VADManager()
    result = vad.detect_speech(test_audio)
    assert result is not None
    assert result.confidence > 0.8
    
    # Test performance
    start = time.time()
    vad.process_batch(audio_batch)
    duration = time.time() - start
    assert duration <= reference_duration * 1.02
```

### Pour Modules TTS
```python
def test_tts_module():
    # DIAGNOSTIC RTX 3090 OBLIGATOIRE
    import subprocess
    result = subprocess.run([
        "python", "C:\\Dev\\SuperWhisper_V6\\test_diagnostic_rtx3090.py"
    ], capture_output=True, text=True)
    assert result.returncode == 0, "Script diagnostic RTX 3090 Ã©chouÃ©"
    print("âœ… Diagnostic RTX 3090 validÃ© pour module TTS")
    
    validate_rtx3090_mandatory()
    
    # Test spÃ©cifique TTS
    tts = TTSHandler()
    audio = tts.synthesize("Test phrase franÃ§aise")
    assert len(audio) > 0
    assert audio_quality(audio) > min_quality_threshold
    
    # Test voix multiples
    for voice in available_voices:
        tts.set_voice(voice)
        audio = tts.synthesize("Test")
        assert audio_voice_correct(audio, voice)
```

### Pour Modules LLM
```python
def test_llm_module():
    # DIAGNOSTIC RTX 3090 OBLIGATOIRE
    import subprocess
    result = subprocess.run([
        "python", "C:\\Dev\\SuperWhisper_V6\\test_diagnostic_rtx3090.py"
    ], capture_output=True, text=True)
    assert result.returncode == 0, "Script diagnostic RTX 3090 Ã©chouÃ©"
    print("âœ… Diagnostic RTX 3090 validÃ© pour module LLM")
    
    validate_rtx3090_mandatory()
    
    # Test spÃ©cifique LLM
    llm = LLMManager()
    response = llm.process("Question test")
    assert response is not None
    assert len(response) > 0
    assert response_quality(response) > min_threshold
```

### Pour Scripts de Test
```python
def test_script_test():
    # DIAGNOSTIC RTX 3090 OBLIGATOIRE
    import subprocess
    result = subprocess.run([
        "python", "C:\\Dev\\SuperWhisper_V6\\test_diagnostic_rtx3090.py"
    ], capture_output=True, text=True)
    assert result.returncode == 0, "Script diagnostic RTX 3090 Ã©chouÃ©"
    print("âœ… Diagnostic RTX 3090 validÃ© pour script de test")
    
    validate_rtx3090_mandatory()
    
    # ExÃ©cuter le script de test
    result = run_test_script()
    assert result.exit_code == 0
    assert result.gpu_used == "RTX 3090"
    assert no_errors_in_output(result.output)
```

---

## ğŸ“Š WORKFLOW DE CORRECTION RECOMMANDÃ‰

### Phase 1 : Setup SÃ©curisÃ©
```bash
# CrÃ©er branche dÃ©diÃ©e
git checkout -b feature/gpu-mapping-homogenization
git push -u origin feature/gpu-mapping-homogenization

# CrÃ©er structure de travail
mkdir -p docs/gpu-correction/{reports,tests,backups}

# Tag de rÃ©fÃ©rence
git tag -a v-before-gpu-correction -m "Ã‰tat avant correction mapping GPU"
```

### Phase 2 : Correction SystÃ©matique
1. **VÃ©rifier la configuration existante** dans chaque fichier
2. **Ajouter/complÃ©ter la configuration GPU** si nÃ©cessaire
3. **S'assurer que le code utilise `cuda:0`** aprÃ¨s la configuration
4. **Validation factuelle** Ã  chaque Ã©tape
5. **Documentation** des rÃ©sultats

### Phase 3 : Validation SystÃ¨me
```python
def test_systeme_complet():
    """Test d'intÃ©gration finale"""
    
    # VÃ©rifier tous les processus GPU
    for process in get_gpu_processes():
        assert process.gpu_id == 0  # cuda:0 aprÃ¨s mapping
        assert "RTX 3090" in process.gpu_name
    
    # Test workflow complet STTâ†’LLMâ†’TTS
    result = run_complete_workflow(test_audio)
    assert result.success
    assert result.all_gpu_rtx3090
    
    print("âœ… SystÃ¨me complet validÃ© RTX 3090")
```

---

## ğŸ“ˆ RAPPORT DE VALIDATION OBLIGATOIRE

### Template de Rapport par Fichier
```markdown
## RAPPORT - [nom_fichier]

### Configuration GPU
- âœ… CUDA_VISIBLE_DEVICES: '1'
- âœ… CUDA_DEVICE_ORDER: 'PCI_BUS_ID'
- âœ… GPU dÃ©tectÃ©: NVIDIA GeForce RTX 3090 (24.0GB)
- âœ… Validation fonction: validate_rtx3090_mandatory() 

### Tests Fonctionnels
- âœ… Import module: OK
- âœ… Classes testÃ©es: X/X (100%)
- âœ… Fonctions testÃ©es: Y/Y (100%)
- âœ… Workflows testÃ©es: Z/Z (100%)

### Performance
- âœ… Temps exÃ©cution: [durÃ©e] (ref: [rÃ©fÃ©rence])
- âœ… MÃ©moire GPU: [usage] (max: [limite])
- âœ… RÃ©gression: 0% (amÃ©lioration: +X%)

### Validation Comparative
- âœ… Sorties identiques: OUI
- âœ… Comportement identique: OUI
- âœ… Gestion erreurs: IDENTIQUE

### Conclusion
âœ… CORRECTION VALIDÃ‰E - Aucune rÃ©gression dÃ©tectÃ©e
```

---

## ğŸš¨ POINTS D'ATTENTION CRITIQUES

### Configuration GPU Correcte
```python
# âœ… CORRECT - Force RTX 3090
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
# AprÃ¨s cette config : cuda:0 = RTX 3090

# âŒ INCORRECT - Manque CUDA_DEVICE_ORDER
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
# Sans CUDA_DEVICE_ORDER, l'ordre GPU peut Ãªtre imprÃ©visible
```

### Erreurs Ã  Ã‰viter Absolument
1. **âŒ Oublier `CUDA_DEVICE_ORDER='PCI_BUS_ID'`** - Critical !
2. **âŒ Assumer que la correction fonctionne** sans test factuel
3. **âŒ Tester seulement la "fonctionnalitÃ© principale"** au lieu de TOUT
4. **âŒ Ignorer les tests de performance** comparatifs
5. **âŒ Ne pas documenter** les rÃ©sultats de validation

### Validation Factuelle Obligatoire
```python
# TOUJOURS VÃ‰RIFIER FACTUELLEMENT
gpu_name = torch.cuda.get_device_name(0)
assert "RTX 3090" in gpu_name, f"Ã‰CHEC: {gpu_name}"

# JAMAIS D'ASSOMPTION
# âŒ INTERDIT: "La configuration devrait Ãªtre correcte"
# âœ… OBLIGATOIRE: ContrÃ´le factuel Ã  chaque Ã©tape
```

### Gestion des Erreurs
```python
try:
    validate_rtx3090_mandatory()
    run_functionality_tests()
    check_performance_regression()
except Exception as e:
    # Rollback automatique
    restore_original_file()
    raise RuntimeError(f"Correction Ã©chouÃ©e: {e}")
```

---

## ğŸ¯ LIVRABLES ATTENDUS

1. **40 fichiers avec configuration GPU homogÃ¨ne** (CUDA_VISIBLE_DEVICES='1' + CUDA_DEVICE_ORDER='PCI_BUS_ID')
2. **Code utilisant `cuda:0`** de maniÃ¨re cohÃ©rente
3. **40 validations script diagnostic** "C:\Dev\SuperWhisper_V6\test_diagnostic_rtx3090.py"
4. **40 rapports de validation** dÃ©taillÃ©s
5. **Tests automatisÃ©s** pour chaque correction
6. **Standards GPU documentÃ©s** pour dÃ©veloppements futurs
7. **Guide de validation** rÃ©utilisable
8. **Rapport final** de mission

---

## ğŸš€ COMMANDES D'EXÃ‰CUTION

### Lancement de la Mission
```bash
# ExÃ©cuter avec TaskMaster
task-master parse-prd --input=docs/prd.md
task-master analyze-complexity --research
task-master list
task-master next

# Script de validation GPU
python scripts/validate_gpu_configuration.py

# Ou exÃ©cution directe
python -c "exec(open('docs/prompt.md').read())"
```

---

**CE PROMPT GARANTIT UNE EXÃ‰CUTION MÃ‰THODIQUE, RIGOUREUSE ET SANS RISQUE DE LA MISSION D'HOMOGÃ‰NISATION GPU, AVEC VALIDATION FACTUELLE OBLIGATOIRE Ã€ CHAQUE Ã‰TAPE ET PRÃ‰SERVATION INTÃ‰GRALE DES FONCTIONNALITÃ‰S EXISTANTES.**

---

*Prompt crÃ©Ã© d'aprÃ¨s les enseignements mÃ©thodologiques tirÃ©s de la session de travail SuperWhisper V6 - Mise Ã  jour Juin 2025* 