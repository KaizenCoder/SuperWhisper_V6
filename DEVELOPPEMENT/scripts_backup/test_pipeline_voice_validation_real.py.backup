#!/usr/bin/env python3
"""
Test de validation pipeline voix-√†-voix SuperWhisper V6 - AVEC TTS R√âEL
üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE

Utilise le TTSHandler valid√© de la transmission du coordinateur (10/06/2025)
avec fallback intelligent si mod√®les non disponibles.

Test interactif complet: STT ‚Üí LLM ‚Üí TTS ‚Üí Audio avec validation humaine
"""

import os
import sys
import time
import json
import asyncio
import argparse
from datetime import datetime
from pathlib import Path
from typing import Tuple, Optional

import numpy as np
import sounddevice as sd

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Configuration paths
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / "TTS"))

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    try:
        import torch
        if not torch.cuda.is_available():
            raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
        
        cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
        if cuda_devices != '1':
            raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
        
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if gpu_memory < 20:  # RTX 3090 = ~24GB
            raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
        
        print(f"‚úÖ RTX 3090 valid√©e: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")
        return True
    except ImportError:
        print("‚ö†Ô∏è PyTorch non disponible - validation GPU ignor√©e")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Validation GPU √©chou√©e: {e}")
        return True

class MockSTTManager:
    """Mock STT Manager pour test pipeline"""
    
    def __init__(self):
        print("üé§ Mock STT Manager initialis√©")
    
    async def transcribe(self, audio_data: np.ndarray) -> object:
        """Simule transcription STT"""
        await asyncio.sleep(0.15)  # 150ms latence STT
        
        class STTResult:
            def __init__(self, text: str):
                self.text = text
                self.confidence = 0.95
        
        return STTResult("Bonjour, je teste le pipeline voix-√†-voix de SuperWhisper V6")

class MockLLMClient:
    """Mock LLM Client pour test pipeline"""
    
    def __init__(self, endpoint: str):
        self.endpoint = endpoint
        self.fallback_responses = [
            "Bonjour ! Je suis SuperWhisper V6, votre assistant vocal intelligent.",
            "Parfait ! Le pipeline voix-√†-voix fonctionne correctement.",
            "Excellent ! Tous les composants STT, LLM et TTS sont op√©rationnels.",
            "Je vous entends parfaitement. Le syst√®me de reconnaissance vocale est fonctionnel.",
            "Merci de tester SuperWhisper V6. La synth√®se vocale est de qualit√© exceptionnelle."
        ]
        print(f"ü§ñ Mock LLM Client initialis√© (endpoint: {endpoint})")
    
    async def generate_response(self, text: str) -> str:
        """Simule g√©n√©ration LLM"""
        await asyncio.sleep(0.18)  # 180ms latence LLM
        
        if "test" in text.lower() or "pipeline" in text.lower():
            return self.fallback_responses[1]
        elif "bonjour" in text.lower():
            return self.fallback_responses[0]
        else:
            return self.fallback_responses[2]

class RealTTSHandler:
    """TTS Handler r√©el utilisant le TTSHandler valid√© de la transmission"""
    
    def __init__(self):
        self.sample_rate = 22050
        self.tts_handler = None
        self.use_fallback = False
        
        print("üîä Initialisation TTS Handler r√©el...")
        
        # Essayer d'utiliser le vrai TTSHandler
        try:
            from tts_handler import TTSHandler
            
            # Chercher mod√®le TTS dans transmission
            model_paths = [
                "docs/Transmission_Coordinateur/zip/extracted_1744/fr_FR-siwis-medium.onnx",
                "models/fr_FR-siwis-medium.onnx",
                "TTS/models/fr_FR-siwis-medium.onnx"
            ]
            
            model_found = None
            for model_path in model_paths:
                if Path(model_path).exists():
                    model_found = model_path
                    break
            
            if model_found:
                config = {'model_path': model_found}
                self.tts_handler = TTSHandler(config)
                print(f"‚úÖ TTSHandler r√©el initialis√© avec mod√®le: {model_found}")
            else:
                print("‚ö†Ô∏è Aucun mod√®le TTS trouv√© - utilisation fallback")
                self.use_fallback = True
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur initialisation TTSHandler r√©el: {e}")
            self.use_fallback = True
        
        if self.use_fallback:
            print("üîÑ Utilisation TTS fallback (Windows SAPI)")
    
    def speak(self, text: str) -> Tuple[np.ndarray, int]:
        """Synth√®se TTS avec handler r√©el ou fallback"""
        if not self.use_fallback and self.tts_handler:
            try:
                # Utiliser le vrai TTSHandler
                print(f"üéµ Synth√®se TTS r√©elle: {text}")
                
                # Le TTSHandler original joue directement l'audio
                # Nous devons capturer l'audio g√©n√©r√©
                return self._capture_tts_output(text)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur TTS r√©el: {e} - utilisation fallback")
                return self._fallback_sapi_tts(text)
        else:
            return self._fallback_sapi_tts(text)
    
    def _capture_tts_output(self, text: str) -> Tuple[np.ndarray, int]:
        """Capture la sortie du TTSHandler r√©el"""
        try:
            import tempfile
            import wave
            import subprocess
            
            # V√©rifier si piper.exe est disponible
            piper_paths = ["piper/piper.exe", "piper.exe"]
            piper_exe = None
            
            for path in piper_paths:
                if Path(path).exists():
                    piper_exe = path
                    break
            
            if not piper_exe:
                print("‚ö†Ô∏è piper.exe non trouv√© - utilisation fallback")
                return self._fallback_sapi_tts(text)
            
            # Utiliser piper directement
            model_path = "docs/Transmission_Coordinateur/zip/extracted_1744/fr_FR-siwis-medium.onnx"
            if not Path(model_path).exists():
                print("‚ö†Ô∏è Mod√®le TTS non trouv√© - utilisation fallback")
                return self._fallback_sapi_tts(text)
            
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                tmp_path = tmp_file.name
            
            # Commande piper
            cmd = [
                piper_exe,
                "--model", model_path,
                "--output_file", tmp_path,
                "--speaker", "0"
            ]
            
            # Ex√©cuter piper
            result = subprocess.run(
                cmd,
                input=text,
                text=True,
                capture_output=True,
                timeout=30
            )
            
            if result.returncode == 0 and Path(tmp_path).exists():
                # Lire le fichier WAV g√©n√©r√©
                with wave.open(tmp_path, 'rb') as wav_file:
                    frames = wav_file.readframes(-1)
                    sample_rate = wav_file.getframerate()
                    
                    # Conversion vers numpy
                    audio_data = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32767.0
                    
                    # Nettoyage
                    Path(tmp_path).unlink(missing_ok=True)
                    
                    print("‚úÖ TTS r√©el g√©n√©r√© avec succ√®s")
                    return audio_data, sample_rate
            else:
                print(f"‚ö†Ô∏è Erreur piper: {result.stderr}")
                return self._fallback_sapi_tts(text)
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur capture TTS: {e}")
            return self._fallback_sapi_tts(text)
    
    def _fallback_sapi_tts(self, text: str) -> Tuple[np.ndarray, int]:
        """TTS fallback avec Windows SAPI"""
        try:
            import win32com.client
            import tempfile
            import wave
            
            print("üîÑ Utilisation Windows SAPI pour TTS")
            
            # Initialiser SAPI
            sapi = win32com.client.Dispatch("SAPI.SpVoice")
            
            # Configurer voix fran√ßaise si disponible
            voices = sapi.GetVoices()
            for i in range(voices.Count):
                voice = voices.Item(i)
                if "french" in voice.GetDescription().lower():
                    sapi.Voice = voice
                    break
            
            # Synth√®se vers fichier temporaire
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                tmp_path = tmp_file.name
            
            # Configuration sortie fichier
            file_stream = win32com.client.Dispatch("SAPI.SpFileStream")
            file_stream.Open(tmp_path, 3)
            sapi.AudioOutputStream = file_stream
            
            # Synth√®se
            sapi.Speak(text)
            file_stream.Close()
            
            # Lecture fichier g√©n√©r√©
            with wave.open(tmp_path, 'rb') as wav_file:
                frames = wav_file.readframes(-1)
                sample_rate = wav_file.getframerate()
                
                audio_data = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32767.0
                
                # Nettoyage
                Path(tmp_path).unlink(missing_ok=True)
                
                print("‚úÖ TTS SAPI g√©n√©r√© avec succ√®s")
                return audio_data, sample_rate
                
        except ImportError:
            print("‚ö†Ô∏è win32com non disponible - TTS simul√©")
            return self._simulate_tts(text)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur SAPI: {e} - TTS simul√©")
            return self._simulate_tts(text)
    
    def _simulate_tts(self, text: str) -> Tuple[np.ndarray, int]:
        """TTS simul√© en dernier recours"""
        print("üîÑ TTS simul√© (dernier recours)")
        duration = min(len(text) * 0.1, 3.0)
        t = np.linspace(0, duration, int(self.sample_rate * duration))
        
        # Signal plus r√©aliste (voix synth√©tique)
        freq_base = 200  # Fr√©quence fondamentale voix
        freq_harmonics = [400, 600, 800]  # Harmoniques
        
        audio = 0.2 * np.sin(2 * np.pi * freq_base * t)
        for freq in freq_harmonics:
            audio += 0.1 * np.sin(2 * np.pi * freq * t)
        
        # Modulation pour simuler parole
        modulation = 1 + 0.3 * np.sin(2 * np.pi * 5 * t)  # 5Hz modulation
        audio *= modulation
        
        # Enveloppe
        fade_samples = int(0.05 * self.sample_rate)
        audio[:fade_samples] *= np.linspace(0, 1, fade_samples)
        audio[-fade_samples:] *= np.linspace(1, 0, fade_samples)
        
        return audio, self.sample_rate

def _to_int16(audio_f: np.ndarray) -> np.ndarray:
    """Conversion audio float vers int16 s√©curis√©e"""
    audio_c = np.clip(audio_f, -1.0, 1.0)
    return (audio_c * 32767).astype(np.int16)

async def main():
    """Test interactif pipeline voix-√†-voix SuperWhisper V6 avec TTS r√©el"""
    parser = argparse.ArgumentParser(description="Test pipeline voix-√†-voix SuperWhisper V6 - TTS R√âEL")
    parser.add_argument("--llm-endpoint", default="http://localhost:1234/v1",
                        help="Endpoint LLM (LM Studio/Ollama)")
    parser.add_argument("--duration", type=float, default=3.0, 
                        help="Dur√©e d'enregistrement (s)")
    args = parser.parse_args()

    print("\n" + "="*80)
    print("üöÄ SUPERWHISPER V6 - TEST PIPELINE VOIX-√Ä-VOIX (TTS R√âEL)")
    print("="*80)

    # 1. Validation GPU RTX 3090
    print("\n1Ô∏è‚É£ Validation GPU RTX 3090...")
    if not validate_rtx3090_configuration():
        print("üö´ √âCHEC: Configuration GPU RTX 3090 invalide")
        return False

    # 2. Initialisation composants
    print("\n2Ô∏è‚É£ Initialisation des composants...")
    try:
        stt = MockSTTManager()
        llm = MockLLMClient(args.llm_endpoint)
        tts = RealTTSHandler()
        print("‚úÖ Tous les composants initialis√©s")
    except Exception as e:
        print(f"‚ùå Erreur initialisation: {e}")
        return False

    # 3. Pr√©paration log
    log = {
        "utc_ts": datetime.now().isoformat(),
        "gpu_config": "RTX 3090 (CUDA:1)",
        "llm_endpoint": args.llm_endpoint,
        "test_type": "pipeline_voice_validation_real_tts",
        "tts_type": "fallback" if tts.use_fallback else "real"
    }

    # 4. Capture audio
    print(f"\n3Ô∏è‚É£ Capture audio ({args.duration}s)...")
    print("üé§ Parlez maintenant apr√®s le bip...")
    
    sample_rate = 16000
    t0 = time.perf_counter()
    
    # Bip de d√©marrage
    print("üîî BIP!")
    beep = 0.3 * np.sin(2 * np.pi * 800 * np.linspace(0, 0.2, int(0.2 * sample_rate)))
    sd.play(_to_int16(beep), samplerate=sample_rate)
    sd.wait()
    
    # Enregistrement
    recording = sd.rec(int(args.duration * sample_rate), 
                      samplerate=sample_rate, channels=1, dtype=np.float32)
    sd.wait()
    t_record_end = time.perf_counter()
    log["record_time_ms"] = (t_record_end - t0) * 1000

    # 5. STT
    print("\n4Ô∏è‚É£ Transcription STT...")
    stt_start = time.perf_counter()
    stt_result = await stt.transcribe(recording.flatten())
    stt_end = time.perf_counter()
    log["stt_latency_ms"] = (stt_end - stt_start) * 1000
    log["transcription"] = stt_result.text
    print(f"üìù Transcription: {stt_result.text}")

    # 6. LLM
    print("\n5Ô∏è‚É£ G√©n√©ration LLM...")
    llm_start = time.perf_counter()
    assistant_text = await llm.generate_response(stt_result.text)
    llm_end = time.perf_counter()
    log["llm_latency_ms"] = (llm_end - llm_start) * 1000
    log["assistant_text"] = assistant_text
    print(f"ü§ñ R√©ponse LLM: {assistant_text}")

    if not assistant_text.strip():
        print("‚ùå LLM a renvoy√© une r√©ponse vide")
        _write_log(log, error="empty_assistant_text")
        return False

    # 7. TTS R√âEL
    print("\n6Ô∏è‚É£ Synth√®se TTS R√âELLE...")
    tts_start = time.perf_counter()
    audio_f, sr = tts.speak(assistant_text)
    tts_end = time.perf_counter()
    log["tts_latency_ms"] = (tts_end - tts_start) * 1000
    log["tts_sample_rate"] = sr
    log["audio_max"] = float(np.max(np.abs(audio_f)))

    # 8. Lecture audio
    print("\n7Ô∏è‚É£ Lecture r√©ponse audio...")
    audio_i16 = _to_int16(audio_f)
    playback_start = time.perf_counter()
    sd.play(audio_i16, samplerate=sr)
    sd.wait()
    playback_end = time.perf_counter()

    # 9. M√©triques finales
    log["playback_ms"] = (playback_end - playback_start) * 1000
    log["time_to_first_audio_ms"] = (tts_start - t0) * 1000
    log["e2e_ms"] = (playback_end - t0) * 1000

    # 10. Validation humaine
    print("\n" + "="*80)
    print("üìä R√âCAPITULATIF PIPELINE (TTS R√âEL)")
    print("="*80)
    print(f"üé§ Vous avez dit    : {stt_result.text}")
    print(f"ü§ñ Assistant r√©pond : {assistant_text}")
    print(f"üîä Type TTS         : {'Fallback' if tts.use_fallback else 'R√©el'}")
    print(f"‚è±Ô∏è  Latence STT     : {log['stt_latency_ms']:.1f}ms")
    print(f"‚è±Ô∏è  Latence LLM     : {log['llm_latency_ms']:.1f}ms")
    print(f"‚è±Ô∏è  Latence TTS     : {log['tts_latency_ms']:.1f}ms")
    print(f"‚è±Ô∏è  Latence totale  : {log['e2e_ms']:.1f}ms")
    print("="*80)

    # Validation humaine
    try:
        print("\nüéß IMPORTANT: Avez-vous entendu une VRAIE VOIX SYNTH√âTIQUE")
        print("   (pas un bip ou signal √©lectronique) ?")
        response = input("\n‚úÖ La r√©ponse audio est-elle une VRAIE SYNTH√àSE VOCALE ? (y/n): ").strip().lower()
        ok = response.startswith('y')
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Test interrompu par l'utilisateur")
        ok = False

    log["human_validation"] = ok
    log["validation_type"] = "real_voice_synthesis"

    # 11. √âcriture log et verdict
    _write_log(log)
    
    if ok:
        print("\nüéä VALIDATION R√âUSSIE !")
        print("‚úÖ Pipeline voix-√†-voix SuperWhisper V6 avec TTS R√âEL fonctionnel")
        return True
    else:
        print("\n‚ùå VALIDATION √âCHOU√âE")
        print("‚ö†Ô∏è TTS ne produit pas de vraie synth√®se vocale")
        return False

def _write_log(payload: dict, error: Optional[str] = None) -> None:
    """√âcriture log JSON"""
    if error:
        payload["error"] = error
    
    log_dir = PROJECT_ROOT / "logs"
    log_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    fname = log_dir / f"voice_pipeline_validation_real_{timestamp}.json"
    
    with open(fname, "w", encoding="utf-8") as fp:
        json.dump(payload, fp, ensure_ascii=False, indent=2)
    
    print(f"üìÑ Log sauvegard√©: {fname}")

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Test interrompu")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Erreur inattendue: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 