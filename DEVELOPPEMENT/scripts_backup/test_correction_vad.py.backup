#!/usr/bin/env python3
"""
Test Correction VAD - SuperWhisper V6 Phase 4
ğŸ”§ VALIDATION: Transcription complÃ¨te avec paramÃ¨tres VAD corrigÃ©s

Mission: Valider que la correction VAD permet de transcrire
le texte complet fourni (155 mots) au lieu de s'arrÃªter Ã  25 mots.
"""

import os
import sys
import time
import asyncio
import numpy as np
from pathlib import Path

# =============================================================================
# ğŸš¨ CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation mÃ©moire

print("ğŸ® Test Correction VAD - Configuration GPU RTX 3090 (CUDA:1) forcÃ©e")
print(f"ğŸ”’ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Imports aprÃ¨s configuration GPU
sys.path.append(str(Path(__file__).parent.parent))

from STT.backends.prism_stt_backend import PrismSTTBackend

def generer_audio_test_long(duree: float = 30.0, sample_rate: int = 16000) -> np.ndarray:
    """
    GÃ©nÃ¨re un audio test pour simuler le texte de 155 mots
    
    Args:
        duree: DurÃ©e en secondes (30s pour 155 mots â‰ˆ 5 mots/seconde)
        sample_rate: FrÃ©quence d'Ã©chantillonnage
        
    Returns:
        Audio numpy array avec pattern rÃ©aliste
    """
    print(f"ğŸµ GÃ©nÃ©ration audio test {duree}s pour validation VAD...")
    
    samples = int(duree * sample_rate)
    audio = np.zeros(samples, dtype=np.float32)
    
    # Simuler pattern de parole: segments avec silences
    segment_duration = 3.0  # 3 secondes par segment
    silence_duration = 0.5  # 0.5 seconde de silence entre segments
    
    current_pos = 0
    segment_id = 1
    
    while current_pos < samples:
        # Segment de parole
        segment_samples = int(segment_duration * sample_rate)
        if current_pos + segment_samples > samples:
            segment_samples = samples - current_pos
        
        # Pattern audio rÃ©aliste (plusieurs frÃ©quences)
        t = np.linspace(0, segment_duration, segment_samples)
        
        # FrÃ©quences vocales typiques
        freq1 = 150 + (segment_id % 3) * 50  # FrÃ©quence fondamentale variable
        freq2 = freq1 * 2                   # Harmonique
        freq3 = freq1 * 3                   # Harmonique
        
        # Signal composite avec modulation
        signal = (
            0.3 * np.sin(2 * np.pi * freq1 * t) +
            0.2 * np.sin(2 * np.pi * freq2 * t) +
            0.1 * np.sin(2 * np.pi * freq3 * t)
        )
        
        # Enveloppe rÃ©aliste
        envelope = np.exp(-t / (segment_duration * 0.8))  # DÃ©croissance
        signal *= envelope
        
        # Ajouter bruit lÃ©ger
        noise = np.random.normal(0, 0.02, len(signal))
        signal += noise
        
        # InsÃ©rer dans audio principal
        end_pos = min(current_pos + len(signal), samples)
        audio[current_pos:end_pos] = signal[:end_pos - current_pos]
        
        current_pos += segment_samples
        
        # Silence entre segments
        silence_samples = int(silence_duration * sample_rate)
        current_pos += silence_samples
        
        segment_id += 1
        
        print(f"   Segment {segment_id-1}: {freq1}Hz, position {current_pos/sample_rate:.1f}s")
    
    print(f"âœ… Audio test gÃ©nÃ©rÃ©: {len(audio)} Ã©chantillons ({len(audio)/sample_rate:.1f}s)")
    return audio

async def test_correction_vad_complete():
    """
    Test principal de la correction VAD
    
    Objectif: Valider que la transcription va jusqu'au bout
    """
    print("\n" + "="*60)
    print("ğŸ”§ TEST CORRECTION VAD - TRANSCRIPTION COMPLÃˆTE")
    print("="*60)
    
    print("\nğŸ¯ Objectif:")
    print("   Valider que les paramÃ¨tres VAD corrigÃ©s permettent")
    print("   une transcription complÃ¨te sans coupure prÃ©maturÃ©e")
    print("   (problÃ¨me rÃ©solu: 25 mots sur 155)")
    
    try:
        # Initialiser backend avec VAD activÃ©
        print("\nğŸš€ Initialisation Backend Prism STT...")
        config = {
            'model': 'large-v2',
            'compute_type': 'float16',
            'language': 'fr',
            'beam_size': 5,
            'vad_filter': True  # VAD ACTIVÃ‰ avec paramÃ¨tres corrigÃ©s
        }
        
        backend = PrismSTTBackend(config)
        print("âœ… Backend initialisÃ© avec VAD corrigÃ©")
        
        # GÃ©nÃ©rer audio test long (simule 155 mots)
        print("\nğŸµ GÃ©nÃ©ration audio test long...")
        audio_test = generer_audio_test_long(duree=30.0)  # 30 secondes
        print(f"âœ… Audio gÃ©nÃ©rÃ©: {len(audio_test)} Ã©chantillons")
        
        # Test transcription AVEC VAD corrigÃ©
        print("\nğŸ”§ Test transcription avec VAD corrigÃ©...")
        start_time = time.time()
        
        result = await backend.transcribe(audio_test)
        
        transcription_time = time.time() - start_time
        
        # Analyser rÃ©sultats
        print(f"\nğŸ“Š RÃ‰SULTATS CORRECTION VAD:")
        print(f"   â±ï¸ Temps transcription: {transcription_time:.2f}s")
        print(f"   âš¡ RTF: {result.rtf:.3f}")
        print(f"   ğŸ¯ SuccÃ¨s: {result.success}")
        print(f"   ğŸ“ Texte transcrit: '{result.text}'")
        print(f"   ğŸ“ Longueur texte: {len(result.text)} caractÃ¨res")
        print(f"   ğŸ”¢ Mots estimÃ©s: {len(result.text.split()) if result.text else 0}")
        print(f"   ğŸª Segments: {len(result.segments)}")
        print(f"   ğŸ’ª Confiance: {result.confidence:.3f}")
        
        # Validation correction
        mots_transcrits = len(result.text.split()) if result.text else 0
        caracteres_transcrits = len(result.text)
        
        print(f"\nâœ… VALIDATION CORRECTION VAD:")
        
        # CritÃ¨re 1: Transcription non vide
        if result.text and len(result.text) > 0:
            print("   âœ… Transcription non vide")
        else:
            print("   âŒ Transcription vide")
        
        # CritÃ¨re 2: DurÃ©e transcription proche durÃ©e audio
        duree_audio = len(audio_test) / 16000
        segments_traites = len(result.segments)
        if segments_traites > 5:  # Au moins 5 segments pour 30s
            print(f"   âœ… Segments traitÃ©s: {segments_traites} (audio {duree_audio:.1f}s)")
        else:
            print(f"   âš ï¸ Peu de segments: {segments_traites} pour {duree_audio:.1f}s")
        
        # CritÃ¨re 3: RTF acceptable
        if result.rtf < 1.0:
            print(f"   âœ… RTF temps rÃ©el: {result.rtf:.3f}")
        else:
            print(f"   âš ï¸ RTF Ã©levÃ©: {result.rtf:.3f}")
        
        # CritÃ¨re 4: Pas d'erreur
        if result.success:
            print("   âœ… Transcription rÃ©ussie")
        else:
            print(f"   âŒ Erreur: {result.error}")
        
        # RÃ©sumÃ©
        if result.success and result.text and segments_traites > 5:
            print(f"\nğŸŠ CORRECTION VAD VALIDÃ‰E!")
            print(f"   La transcription semble complÃ¨te avec {segments_traites} segments")
            return True
        else:
            print(f"\nâš ï¸ CORRECTION VAD Ã€ VÃ‰RIFIER")
            print(f"   Validation manuelle recommandÃ©e")
            return False
            
    except Exception as e:
        print(f"\nâŒ ERREUR Test Correction VAD: {e}")
        import traceback
        traceback.print_exc()
        return False

def afficher_aide_interpretation():
    """Affiche l'aide pour interprÃ©ter les rÃ©sultats"""
    print("\n" + "="*60)
    print("ğŸ“š AIDE INTERPRÃ‰TATION RÃ‰SULTATS")
    print("="*60)
    
    print("\nğŸ” Comment interprÃ©ter:")
    print("   âœ… CORRECTION RÃ‰USSIE si:")
    print("      - Transcription non vide")
    print("      - Plusieurs segments traitÃ©s (> 5 pour 30s)")
    print("      - RTF < 1.0 (temps rÃ©el)")
    print("      - Pas d'erreur technique")
    
    print("\n   âš ï¸ INVESTIGATION REQUISE si:")
    print("      - Transcription trÃ¨s courte")
    print("      - Peu de segments (< 3 pour 30s)")
    print("      - RTF trÃ¨s Ã©levÃ© (> 2.0)")
    print("      - Erreurs techniques")
    
    print("\nğŸ¯ Prochaines Ã©tapes:")
    print("   1. Si correction validÃ©e â†’ Test avec micro rÃ©el")
    print("   2. Si problÃ¨me persiste â†’ Ajuster paramÃ¨tres VAD")
    print("   3. Validation humaine finale obligatoire")

async def main():
    """Point d'entrÃ©e principal"""
    print("ğŸ”§ TEST CORRECTION VAD - SUPERWHISPER V6 PHASE 4")
    print("Mission: Valider paramÃ¨tres VAD corrigÃ©s pour transcription complÃ¨te")
    
    # Test correction
    success = await test_correction_vad_complete()
    
    # Aide interprÃ©tation
    afficher_aide_interpretation()
    
    # Conclusion
    if success:
        print(f"\nğŸŠ RÃ‰SULTAT: CORRECTION VAD VALIDÃ‰E")
        print("ğŸ’¡ Prochaine Ã©tape: Test microphone rÃ©el avec validation humaine")
    else:
        print(f"\nâš ï¸ RÃ‰SULTAT: INVESTIGATION REQUISE")
        print("ğŸ’¡ VÃ©rifier logs et ajuster paramÃ¨tres si nÃ©cessaire")

if __name__ == "__main__":
    asyncio.run(main()) 