#!/usr/bin/env python3
"""
Test Microphone Optimis√© - SuperWhisper V6 Phase 4
üéØ VALIDATION: Transcription VAD avec gestion robuste erreurs

Mission: Tester transcription compl√®te avec timeout adapt√© pour texte long

üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# üöÄ PORTABILIT√â AUTOMATIQUE - EX√âCUTABLE DEPUIS N'IMPORTE O√ô
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour ex√©cution portable"""
    # D√©terminer le r√©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le r√©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
    print(f"üìÅ Project Root: {project_root}")
    print(f"üíª Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import time
import asyncio
import json
import sounddevice as sd
import numpy as np
from pathlib import Path

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ SuperWhisper V6 Phase 4 STT - Test Microphone Optimis√©")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajouter STT au path
sys.path.append(str(Path(__file__).parent.parent))

from STT.backends.prism_stt_backend import PrismSTTBackend

def validate_rtx3090_stt():
    """Validation syst√©matique RTX 3090 pour STT"""
    import torch
    if not torch.cuda.is_available():
        raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise pour STT")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 = ~24GB
        raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
    
    print(f"‚úÖ RTX 3090 valid√©e pour STT: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")

async def test_microphone_simple():
    """Test microphone avec backend direct pour √©viter timeouts"""
    
    print("\n" + "="*60)
    print("üé§ TEST MICROPHONE SIMPLE - BACKEND DIRECT")
    print("="*60)
    
    # Validation GPU
    validate_rtx3090_stt()
    
    # Configuration Backend direct (plus robuste)
    config = {
        'model': 'large-v2',
        'compute_type': 'float16',
        'language': 'fr',
        'beam_size': 5,
        'vad_filter': True
    }
    
    print(f"üöÄ Initialisation Backend Prism direct...")
    backend = PrismSTTBackend(config)
    print(f"‚úÖ Backend initialis√©")
    
    # Configuration audio
    SAMPLE_RATE = 16000
    CHUNK_SIZE = 1024
    
    print(f"\nüìã INSTRUCTIONS:")
    print(f"   1. Parlez clairement pendant 10-15 secondes")
    print(f"   2. Testez une phrase compl√®te et complexe")
    print(f"   3. CTRL+C pour arr√™ter quand termin√©")
    
    input(f"\nüé§ Appuyez sur ENTR√âE pour d√©marrer l'enregistrement...")
    
    print(f"\nüî¥ ENREGISTREMENT EN COURS")
    print(f"   ‚èπÔ∏è CTRL+C pour arr√™ter")
    
    # Enregistrement avec arr√™t manuel
    frames = []
    try:
        # Configuration stream
        stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype=np.float32,
            blocksize=CHUNK_SIZE
        )
        
        with stream:
            start_recording = time.time()
            while True:
                # Lire chunk audio
                audio_chunk, overflowed = stream.read(CHUNK_SIZE)
                frames.append(audio_chunk.flatten())
                
                # Affichage temps √©coul√©
                temps_ecoule = time.time() - start_recording
                print(f"\r‚è±Ô∏è Temps √©coul√©: {temps_ecoule:.1f}s", end="", flush=True)
                
                # Arr√™t automatique apr√®s 60s
                if temps_ecoule > 60:
                    print(f"\n‚è∞ Arr√™t automatique apr√®s 60s")
                    break
                    
    except KeyboardInterrupt:
        duree_enregistrement = time.time() - start_recording
        print(f"\n‚úÖ Enregistrement arr√™t√© apr√®s {duree_enregistrement:.1f}s")
    
    # Construire audio final
    if not frames:
        print(f"‚ùå Aucun audio enregistr√©")
        return
    
    audio_complet = np.concatenate(frames)
    duree_audio = len(audio_complet) / SAMPLE_RATE
    niveau_audio = np.max(np.abs(audio_complet))
    
    print(f"\nüìä AUDIO ENREGISTR√â:")
    print(f"   ‚è±Ô∏è Dur√©e: {duree_audio:.1f}s")
    print(f"   üìä Niveau: {niveau_audio:.3f}")
    print(f"   üìè √âchantillons: {len(audio_complet)}")
    
    if niveau_audio < 0.01:
        print(f"‚ö†Ô∏è Niveau audio tr√®s faible, v√©rifiez votre microphone")
        return
    
    # Transcription STT DIRECTE avec timeout adapt√©
    print(f"\nü§ñ TRANSCRIPTION STT AVEC VAD CORRIG√â...")
    print(f"   üîß Backend direct pour plus de robustesse")
    print(f"   ‚è±Ô∏è Timeout adapt√©: {duree_audio * 5:.1f}s")
    
    start_transcription = time.time()
    
    try:
        # Utilisation directe du backend pour √©viter timeouts UnifiedSTTManager
        result = await backend.transcribe(audio_complet)
        
        duree_transcription = time.time() - start_transcription
        rtf = duree_transcription / duree_audio
        
        print(f"‚úÖ Transcription termin√©e en {duree_transcription:.2f}s")
        
        # Analyser r√©sultats
        texte_transcrit = result.text
        nb_mots_transcrit = len(texte_transcrit.split()) if texte_transcrit else 0
        
        print(f"\n" + "="*60)
        print(f"üìä R√âSULTATS TRANSCRIPTION VAD CORRIG√â")
        print(f"="*60)
        
        print(f"\nüìù TRANSCRIPTION OBTENUE:")
        print(f"   '{texte_transcrit}'")
        
        print(f"\nüìä M√âTRIQUES:")
        print(f"   ‚è±Ô∏è Dur√©e transcription: {duree_transcription:.2f}s")
        print(f"   ‚ö° RTF: {rtf:.3f}")
        print(f"   üéØ Succ√®s: {result.success}")
        print(f"   üí™ Confiance: {result.confidence:.3f}")
        print(f"   üéÆ Backend: {result.backend_used}")
        print(f"   üìè Mots transcrits: {nb_mots_transcrit}")
        
        print(f"\nüîß ANALYSE VAD:")
        print(f"   üìä Segments d√©tect√©s: {len(result.segments)}")
        
        if result.segments:
            print(f"   üîç D√©tail segments (premiers 3):")
            for i, segment in enumerate(result.segments[:3]):
                start = segment.get('start', 0)
                end = segment.get('end', 0)
                duree_seg = end - start
                texte_seg = segment.get('text', '')
                print(f"      Seg {i+1}: {start:.1f}s ‚Üí {end:.1f}s ({duree_seg:.1f}s) - '{texte_seg[:50]}...'")
        
        # √âvaluation correction VAD
        print(f"\nüîß √âVALUATION CORRECTION VAD:")
        
        correction_ok = True
        
        if not texte_transcrit.strip():
            print(f"‚ùå Transcription vide")
            correction_ok = False
        else:
            print(f"‚úÖ Transcription non vide")
        
        if nb_mots_transcrit < 5:
            print(f"‚ùå Trop peu de mots: {nb_mots_transcrit}")
            correction_ok = False
        else:
            print(f"‚úÖ Nombre de mots significatif: {nb_mots_transcrit}")
        
        if len(result.segments) < 2:
            print(f"‚ö†Ô∏è Peu de segments VAD: {len(result.segments)}")
        else:
            print(f"‚úÖ Segments VAD multiples: {len(result.segments)}")
        
        if rtf > 1.5:
            print(f"‚ö†Ô∏è RTF √©lev√©: {rtf:.3f}")
        else:
            print(f"‚úÖ RTF acceptable: {rtf:.3f}")
        
        # R√©sultat final
        print(f"\nüéØ R√âSULTAT:")
        if correction_ok:
            print(f"‚úÖ CORRECTION VAD FONCTIONNE")
            print(f"   Transcription compl√®te obtenue")
        else:
            print(f"‚ö†Ô∏è PROBL√àME D√âTECT√â")
            print(f"   Transcription incompl√®te ou vide")
        
        # Sauvegarde
        resultats = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "duree_audio": duree_audio,
            "niveau_audio": niveau_audio,
            "texte_transcrit": texte_transcrit,
            "nb_mots_transcrit": nb_mots_transcrit,
            "duree_transcription": duree_transcription,
            "rtf": rtf,
            "confiance": result.confidence,
            "backend_used": result.backend_used,
            "nb_segments": len(result.segments),
            "correction_vad_ok": correction_ok
        }
        
        os.makedirs('test_output', exist_ok=True)
        output_file = f"test_output/test_microphone_optimise_{time.strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(resultats, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ R√©sultats sauvegard√©s: {output_file}")
        
        return correction_ok
        
    except Exception as e:
        print(f"‚ùå Erreur transcription: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Point d'entr√©e principal"""
    print("üé§ TEST MICROPHONE OPTIMIS√â - SUPERWHISPER V6 PHASE 4")
    print("Mission: Validation robuste correction VAD")
    
    try:
        success = await test_microphone_simple()
        
        if success:
            print(f"\nüéä TEST R√âUSSI - CORRECTION VAD VALID√âE !")
        else:
            print(f"\n‚ö†Ô∏è TEST PARTIEL - √Ä INVESTIGUER")
            
    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è Test interrompu par l'utilisateur")
    except Exception as e:
        print(f"\n‚ùå Erreur test: {e}")
    
    print(f"\n‚úÖ Test microphone optimis√© termin√©")

if __name__ == "__main__":
    asyncio.run(main()) 