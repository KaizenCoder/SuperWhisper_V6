# üÜò **AIDE EXTERNE - CODE ESSENTIEL SUPERWHISPER V6**

**Probl√®me** : Validation microphone live Phase 4 STT  
**Statut** : Architecture STT parfaite sur fichiers, √©chec total microphone  
**Urgence** : 48-72h maximum  

---

## üéØ **PROBL√àME R√âSUM√â**

- ‚úÖ **Tests fichiers audio** : 148/138 mots (107.2%), RTF 0.082 - PARFAIT
- ‚ùå **Tests microphone live** : 0% r√©ussite - √âCHEC SYST√âMATIQUE
- **Hypoth√®se** : VAD streaming ‚â† VAD fichier, ou pipeline async d√©faillant

---

## üîß **CODE ESSENTIEL ACTUEL**

### **1. UnifiedSTTManager - Architecture Principale**

```python
#!/usr/bin/env python3
"""
STT/unified_stt_manager.py
Manager STT unifi√© avec fallback - FONCTIONNE sur fichiers, PAS sur microphone
"""

import os
import sys
import logging
import asyncio
from typing import Optional, Dict, Any, List
import time

# Configuration GPU RTX 3090 OBLIGATOIRE
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'

class UnifiedSTTManager:
    """Manager STT unifi√© avec fallback intelligent"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.backends = []
        self.current_backend = None
        self.metrics = {
            'transcriptions': 0,
            'errors': 0,
            'avg_latency': 0.0,
            'backend_usage': {}
        }
        
        # Configuration VAD - FONCTIONNE sur fichiers
        self.vad_config = {
            "threshold": 0.3,
            "min_speech_duration_ms": 100,
            "max_speech_duration_s": float('inf'),
            "min_silence_duration_ms": 2000,
            "speech_pad_ms": 400
        }
        
        self._initialize_backends()
    
    def _initialize_backends(self):
        """Initialise les backends STT avec fallback"""
        try:
            from STT.backends.prism_stt_backend import PrismSTTBackend
            backend = PrismSTTBackend()
            if backend.is_available():
                self.backends.append(backend)
                self.logger.info("‚úÖ PrismSTTBackend RTX 3090 initialis√©")
        except Exception as e:
            self.logger.error(f"‚ùå PrismSTTBackend √©chec: {e}")
        
        # Fallbacks...
        self.current_backend = self.backends[0] if self.backends else None
    
    def transcribe_file(self, audio_path: str) -> Dict[str, Any]:
        """Transcription fichier - FONCTIONNE PARFAITEMENT"""
        if not self.current_backend:
            raise RuntimeError("Aucun backend STT disponible")
        
        start_time = time.time()
        try:
            result = self.current_backend.transcribe_file(audio_path)
            latency = time.time() - start_time
            
            self.metrics['transcriptions'] += 1
            self.metrics['avg_latency'] = (
                (self.metrics['avg_latency'] * (self.metrics['transcriptions'] - 1) + latency) 
                / self.metrics['transcriptions']
            )
            
            return {
                'text': result.get('text', ''),
                'confidence': result.get('confidence', 0.0),
                'latency': latency,
                'backend': self.current_backend.__class__.__name__,
                'rtf': latency / result.get('duration', 1.0)
            }
            
        except Exception as e:
            self.metrics['errors'] += 1
            self.logger.error(f"‚ùå Transcription √©chec: {e}")
            raise
    
    async def transcribe_stream(self, audio_stream):
        """Transcription streaming - √âCHEC SYST√âMATIQUE"""
        # ‚ùå PROBL√àME ICI - Pipeline streaming d√©faillant
        if not self.current_backend:
            raise RuntimeError("Aucun backend STT disponible")
        
        try:
            # ‚ùå Cette m√©thode √©choue syst√©matiquement avec microphone
            async for chunk in audio_stream:
                result = await self.current_backend.transcribe_chunk(chunk)
                if result and result.get('text'):
                    yield result
        except Exception as e:
            self.logger.error(f"‚ùå Streaming √©chec: {e}")
            raise
```

### **2. PrismSTTBackend - Backend Principal RTX 3090**

```python
#!/usr/bin/env python3
"""
STT/backends/prism_stt_backend.py
Backend principal Prism_Whisper2 RTX 3090 - PARFAIT fichiers, √âCHEC microphone
"""

import os
import torch
import logging
from pathlib import Path
import time
import numpy as np

# Configuration GPU RTX 3090 OBLIGATOIRE
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'

class PrismSTTBackend:
    """Backend Prism_Whisper2 optimis√© RTX 3090"""
    
    def __init__(self, model_name="Prism_Whisper2"):
        self.logger = logging.getLogger(__name__)
        self.model_name = model_name
        self.model = None
        self.device = None
        self._validate_rtx3090()
        self._initialize_model()
    
    def _validate_rtx3090(self):
        """Validation RTX 3090 obligatoire"""
        if not torch.cuda.is_available():
            raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
        
        cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
        if cuda_devices != '1':
            raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' - doit √™tre '1'")
        
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if gpu_memory < 20:
            raise RuntimeError(f"üö´ GPU {gpu_memory:.1f}GB trop petite - RTX 3090 requise")
        
        self.device = torch.device("cuda:1")
        self.logger.info(f"‚úÖ RTX 3090 valid√©e: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")
    
    def _initialize_model(self):
        """Initialise le mod√®le Prism_Whisper2"""
        try:
            # Configuration mod√®le RTX 3090
            self.model = self._load_prism_model()
            self.model.to(self.device)
            self.logger.info("‚úÖ Prism_Whisper2 RTX 3090 initialis√©")
        except Exception as e:
            self.logger.error(f"‚ùå √âchec initialisation mod√®le: {e}")
            raise
    
    def transcribe_file(self, audio_path: str) -> dict:
        """Transcription fichier - FONCTIONNE PARFAITEMENT"""
        if not self.model:
            raise RuntimeError("Mod√®le non initialis√©")
        
        try:
            start_time = time.time()
            
            # Chargement audio
            audio_data = self._load_audio(audio_path)
            
            # Transcription avec RTX 3090
            with torch.no_grad():
                result = self.model.transcribe(audio_data, device=self.device)
            
            latency = time.time() - start_time
            
            return {
                'text': result.get('text', ''),
                'confidence': result.get('confidence', 0.0),
                'duration': result.get('duration', 0.0),
                'latency': latency
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Transcription fichier √©chec: {e}")
            raise
    
    async def transcribe_chunk(self, audio_chunk: np.ndarray) -> dict:
        """Transcription chunk streaming - √âCHEC SYST√âMATIQUE"""
        # ‚ùå PROBL√àME ICI - Processing chunk streaming d√©faillant
        if not self.model:
            raise RuntimeError("Mod√®le non initialis√©")
        
        try:
            # ‚ùå Cette logique √©choue avec audio streaming
            with torch.no_grad():
                audio_tensor = torch.from_numpy(audio_chunk).to(self.device)
                result = self.model.transcribe_chunk(audio_tensor)
            
            return {
                'text': result.get('text', ''),
                'confidence': result.get('confidence', 0.0),
                'is_final': result.get('is_final', False)
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Transcription chunk √©chec: {e}")
            return None
```

### **3. VAD Manager - Voice Activity Detection**

```python
#!/usr/bin/env python3
"""
STT/vad_manager.py
Voice Activity Detection - PARFAIT fichiers, INSTABLE microphone
"""

import numpy as np
import logging
from typing import List, Tuple, Optional
import webrtcvad

class VADManager:
    """Voice Activity Detection Manager"""
    
    def __init__(self, 
                 threshold: float = 0.3,
                 min_speech_duration_ms: int = 100,
                 max_speech_duration_s: float = float('inf'),
                 min_silence_duration_ms: int = 2000,
                 speech_pad_ms: int = 400):
        
        self.logger = logging.getLogger(__name__)
        self.threshold = threshold
        self.min_speech_duration_ms = min_speech_duration_ms
        self.max_speech_duration_s = max_speech_duration_s
        self.min_silence_duration_ms = min_silence_duration_ms
        self.speech_pad_ms = speech_pad_ms
        
        # WebRTC VAD
        self.vad = webrtcvad.Vad(2)  # Aggressivit√© 2/3
        
        self.logger.info(f"‚úÖ VAD initialis√© - threshold: {threshold}")
    
    def process_file(self, audio_path: str) -> List[Tuple[float, float]]:
        """VAD sur fichier complet - FONCTIONNE PARFAITEMENT"""
        try:
            audio_data = self._load_audio(audio_path)
            return self._detect_speech_segments(audio_data)
        except Exception as e:
            self.logger.error(f"‚ùå VAD fichier √©chec: {e}")
            return []
    
    def process_chunk(self, audio_chunk: np.ndarray, sample_rate: int = 16000) -> bool:
        """VAD chunk streaming - INSTABLE"""
        # ‚ùå PROBL√àME ICI - VAD temps r√©el instable
        try:
            # Conversion pour WebRTC VAD
            if len(audio_chunk) != int(sample_rate * 0.02):  # 20ms chunks requis
                return False
            
            audio_bytes = (audio_chunk * 32767).astype(np.int16).tobytes()
            is_speech = self.vad.is_speech(audio_bytes, sample_rate)
            
            return is_speech
            
        except Exception as e:
            self.logger.error(f"‚ùå VAD chunk √©chec: {e}")
            return False
    
    def _detect_speech_segments(self, audio_data: np.ndarray) -> List[Tuple[float, float]]:
        """D√©tection segments parole - FONCTIONNE sur fichiers"""
        segments = []
        chunk_duration = 0.02  # 20ms
        sample_rate = 16000
        
        chunk_size = int(sample_rate * chunk_duration)
        speech_chunks = []
        
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i + chunk_size]
            if len(chunk) == chunk_size:
                is_speech = self.process_chunk(chunk, sample_rate)
                speech_chunks.append((i / sample_rate, is_speech))
        
        # Fusion segments
        current_start = None
        for timestamp, is_speech in speech_chunks:
            if is_speech and current_start is None:
                current_start = timestamp
            elif not is_speech and current_start is not None:
                duration = timestamp - current_start
                if duration >= self.min_speech_duration_ms / 1000:
                    segments.append((current_start, timestamp))
                current_start = None
        
        return segments
```

### **4. Script Validation Microphone - √âCHEC ACTUEL**

```python
#!/usr/bin/env python3
"""
scripts/validation_microphone_live_equipe.py
Script validation microphone - √âCHEC SYST√âMATIQUE
"""

import sounddevice as sd
import numpy as np
import asyncio
import logging
from STT.unified_stt_manager import UnifiedSTTManager

class ValidationMicrophoneLive:
    """Validation microphone live - PROBL√âMATIQUE"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.stt_manager = UnifiedSTTManager()
        
        # Configuration audio
        self.sample_rate = 16000
        self.buffer_size = 1024
        self.channels = 1
        
        # Queue audio
        self.audio_queue = asyncio.Queue()
        
    async def start_validation(self):
        """D√©marre validation microphone - √âCHEC"""
        try:
            print("üé§ D√©marrage capture microphone...")
            
            # ‚ùå PROBL√àME ICI - Capture streaming d√©faillante
            with sd.InputStream(
                samplerate=self.sample_rate,
                channels=self.channels,
                blocksize=self.buffer_size,
                callback=self._audio_callback
            ):
                print("üó£Ô∏è Parlez maintenant...")
                
                # ‚ùå Pipeline streaming d√©faillant
                async for result in self.stt_manager.transcribe_stream(self._audio_stream()):
                    print(f"Transcription: {result.get('text', '')}")
                    
        except Exception as e:
            self.logger.error(f"‚ùå Validation microphone √©chec: {e}")
    
    def _audio_callback(self, indata, frames, time, status):
        """Callback audio - PROBL√âMATIQUE"""
        if status:
            self.logger.warning(f"‚ö†Ô∏è Audio callback status: {status}")
        
        # ‚ùå Queue peut se saturer ou rester vide
        try:
            self.audio_queue.put_nowait(indata.copy())
        except asyncio.QueueFull:
            self.logger.warning("‚ö†Ô∏è Queue audio satur√©e")
    
    async def _audio_stream(self):
        """Stream audio - D√âFAILLANT"""
        # ‚ùå PROBL√àME PRINCIPAL ICI
        while True:
            try:
                audio_chunk = await asyncio.wait_for(
                    self.audio_queue.get(), 
                    timeout=1.0
                )
                yield audio_chunk
            except asyncio.TimeoutError:
                self.logger.warning("‚ö†Ô∏è Timeout audio stream")
                break

if __name__ == "__main__":
    validation = ValidationMicrophoneLive()
    asyncio.run(validation.start_validation())
```

---

## üîç **ANALYSE PROBL√àME**

### **Zones Suspectes Identifi√©es**

1. **Pipeline Streaming Audio (scripts/validation_microphone_live_equipe.py)**
   - `_audio_callback()` : Queue saturation/vide
   - `_audio_stream()` : Timeout ou data corruption
   - `sounddevice` configuration inad√©quate

2. **VAD Streaming (STT/vad_manager.py)**
   - `process_chunk()` : VAD instable temps r√©el
   - Chunks 20ms requis vs chunks variables re√ßus
   - WebRTC VAD inadapt√© streaming continu

3. **Backend Streaming (STT/backends/prism_stt_backend.py)**
   - `transcribe_chunk()` : Processing d√©faillant
   - Mod√®le optimis√© fichiers ‚â† chunks temps r√©el
   - GPU memory management streaming

4. **Architecture Async (STT/unified_stt_manager.py)**
   - `transcribe_stream()` : Race conditions
   - Threading/async mal coordonn√©
   - Gestion erreurs insuffisante

---

## üÜò **AIDE DEMAND√âE - CODE EXHAUSTIF**

### **Solution Streaming Compl√®te Attendue**

```python
# ‚úÖ SOLUTION DEMAND√âE
class StreamingMicrophoneSTT:
    """Pipeline microphone streaming fonctionnel"""
    
    def __init__(self):
        # Configuration optimale audio streaming
        # VAD streaming temps r√©el
        # GPU RTX 3090 configuration
        pass
    
    async def start_streaming(self):
        # Pipeline robuste capture ‚Üí VAD ‚Üí STT
        # Gestion threading/async optimale
        # Gestion erreurs compl√®te
        pass
    
    def process_audio_realtime(self, audio_chunk):
        # VAD streaming optimis√©
        # Transcription chunk temps r√©el
        # Performance et stabilit√©
        pass
```

### **Points Critiques √† R√©soudre**
1. **Audio Capture Streaming** : Configuration sounddevice optimale
2. **VAD Temps R√©el** : Algorithme adapt√© streaming continu
3. **Threading/Async** : Architecture robuste sans race conditions
4. **Memory Management** : GPU RTX 3090 streaming optimis√©
5. **Error Handling** : R√©cup√©ration automatique d√©faillances

### **Configuration Syst√®me**
- **OS** : Windows 10 avec PowerShell 7
- **GPU** : RTX 3090 24GB exclusif (CUDA:1)
- **Microphone** : Rode PodMic USB + microphone int√©gr√©
- **Python** : 3.12 avec PyTorch, sounddevice, webrtcvad

---

**üÜò GUIDANCE EXHAUSTIVE DEMAND√âE : Pipeline microphone streaming fonctionnel complet !** 