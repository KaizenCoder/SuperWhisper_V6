#!/usr/bin/env python3
"""
Streaming microphone RAPIDE - SuperWhisper V6
Utilise le mod√®le SMALL pour un d√©marrage rapide

üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# üöÄ PORTABILIT√â AUTOMATIQUE - EX√âCUTABLE DEPUIS N'IMPORTE O√ô
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour ex√©cution portable"""
    # D√©terminer le r√©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le r√©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
    print(f"üìÅ Project Root: {project_root}")
    print(f"üíª Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import asyncio
from pathlib import Path

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ Streaming Microphone RAPIDE - Configuration GPU RTX 3090 (CUDA:1)")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajouter le r√©pertoire parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Imports apr√®s configuration GPU
import torch
from STT.unified_stt_manager import UnifiedSTTManager
from STT.streaming_microphone_manager import StreamingMicrophoneManager

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    if not torch.cuda.is_available():
        raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 = ~24GB
        raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
    
    print(f"‚úÖ RTX 3090 valid√©e: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")

async def main():
    """D√©monstration rapide avec mod√®le small"""
    print("üöÄ Streaming Microphone RAPIDE - SuperWhisper V6")
    print("=" * 50)
    
    # Validation GPU RTX 3090
    try:
        validate_rtx3090_configuration()
    except Exception as e:
        print(f"‚ùå Erreur configuration GPU: {e}")
        return
    
    print("\nüîß Initialisation RAPIDE (mod√®le small)...")
    
    try:
        # Configuration pour mod√®le SMALL uniquement
        fast_config = {
            'fallback_chain': ['prism_small'],  # SEUL le mod√®le small
            'cache_size_mb': 50,                # Cache r√©duit en MB
            'cache_ttl': 300,                   # TTL cache 5 minutes
            'timeout_per_minute': 2.0,          # Timeout r√©duit
            'retry_attempts': 2,                # Moins de tentatives
            'enable_fallback': True             # Fallback activ√©
        }
        
        # Initialisation STT Manager en mode rapide
        print("‚ö° Initialisation UnifiedSTTManager (small)...")
        stt_mgr = UnifiedSTTManager(fast_config)
        print("‚úÖ UnifiedSTTManager initialis√©")
        
        # Initialisation Streaming Microphone Manager
        print("‚ö° Initialisation StreamingMicrophoneManager...")
        mic_mgr = StreamingMicrophoneManager(stt_mgr)
        print("‚úÖ StreamingMicrophoneManager initialis√©")
        
        print("\nüé§ D√©marrage capture microphone RAPIDE...")
        print("üó£Ô∏è Parlez maintenant! (Ctrl+C pour arr√™ter)")
        print("üéØ Objectifs: Premier token < 800ms, Latence moyenne < 1s")
        print("üìä Mod√®le: small (d√©marrage rapide)")
        print("-" * 50)
        
        # D√©marrage streaming
        await mic_mgr.run()
        
    except KeyboardInterrupt:
        print("\nüõë Arr√™t demand√© par l'utilisateur")
        print("üéâ Test streaming microphone TERMIN√â")
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        
        # Diagnostic si erreur
        print("\nüîç DIAGNOSTIC:")
        print("1. V√©rifiez que le microphone fonctionne")
        print("2. Essayez: python scripts/test_streaming_light.py")
        print("3. V√©rifiez la configuration GPU RTX 3090")
    
    print("\nüéØ Streaming microphone rapide termin√©")

if __name__ == "__main__":
    print("üéØ D√©marrage streaming microphone RAPIDE...")
    
    try:
        asyncio.run(main())
        print("\n‚úÖ Session streaming termin√©e avec succ√®s")
    except KeyboardInterrupt:
        print("\nüõë Session interrompue par l'utilisateur")
    except Exception as e:
        print(f"\nüí• Erreur fatale: {e}")
        sys.exit(1) 