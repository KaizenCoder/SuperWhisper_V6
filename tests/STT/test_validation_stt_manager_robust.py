#!/usr/bin/env python3
"""
VALIDATION FACTUELLE - STT/stt_manager_robust.py
Test pour v√©rifier que le manager utilise RTX 3090 (CUDA:0)

üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# üöÄ PORTABILIT√â AUTOMATIQUE - EX√âCUTABLE DEPUIS N'IMPORTE O√ô
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour ex√©cution portable"""
    # D√©terminer le r√©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le r√©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
    print(f"üìÅ Project Root: {project_root}")
    print(f"üíª Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import torch
import asyncio
import logging
import os

# Test de la configuration RTX 3090
def test_stt_manager_gpu_config():
    """Test factuel de la configuration GPU du STT manager"""
    print("üîç VALIDATION - STT/stt_manager_robust.py")
    print("="*50)
    
    # Nettoyer variables environnement pour test propre
    if 'CUDA_VISIBLE_DEVICES' in os.environ:
        del os.environ['CUDA_VISIBLE_DEVICES']
    
    # Configuration test
    config = {
        'use_gpu': True,
        'use_vad': False,
        'model_cache_dir': './models'
    }
    
    try:
        # Import et instanciation 
        sys.path.append('.')
        from STT.stt_manager_robust import RobustSTTManager
        
        manager = RobustSTTManager(config)
        print(f"‚úÖ STTManager instanci√© avec device: {manager.device}")
        
        # V√©rifier device GPU
        if manager.device == "cuda":
            current_device = torch.cuda.current_device()
            gpu_name = torch.cuda.get_device_name(current_device)
            vram_total = torch.cuda.get_device_properties(current_device).total_memory / (1024**3)
            
            print(f"   Device actuel: {current_device}")
            print(f"   GPU utilis√©e: {gpu_name}")
            print(f"   VRAM totale: {vram_total:.1f}GB")
            
            is_rtx3090 = "3090" in gpu_name
            print(f"   RTX 3090 confirm√©e: {'‚úÖ OUI' if is_rtx3090 else '‚ùå NON'}")
            
            return is_rtx3090 and current_device == 0
            
        else:
            print(f"   ‚ùå Device non-GPU: {manager.device}")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur instanciation STT manager: {e}")
        return False

def test_gpu_allocation_direct():
    """Test direct d'allocation GPU"""
    print("\nüéÆ TEST ALLOCATION GPU DIRECTE")
    print("="*40)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA non disponible")
        return False
    
    try:
        # Test CUDA:0 direct
        device = torch.device('cuda:0')
        test_tensor = torch.randn(100, 100).to(device)
        gpu_name = torch.cuda.get_device_name(device)
        
        print(f"   Device test√©: cuda:0")
        print(f"   GPU utilis√©e: {gpu_name}")
        
        is_rtx3090 = "3090" in gpu_name
        print(f"   RTX 3090 confirm√©e: {'‚úÖ OUI' if is_rtx3090 else '‚ùå NON'}")
        
        # Cleanup
        del test_tensor
        torch.cuda.empty_cache()
        
        return is_rtx3090
        
    except Exception as e:
        print(f"‚ùå Erreur allocation: {e}")
        return False

async def test_manager_initialization():
    """Test d'initialisation asynchrone du manager"""
    print("\nüöÄ TEST INITIALISATION MANAGER")
    print("="*40)
    
    # Nettoyer variables environnement
    if 'CUDA_VISIBLE_DEVICES' in os.environ:
        del os.environ['CUDA_VISIBLE_DEVICES']
    
    try:
        sys.path.append('.')
        from STT.stt_manager_robust import RobustSTTManager
        
        config = {
            'use_gpu': True,
            'use_vad': False,
            'model_cache_dir': './models'
        }
        
        manager = RobustSTTManager(config)
        print(f"   ‚úÖ Manager cr√©√© sur device: {manager.device}")
        
        if manager.device == "cuda":
            current_device = torch.cuda.current_device()
            gpu_name = torch.cuda.get_device_name(current_device)
            print(f"   GPU active: {gpu_name} (device {current_device})")
            
            is_correct = "3090" in gpu_name and current_device == 0
            print(f"   Configuration correcte: {'‚úÖ OUI' if is_correct else '‚ùå NON'}")
            return is_correct
        else:
            print(f"   ‚ùå Device non-GPU: {manager.device}")
            return False
        
    except Exception as e:
        print(f"‚ùå Erreur initialisation: {e}")
        return False

if __name__ == "__main__":
    print("üö® VALIDATION STT MANAGER - RTX 3090")
    print("="*60)
    
    # Tests
    config_valid = test_stt_manager_gpu_config()
    gpu_valid = test_gpu_allocation_direct()
    init_valid = asyncio.run(test_manager_initialization())
    
    # R√©sultat final
    print(f"\nüéØ R√âSULTAT FINAL:")
    print(f"   Configuration GPU: {'‚úÖ' if config_valid else '‚ùå'}")
    print(f"   Allocation directe: {'‚úÖ' if gpu_valid else '‚ùå'}")
    print(f"   Initialisation: {'‚úÖ' if init_valid else '‚ùå'}")
    
    overall_success = config_valid and gpu_valid and init_valid
    print(f"   Validation globale: {'‚úÖ R√âUSSIE' if overall_success else '‚ùå √âCHEC'}")
    
    if overall_success:
        print("   ‚úÖ stt_manager_robust.py utilise correctement RTX 3090")
    else:
        print("   ‚ùå stt_manager_robust.py n√©cessite correction") 