#!/usr/bin/env python3
"""
Validation Humaine Pipeline Complet Voix-√†-Voix
üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE

PIPELINE COMPLET : Microphone ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Audio
Test conversation r√©elle avec validation humaine obligatoire
"""

import os
import sys
import asyncio
import time
import json
from pathlib import Path

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Imports
sys.path.insert(0, '.')

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    try:
        import torch
        if not torch.cuda.is_available():
            raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
        
        cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
        if cuda_devices != '1':
            raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
        
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if gpu_memory < 20:  # RTX 3090 = ~24GB
            raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
        
        print(f"‚úÖ RTX 3090 valid√©e: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Validation GPU √©chou√©e: {e}")
        return False

async def test_pipeline_voix_a_voix_complet():
    """Test pipeline complet voix-√†-voix avec validation humaine"""
    print("\nüé§ VALIDATION HUMAINE PIPELINE COMPLET VOIX-√Ä-VOIX")
    print("üîÑ Microphone ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Audio")
    print("=" * 70)
    
    # Validation GPU obligatoire
    if not validate_rtx3090_configuration():
        print("üö´ √âCHEC: Configuration GPU RTX 3090 invalide")
        return False
    
    try:
        # Imports composants pipeline existants
        from STT.unified_stt_manager import UnifiedSTTManager
        from LLM.llm_manager_enhanced import EnhancedLLMManager  # Module existant
        from TTS.tts_manager import UnifiedTTSManager
        from PIPELINE.audio_output_manager import AudioOutputManager  # Module local
        
        # Import microphone depuis STT (streaming int√©gr√©)
        from STT.streaming_microphone_manager import StreamingMicrophoneManager
        
        print("‚úÖ Imports composants pipeline r√©ussis")
        
        # Configuration composants
        import yaml
        
        # Configuration STT
        stt_config_path = Path("config/stt.yaml")
        if stt_config_path.exists():
            with open(stt_config_path, 'r', encoding='utf-8') as f:
                stt_config = yaml.safe_load(f)
        else:
            stt_config = {}
        
        # Configuration TTS (EXISTANT INCHANG√â)
        tts_config_path = Path("config/tts.yaml")
        if tts_config_path.exists():
            with open(tts_config_path, 'r', encoding='utf-8') as f:
                tts_config = yaml.safe_load(f)
        else:
            tts_config = {}
        
        # Configuration LLM
        llm_config = {
            "endpoints": [
                {"url": "http://localhost:1234/v1", "name": "LM Studio"},
                {"url": "http://localhost:11434/api", "name": "Ollama"}
            ],
            "fallback_responses": [
                "Bonjour ! Je suis SuperWhisper V6, votre assistant vocal.",
                "Je vous entends parfaitement. Comment puis-je vous aider ?",
                "Excellent ! Le pipeline voix-√†-voix fonctionne correctement."
            ]
        }
        
        print("üîß Initialisation composants pipeline...")
        
        # Initialisation composants
        microphone_manager = StreamingMicrophoneManager()
        stt_manager = UnifiedSTTManager(stt_config)
        llm_manager = EnhancedLLMManager(llm_config)  # Module existant
        tts_manager = UnifiedTTSManager(tts_config)  # TTS EXISTANT INCHANG√â
        audio_manager = AudioOutputManager()
        
        print("‚úÖ Tous les composants initialis√©s")
        
        # √âTAPE 1: Enregistrement microphone
        print("\nüé§ √âTAPE 1: ENREGISTREMENT MICROPHONE")
        print("üî¥ Parlez maintenant pendant 10 secondes...")
        print("üí¨ Dites quelque chose comme: 'Bonjour SuperWhisper, comment allez-vous ?'")
        
        start_total = time.time()
        start_mic = time.time()
        
        # Enregistrement 10 secondes
        audio_data = await microphone_manager.record_audio(duration_seconds=10)
        
        end_mic = time.time()
        mic_latency = (end_mic - start_mic) * 1000
        
        if not audio_data:
            print("üö´ √âCHEC: Aucun audio enregistr√©")
            return False
        
        print(f"‚úÖ Audio enregistr√©: {len(audio_data):,} bytes")
        print(f"‚ö° Latence microphone: {mic_latency:.1f}ms")
        
        # √âTAPE 2: Transcription STT
        print("\nüéØ √âTAPE 2: TRANSCRIPTION STT")
        start_stt = time.time()
        
        stt_result = await stt_manager.transcribe_audio(audio_data)
        
        end_stt = time.time()
        stt_latency = (end_stt - start_stt) * 1000
        
        if not stt_result or not stt_result.text:
            print("üö´ √âCHEC: Transcription STT √©chou√©e")
            return False
        
        transcribed_text = stt_result.text.strip()
        print(f"‚úÖ Transcription: '{transcribed_text}'")
        print(f"‚ö° Latence STT: {stt_latency:.1f}ms")
        
        # √âTAPE 3: G√©n√©ration r√©ponse LLM
        print("\nü§ñ √âTAPE 3: G√âN√âRATION R√âPONSE LLM")
        start_llm = time.time()
        
        prompt = f"R√©pondez bri√®vement et naturellement √†: {transcribed_text}"
        llm_response = await llm_manager.generate_response(prompt)
        
        end_llm = time.time()
        llm_latency = (end_llm - start_llm) * 1000
        
        if not llm_response:
            print("üö´ √âCHEC: G√©n√©ration LLM √©chou√©e")
            return False
        
        print(f"‚úÖ R√©ponse LLM: '{llm_response}'")
        print(f"‚ö° Latence LLM: {llm_latency:.1f}ms")
        
        # √âTAPE 4: Synth√®se TTS
        print("\nüîä √âTAPE 4: SYNTH√àSE TTS (EXISTANT INCHANG√â)")
        start_tts = time.time()
        
        tts_result = await tts_manager.synthesize(llm_response)
        
        end_tts = time.time()
        tts_latency = (end_tts - start_tts) * 1000
        
        if not tts_result or not tts_result.success or not tts_result.audio_data:
            print("üö´ √âCHEC: Synth√®se TTS √©chou√©e")
            if tts_result:
                print(f"‚ùå Erreur TTS: {tts_result.error}")
            return False
        
        print(f"‚úÖ TTS r√©ussi: {tts_result.backend_used}")
        print(f"üîä Audio g√©n√©r√©: {len(tts_result.audio_data):,} bytes")
        print(f"‚ö° Latence TTS: {tts_latency:.1f}ms")
        
        # √âTAPE 5: Lecture audio
        print("\nüîà √âTAPE 5: LECTURE AUDIO R√âPONSE")
        start_audio = time.time()
        
        # Sauvegarde audio r√©ponse
        output_file = Path("PIPELINE/test_output/pipeline_complet_reponse.wav")
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'wb') as f:
            f.write(tts_result.audio_data)
        
        # Lecture audio
        await audio_manager.play_audio(tts_result.audio_data)
        
        end_audio = time.time()
        audio_latency = (end_audio - start_audio) * 1000
        
        end_total = time.time()
        total_latency = (end_total - start_total) * 1000
        
        print(f"‚úÖ Audio lu avec succ√®s")
        print(f"‚ö° Latence audio: {audio_latency:.1f}ms")
        print(f"üíæ Fichier sauvegard√©: {output_file}")
        
        # M√âTRIQUES FINALES
        print("\n" + "="*70)
        print("üìä M√âTRIQUES PIPELINE COMPLET")
        print("="*70)
        print(f"üé§ Microphone: {mic_latency:.1f}ms")
        print(f"üéØ STT: {stt_latency:.1f}ms")
        print(f"ü§ñ LLM: {llm_latency:.1f}ms")
        print(f"üîä TTS: {tts_latency:.1f}ms")
        print(f"üîà Audio: {audio_latency:.1f}ms")
        print(f"‚ö° TOTAL: {total_latency:.1f}ms")
        
        # Objectif < 1200ms
        objectif_ms = 1200
        if total_latency < objectif_ms:
            print(f"üéØ OBJECTIF ATTEINT: {total_latency:.1f}ms < {objectif_ms}ms ‚úÖ")
        else:
            print(f"‚ö†Ô∏è OBJECTIF MANQU√â: {total_latency:.1f}ms > {objectif_ms}ms")
        
        # VALIDATION HUMAINE OBLIGATOIRE
        print("\n" + "="*70)
        print("üéß VALIDATION HUMAINE PIPELINE COMPLET")
        print("="*70)
        print("üîÑ PIPELINE TEST√â:")
        print(f"   1. üé§ Votre parole ‚Üí Transcription: '{transcribed_text}'")
        print(f"   2. ü§ñ LLM ‚Üí R√©ponse: '{llm_response}'")
        print(f"   3. üîä TTS ‚Üí Audio lu automatiquement")
        print()
        print("‚ùì QUESTIONS VALIDATION:")
        print("   - Avez-vous entendu votre r√©ponse vocale ?")
        print("   - La conversation voix-√†-voix fonctionne-t-elle ?")
        print("   - Le pipeline complet est-il op√©rationnel ?")
        
        response = input("\n‚úÖ Validation pipeline complet (o/n): ").strip().lower()
        
        if response in ['o', 'oui', 'y', 'yes']:
            print("üéä VALIDATION HUMAINE PIPELINE COMPLET R√âUSSIE!")
            
            # M√©triques finales
            metrics = {
                "validation_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "pipeline_test": "COMPLETE_SUCCESS",
                "transcribed_text": transcribed_text,
                "llm_response": llm_response,
                "backend_used": tts_result.backend_used,
                "latencies": {
                    "microphone_ms": mic_latency,
                    "stt_ms": stt_latency,
                    "llm_ms": llm_latency,
                    "tts_ms": tts_latency,
                    "audio_ms": audio_latency,
                    "total_ms": total_latency
                },
                "objective_1200ms": total_latency < 1200,
                "audio_sizes": {
                    "input_bytes": len(audio_data),
                    "output_bytes": len(tts_result.audio_data)
                },
                "gpu_config": "RTX 3090 (CUDA:1)",
                "human_validation": "SUCCESS",
                "pipeline_complete": True
            }
            
            metrics_file = Path("PIPELINE/reports/validation_pipeline_complet.json")
            metrics_file.parent.mkdir(exist_ok=True)
            
            with open(metrics_file, 'w', encoding='utf-8') as f:
                json.dump(metrics, f, indent=2, ensure_ascii=False)
            
            print(f"üìä M√©triques compl√®tes sauvegard√©es: {metrics_file}")
            return True
        else:
            print("‚ùå VALIDATION HUMAINE PIPELINE COMPLET √âCHOU√âE")
            return False
            
    except Exception as e:
        print(f"üí• ERREUR PIPELINE COMPLET: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Point d'entr√©e principal"""
    print("üéØ VALIDATION HUMAINE PIPELINE COMPLET VOIX-√Ä-VOIX")
    print("üö® RTX 3090 (CUDA:1) OBLIGATOIRE")
    print("üîÑ Test conversation r√©elle: Microphone ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Audio")
    print()
    
    success = await test_pipeline_voix_a_voix_complet()
    
    if success:
        print("\nüéä SUCC√àS COMPLET - PIPELINE VOIX-√Ä-VOIX VALID√â!")
        print("‚úÖ Conversation r√©elle fonctionnelle")
        print("‚úÖ Pipeline complet op√©rationnel")
        print("‚úÖ T√¢che 4 Validation Humaine TERMIN√âE")
    else:
        print("\n‚ùå √âCHEC - Pipeline voix-√†-voix non valid√©")
        print("üîß Probl√®me dans le pipeline complet")
    
    return success

if __name__ == "__main__":
    asyncio.run(main()) 