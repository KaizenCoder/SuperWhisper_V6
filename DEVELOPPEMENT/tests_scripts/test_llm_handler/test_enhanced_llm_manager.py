# tests/test_enhanced_llm_manager.py
"""
Tests pour EnhancedLLMManager - Validation conversation multi-tours
Conforme aux sp√©cifications du Plan de D√©veloppement LUXA Final
"""
import pytest
import asyncio
import yaml
import tempfile
import time
from pathlib import Path
import sys
import logging

# Configuration logging pour debug
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ajout du r√©pertoire parent au path
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

from LLM.llm_manager_enhanced import EnhancedLLMManager, ConversationTurn

@pytest.mark.asyncio
async def test_enhanced_llm_manager_conversation_handling():
    """
    Test de validation conversation multi-tours
    Crit√®res: Contexte conversationnel, m√©triques, gestion historique
    """
    print("\n" + "="*80)
    print("TEST ENHANCED LLM MANAGER - CONVERSATION HANDLING")
    print("="*80)
    
    # 1. Configuration test
    config_path = Path("Config/mvp_settings.yaml")
    if not config_path.exists():
        pytest.skip(f"Configuration non trouv√©e: {config_path}")
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # Configuration LLM pour test (mod√®le plus petit)
    llm_config = config.get('llm', {})
    llm_config.update({
        'max_context_turns': 3,  # Limiter pour test
        'max_history_size': 10,
        'model_path': llm_config.get('model_path', './models/test_model.gguf')
    })
    
    # 2. Initialisation
    print("\nüìã Initialisation EnhancedLLMManager...")
    try:
        llm_manager = EnhancedLLMManager(llm_config)
        await llm_manager.initialize()
        print("‚úÖ LLM Manager initialis√©")
    except Exception as e:
        pytest.skip(f"Impossible d'initialiser LLM: {e}")
    
    # 3. Test 1 : Conversation de base sans contexte
    print("\nüß™ TEST 1 : R√©ponse simple sans contexte")
    
    response1 = await llm_manager.generate_response(
        "Bonjour, comment allez-vous ?",
        max_tokens=50,
        include_context=False
    )
    
    assert response1, "R√©ponse vide pour salutation simple"
    assert len(response1) > 5, "R√©ponse trop courte"
    print(f"üìù R√©ponse 1: '{response1}'")
    
    # V√©rification m√©triques
    metrics1 = llm_manager.get_metrics()
    assert metrics1['total_requests'] == 1, "Compteur requ√™tes incorrect"
    assert metrics1['conversation_turns'] == 1, "Compteur tours incorrect"
    
    print("‚úÖ TEST 1 R√âUSSI : R√©ponse simple fonctionnelle")
    
    # 4. Test 2 : Conversation multi-tours avec contexte
    print("\nüß™ TEST 2 : Conversation multi-tours")
    
    # Tour 2
    response2 = await llm_manager.generate_response(
        "Pouvez-vous me rappeler ce que je viens de dire ?",
        max_tokens=80,
        include_context=True
    )
    
    assert response2, "R√©ponse vide pour question contextuelle"
    
    # V√©rifier que le contexte est pris en compte
    # Le mod√®le devrait faire r√©f√©rence √† la salutation pr√©c√©dente
    context_keywords = ["bonjour", "salutation", "dit", "demand√©"]
    has_context = any(keyword in response2.lower() for keyword in context_keywords)
    
    print(f"üìù R√©ponse 2: '{response2}'")
    print(f"üîç Contexte d√©tect√©: {has_context}")
    
    # Tour 3
    response3 = await llm_manager.generate_response(
        "Et maintenant, quel est le sujet de notre conversation ?",
        max_tokens=80,
        include_context=True
    )
    
    assert response3, "R√©ponse vide pour question m√©taconversationnelle"
    print(f"üìù R√©ponse 3: '{response3}'")
    
    # V√©rification m√©triques
    metrics2 = llm_manager.get_metrics()
    assert metrics2['total_requests'] == 3, "Compteur requ√™tes incorrect apr√®s 3 tours"
    assert metrics2['conversation_turns'] == 3, "Compteur tours incorrect"
    assert metrics2['avg_response_time'] > 0, "Latence moyenne non calcul√©e"
    
    print("‚úÖ TEST 2 R√âUSSI : Conversation multi-tours fonctionnelle")
    
    # 5. Test 3 : R√©sum√© de conversation
    print("\nüß™ TEST 3 : R√©sum√© de conversation")
    
    summary = llm_manager.get_conversation_summary()
    
    assert summary['status'] != 'no_conversation', "R√©sum√© indique aucune conversation"
    assert summary['total_turns'] == 3, "Nombre de tours incorrect dans r√©sum√©"
    assert summary['duration_minutes'] > 0, "Dur√©e conversation nulle"
    assert 'topics' in summary, "Topics manquants dans r√©sum√©"
    assert 'sentiment' in summary, "Sentiment manquant dans r√©sum√©"
    
    print(f"üìä R√©sum√© conversation:")
    print(f"   - Tours: {summary['total_turns']}")
    print(f"   - Dur√©e: {summary['duration_minutes']:.2f} min")
    print(f"   - Topics: {summary['topics']}")
    print(f"   - Sentiment: {summary['sentiment']}")
    
    print("‚úÖ TEST 3 R√âUSSI : R√©sum√© conversation complet")
    
    # 6. Test 4 : Gestion historique limite
    print("\nüß™ TEST 4 : Gestion limite historique")
    
    # Ajouter plus de tours pour tester la limite
    for i in range(5):
        await llm_manager.generate_response(
            f"Message test {i+4} pour remplir l'historique",
            max_tokens=20
        )
    
    # V√©rifier que l'historique est limit√©
    current_turns = len(llm_manager.conversation_history)
    max_history = llm_config.get('max_history_size', 10)
    
    assert current_turns <= max_history, f"Historique d√©passe limite: {current_turns} > {max_history}"
    
    print(f"üìö Historique actuel: {current_turns} tours (limite: {max_history})")
    print("‚úÖ TEST 4 R√âUSSI : Gestion limite historique")
    
    # 7. Test 5 : Nettoyage conversation
    print("\nüß™ TEST 5 : Nettoyage conversation")
    
    llm_manager.clear_conversation()
    
    assert len(llm_manager.conversation_history) == 0, "Historique non vid√©"
    
    summary_vide = llm_manager.get_conversation_summary()
    assert summary_vide['status'] == 'no_conversation', "R√©sum√© devrait indiquer aucune conversation"
    
    print("üßπ Conversation nettoy√©e")
    print("‚úÖ TEST 5 R√âUSSI : Nettoyage conversation")
    
    # 8. Nettoyage final
    await llm_manager.cleanup()
    
    # R√©sum√© final
    print("\n" + "="*80)
    print("‚úÖ VALIDATION COMPL√àTE R√âUSSIE")
    print(f"   - Tests conversationnels: 5/5 r√©ussis")
    print(f"   - Contexte multi-tours: Fonctionnel")
    print(f"   - M√©triques monitoring: Compl√®tes")
    print(f"   - Gestion historique: Op√©rationnelle")
    print("="*80)

@pytest.mark.asyncio
async def test_context_building():
    """Test sp√©cifique de construction du contexte"""
    print("\nüß™ TEST CONTEXT BUILDING")
    
    config = {
        'model_path': './models/test_model.gguf',
        'max_context_turns': 2,
        'n_gpu_layers': 0  # Force CPU pour test
    }
    
    llm_manager = EnhancedLLMManager(config)
    
    # Ajouter manuellement des tours pour tester
    llm_manager._add_to_history("Premi√®re question", "Premi√®re r√©ponse")
    llm_manager._add_to_history("Deuxi√®me question", "Deuxi√®me r√©ponse")
    llm_manager._add_to_history("Troisi√®me question", "Troisi√®me r√©ponse")
    
    # Test construction contexte
    prompt = llm_manager._build_contextual_prompt("Question actuelle", include_context=True)
    
    # V√©rifications
    assert "Conversation r√©cente:" in prompt, "Header contexte manquant"
    assert "Question actuelle" in prompt, "Question actuelle manquante"
    assert "Assistant:" in prompt, "Prompt de r√©ponse manquant"
    
    # V√©rifier limitation contexte (max 2 tours)
    lines = prompt.split('\n')
    utilisateur_lines = [line for line in lines if line.startswith('Utilisateur:')]
    
    # Devrait avoir maximum 2 tours + 1 actuel = 3 "Utilisateur:"
    assert len(utilisateur_lines) <= 3, f"Trop de tours dans contexte: {len(utilisateur_lines)}"
    
    print("‚úÖ Construction contexte valid√©e")

@pytest.mark.asyncio 
async def test_response_cleaning():
    """Test du nettoyage des r√©ponses"""
    print("\nüß™ TEST RESPONSE CLEANING")
    
    config = {
        'model_path': './models/test_model.gguf',
        'n_gpu_layers': 0
    }
    
    llm_manager = EnhancedLLMManager(config)
    
    # Tests de nettoyage
    test_cases = [
        ("Assistant: Voici ma r√©ponse", "Voici ma r√©ponse"),
        ("Utilisateur: Question\nAssistant: R√©ponse", "R√©ponse"),
        ("   R√©ponse avec espaces   ", "R√©ponse avec espaces"),
        ("R√©ponse tr√®s longue " + "qui d√©passe " * 50 + "la limite.", 
         "R√©ponse tr√®s longue " + "qui d√©passe " * 45)  # Approximativement
    ]
    
    for raw_response, expected_type in test_cases:
        cleaned = llm_manager._clean_response(raw_response)
        
        assert cleaned != raw_response or len(raw_response) < 50, "Nettoyage non appliqu√©"
        assert not cleaned.startswith("Assistant:"), "Pr√©fixe Assistant: non supprim√©"
        assert len(cleaned) <= 500, "R√©ponse trop longue non coup√©e"
        
    print("‚úÖ Nettoyage r√©ponses valid√©")

if __name__ == "__main__":
    # Ex√©cution directe pour tests manuels
    asyncio.run(test_enhanced_llm_manager_conversation_handling()) 