#!/usr/bin/env python3
"""
DÃ©monstration streaming microphone SuperWhisper V6
Solution des experts - Test simple et rapide
"""

import os
import sys
import asyncio
from pathlib import Path

# =============================================================================
# ðŸš¨ CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation mÃ©moire

print("ðŸŽ® Demo Streaming Microphone - Configuration GPU RTX 3090 (CUDA:1) forcÃ©e")
print(f"ðŸ”’ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajouter le rÃ©pertoire parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Imports aprÃ¨s configuration GPU
import torch
from STT.unified_stt_manager import UnifiedSTTManager
from STT.streaming_microphone_manager import StreamingMicrophoneManager

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    if not torch.cuda.is_available():
        raise RuntimeError("ðŸš« CUDA non disponible - RTX 3090 requise")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"ðŸš« CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit Ãªtre '1'")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 = ~24GB
        raise RuntimeError(f"ðŸš« GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
    
    print(f"âœ… RTX 3090 validÃ©e: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")

async def main():
    """DÃ©monstration principale"""
    print("ðŸš€ DÃ©monstration streaming microphone SuperWhisper V6")
    print("=" * 50)
    
    # Validation GPU RTX 3090
    try:
        validate_rtx3090_configuration()
    except Exception as e:
        print(f"âŒ Erreur configuration GPU: {e}")
        return
    
    print("\nðŸ”§ Initialisation des managers...")
    
    try:
        # Initialisation STT Manager
        stt_mgr = UnifiedSTTManager()
        print("âœ… UnifiedSTTManager initialisÃ©")
        
        # Initialisation Streaming Microphone Manager
        mic_mgr = StreamingMicrophoneManager(stt_mgr)
        print("âœ… StreamingMicrophoneManager initialisÃ©")
        
        print("\nðŸŽ¤ DÃ©marrage capture microphone...")
        print("Parlez maintenant! (Ctrl+C pour arrÃªter)")
        print("Objectif: Premier token < 800ms, RTF live â‰ˆ 0.1")
        print("-" * 50)
        
        # DÃ©marrage streaming
        await mic_mgr.run()
        
    except KeyboardInterrupt:
        print("\nðŸ›‘ ArrÃªt demandÃ© par l'utilisateur")
    except Exception as e:
        print(f"\nâŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nðŸŽ¯ DÃ©monstration terminÃ©e")

if __name__ == "__main__":
    print("ðŸŽ¯ DÃ©marrage dÃ©monstration streaming microphone...")
    
    try:
        asyncio.run(main())
        print("\nâœ… DÃ©monstration terminÃ©e avec succÃ¨s")
    except KeyboardInterrupt:
        print("\nðŸ›‘ DÃ©monstration interrompue")
    except Exception as e:
        print(f"\nðŸ’¥ Erreur fatale: {e}")
        sys.exit(1) 