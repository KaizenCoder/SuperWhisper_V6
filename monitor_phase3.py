#!/usr/bin/env python3
"""
Monitoring Phase 3 - SuperWhisper V6 TTS
Surveillance en temps r√©el des m√©triques de performance
üöÄ Dashboard des optimisations Phase 3
"""

import os
import sys
import asyncio
import logging
import time
import json
from pathlib import Path
from datetime import datetime, timedelta
from collections import deque
import threading

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'

print("üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Import du syst√®me TTS
try:
    from TTS.tts_manager import UnifiedTTSManager
    from TTS.utils_audio import is_valid_wav, get_wav_info
    import yaml
    TTS_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Syst√®me TTS non disponible: {e}")
    TTS_AVAILABLE = False

class Phase3Monitor:
    """
    Monitoring en temps r√©el des performances Phase 3
    
    üöÄ M√âTRIQUES SURVEILL√âES:
    1. Latence de synth√®se (ms)
    2. D√©bit de traitement (chars/ms)
    3. Taux de cache hit (%)
    4. Utilisation m√©moire (MB)
    5. Backends utilis√©s
    6. Erreurs et fallbacks
    """
    
    def __init__(self, monitoring_duration_minutes=5):
        self.monitoring_duration = monitoring_duration_minutes
        self.tts_manager = None
        self.metrics = {
            'synthesis_times': deque(maxlen=100),
            'cache_hits': deque(maxlen=100),
            'cache_misses': deque(maxlen=100),
            'backend_usage': {},
            'errors': deque(maxlen=50),
            'throughput': deque(maxlen=100),
            'audio_sizes': deque(maxlen=100)
        }
        self.start_time = None
        self.running = False
        
        # Textes de test vari√©s
        self.test_texts = [
            "Bonjour, test de performance.",
            "SuperWhisper V6 est un assistant vocal avanc√©.",
            "Les optimisations Phase 3 am√©liorent significativement les performances du syst√®me TTS.",
            "L'intelligence artificielle conversationnelle repr√©sente l'avenir des interactions homme-machine.",
            """SuperWhisper V6 int√®gre des technologies de pointe pour offrir une exp√©rience utilisateur 
            exceptionnelle avec des temps de r√©ponse optimis√©s et une qualit√© audio remarquable.""",
            "Test de cache - message r√©current.",  # Pour tester le cache
            "Test de cache - message r√©current.",  # R√©p√©tition pour cache hit
        ]
        
        print("üìä Phase 3 Monitor initialis√©")
        print(f"‚è±Ô∏è Dur√©e monitoring: {monitoring_duration_minutes} minutes")
        print(f"üìù {len(self.test_texts)} textes de test pr√©par√©s")
    
    async def start_monitoring(self):
        """D√©marrage du monitoring en temps r√©el"""
        print("\n" + "="*80)
        print("üìä D√âMARRAGE MONITORING PHASE 3")
        print("="*80)
        
        if not TTS_AVAILABLE:
            print("‚ùå Syst√®me TTS non disponible")
            return
        
        try:
            # Initialisation du TTS Manager
            await self._initialize_tts_manager()
            
            # D√©marrage du monitoring
            self.start_time = time.time()
            self.running = True
            
            print(f"\nüöÄ Monitoring d√©marr√© pour {self.monitoring_duration} minutes")
            print("üìä M√©triques collect√©es en temps r√©el...")
            print("üîÑ Appuyez sur Ctrl+C pour arr√™ter\n")
            
            # Boucle de monitoring
            await self._monitoring_loop()
            
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è Monitoring interrompu par l'utilisateur")
        except Exception as e:
            print(f"‚ùå Erreur monitoring: {e}")
            logging.exception("Erreur d√©taill√©e:")
        finally:
            self.running = False
            if self.tts_manager:
                await self.tts_manager.cleanup()
            
            # G√©n√©ration du rapport final
            self._generate_monitoring_report()
    
    async def _initialize_tts_manager(self):
        """Initialisation du TTS Manager"""
        print("üîß Initialisation TTS Manager...")
        
        # Chargement de la configuration
        config_path = Path("config/tts.yaml")
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        start_time = time.perf_counter()
        self.tts_manager = UnifiedTTSManager(config)
        init_time = (time.perf_counter() - start_time) * 1000
        
        print(f"‚úÖ TTS Manager initialis√© en {init_time:.1f}ms")
    
    async def _monitoring_loop(self):
        """Boucle principale de monitoring"""
        test_count = 0
        last_report_time = time.time()
        
        while self.running:
            # V√©rification du temps √©coul√©
            elapsed_time = time.time() - self.start_time
            if elapsed_time >= (self.monitoring_duration * 60):
                print(f"\n‚è∞ Dur√©e de monitoring atteinte ({self.monitoring_duration} min)")
                break
            
            try:
                # S√©lection d'un texte de test
                text = self.test_texts[test_count % len(self.test_texts)]
                test_count += 1
                
                # Test de synth√®se
                await self._perform_synthesis_test(text, test_count)
                
                # Rapport p√©riodique (toutes les 30 secondes)
                if time.time() - last_report_time >= 30:
                    self._print_live_metrics()
                    last_report_time = time.time()
                
                # Pause entre les tests
                await asyncio.sleep(2)
                
            except Exception as e:
                self.metrics['errors'].append({
                    'timestamp': datetime.now().isoformat(),
                    'error': str(e),
                    'test_count': test_count
                })
                print(f"‚ö†Ô∏è Erreur test #{test_count}: {e}")
                await asyncio.sleep(1)
    
    async def _perform_synthesis_test(self, text, test_count):
        """Ex√©cution d'un test de synth√®se avec collecte de m√©triques"""
        start_time = time.perf_counter()
        
        try:
            # Synth√®se
            tts_result = await self.tts_manager.synthesize(text)
            synthesis_time = (time.perf_counter() - start_time) * 1000
            
            # Extraction des donn√©es audio
            if hasattr(tts_result, 'audio_data'):
                audio_data = tts_result.audio_data
            else:
                audio_data = tts_result
            
            # Collecte des m√©triques
            self.metrics['synthesis_times'].append(synthesis_time)
            self.metrics['throughput'].append(len(text) / synthesis_time if synthesis_time > 0 else 0)
            self.metrics['audio_sizes'].append(len(audio_data))
            
            # D√©tection cache hit (temps tr√®s rapide)
            if synthesis_time < 10:  # <10ms = probablement cache hit
                self.metrics['cache_hits'].append(test_count)
            else:
                self.metrics['cache_misses'].append(test_count)
            
            # Backend utilis√© (estimation bas√©e sur la latence)
            backend = self._estimate_backend_used(synthesis_time)
            if backend in self.metrics['backend_usage']:
                self.metrics['backend_usage'][backend] += 1
            else:
                self.metrics['backend_usage'][backend] = 1
            
            # Affichage en temps r√©el
            cache_status = "üíæ HIT" if synthesis_time < 10 else "üîÑ MISS"
            print(f"Test #{test_count:3d}: {synthesis_time:6.1f}ms | {len(text):3d} chars | {cache_status} | {backend}")
            
        except Exception as e:
            self.metrics['errors'].append({
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'test_count': test_count,
                'text_length': len(text)
            })
            raise
    
    def _estimate_backend_used(self, synthesis_time):
        """Estimation du backend utilis√© bas√©e sur la latence"""
        if synthesis_time < 10:
            return "cache"
        elif synthesis_time < 100:
            return "piper_native_optimized"
        elif synthesis_time < 500:
            return "piper_native"
        elif synthesis_time < 1500:
            return "piper_cli"
        elif synthesis_time < 3000:
            return "sapi_french"
        else:
            return "unknown"
    
    def _print_live_metrics(self):
        """Affichage des m√©triques en temps r√©el"""
        elapsed = time.time() - self.start_time
        
        print("\n" + "="*60)
        print(f"üìä M√âTRIQUES LIVE - {elapsed/60:.1f} min √©coul√©es")
        print("="*60)
        
        # M√©triques de latence
        if self.metrics['synthesis_times']:
            times = list(self.metrics['synthesis_times'])
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            print(f"‚ö° Latence: {avg_time:.1f}ms (min: {min_time:.1f}ms, max: {max_time:.1f}ms)")
        
        # M√©triques de cache
        total_hits = len(self.metrics['cache_hits'])
        total_misses = len(self.metrics['cache_misses'])
        total_requests = total_hits + total_misses
        if total_requests > 0:
            hit_rate = (total_hits / total_requests) * 100
            print(f"üíæ Cache: {hit_rate:.1f}% hit rate ({total_hits}/{total_requests})")
        
        # M√©triques de d√©bit
        if self.metrics['throughput']:
            throughputs = list(self.metrics['throughput'])
            avg_throughput = sum(throughputs) / len(throughputs)
            print(f"üöÄ D√©bit: {avg_throughput:.3f} chars/ms")
        
        # Backends utilis√©s
        if self.metrics['backend_usage']:
            print("üîß Backends:")
            for backend, count in self.metrics['backend_usage'].items():
                percentage = (count / sum(self.metrics['backend_usage'].values())) * 100
                print(f"   {backend}: {count} ({percentage:.1f}%)")
        
        # Erreurs
        error_count = len(self.metrics['errors'])
        if error_count > 0:
            print(f"‚ö†Ô∏è Erreurs: {error_count}")
        
        print()
    
    def _generate_monitoring_report(self):
        """G√©n√©ration du rapport final de monitoring"""
        print("\n" + "="*80)
        print("üìä RAPPORT FINAL MONITORING PHASE 3")
        print("="*80)
        
        total_duration = time.time() - self.start_time if self.start_time else 0
        total_tests = len(self.metrics['synthesis_times'])
        
        print(f"‚è±Ô∏è Dur√©e totale: {total_duration/60:.1f} minutes")
        print(f"üß™ Tests effectu√©s: {total_tests}")
        print(f"üìä Fr√©quence: {total_tests/(total_duration/60):.1f} tests/min")
        print()
        
        # Analyse des performances
        if self.metrics['synthesis_times']:
            times = list(self.metrics['synthesis_times'])
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            
            print("‚ö° PERFORMANCES:")
            print(f"   Latence moyenne: {avg_time:.1f}ms")
            print(f"   Latence minimale: {min_time:.1f}ms")
            print(f"   Latence maximale: {max_time:.1f}ms")
            
            # Percentiles
            sorted_times = sorted(times)
            p50 = sorted_times[len(sorted_times)//2]
            p95 = sorted_times[int(len(sorted_times)*0.95)]
            print(f"   P50: {p50:.1f}ms")
            print(f"   P95: {p95:.1f}ms")
            print()
        
        # Analyse du cache
        total_hits = len(self.metrics['cache_hits'])
        total_misses = len(self.metrics['cache_misses'])
        total_requests = total_hits + total_misses
        
        if total_requests > 0:
            hit_rate = (total_hits / total_requests) * 100
            print("üíæ CACHE:")
            print(f"   Taux de hit: {hit_rate:.1f}%")
            print(f"   Hits: {total_hits}")
            print(f"   Misses: {total_misses}")
            print()
        
        # Analyse des backends
        if self.metrics['backend_usage']:
            print("üîß BACKENDS UTILIS√âS:")
            total_backend_calls = sum(self.metrics['backend_usage'].values())
            for backend, count in sorted(self.metrics['backend_usage'].items(), key=lambda x: x[1], reverse=True):
                percentage = (count / total_backend_calls) * 100
                print(f"   {backend}: {count} ({percentage:.1f}%)")
            print()
        
        # Analyse du d√©bit
        if self.metrics['throughput']:
            throughputs = list(self.metrics['throughput'])
            avg_throughput = sum(throughputs) / len(throughputs)
            max_throughput = max(throughputs)
            print("üöÄ D√âBIT:")
            print(f"   D√©bit moyen: {avg_throughput:.3f} chars/ms")
            print(f"   D√©bit maximal: {max_throughput:.3f} chars/ms")
            print()
        
        # Analyse des erreurs
        error_count = len(self.metrics['errors'])
        if error_count > 0:
            print("‚ö†Ô∏è ERREURS:")
            print(f"   Total: {error_count}")
            print(f"   Taux d'erreur: {(error_count/total_tests)*100:.1f}%")
            
            # Derni√®res erreurs
            recent_errors = list(self.metrics['errors'])[-3:]
            for error in recent_errors:
                print(f"   - {error['timestamp']}: {error['error']}")
            print()
        
        # Validation des objectifs Phase 3
        print("üéØ OBJECTIFS PHASE 3:")
        
        # Objectif latence
        if self.metrics['synthesis_times']:
            avg_time = sum(self.metrics['synthesis_times']) / len(self.metrics['synthesis_times'])
            latency_ok = avg_time < 1000  # <1s acceptable
            print(f"   Latence <1s: {'‚úÖ' if latency_ok else '‚ö†Ô∏è'} ({avg_time:.1f}ms)")
        
        # Objectif cache
        cache_ok = hit_rate > 10 if total_requests > 0 else False  # >10% hit rate
        print(f"   Cache efficace: {'‚úÖ' if cache_ok else '‚ö†Ô∏è'} ({hit_rate:.1f}%)")
        
        # Objectif stabilit√©
        stability_ok = error_count < (total_tests * 0.05)  # <5% erreurs
        print(f"   Stabilit√© >95%: {'‚úÖ' if stability_ok else '‚ö†Ô∏è'} ({((total_tests-error_count)/total_tests)*100:.1f}%)")
        
        print("\nüéâ Monitoring Phase 3 termin√©!")
        
        # Sauvegarde des m√©triques
        self._save_metrics_to_file()
    
    def _save_metrics_to_file(self):
        """Sauvegarde des m√©triques dans un fichier JSON"""
        try:
            metrics_data = {
                'timestamp': datetime.now().isoformat(),
                'duration_minutes': (time.time() - self.start_time) / 60 if self.start_time else 0,
                'total_tests': len(self.metrics['synthesis_times']),
                'synthesis_times': list(self.metrics['synthesis_times']),
                'cache_hits': len(self.metrics['cache_hits']),
                'cache_misses': len(self.metrics['cache_misses']),
                'backend_usage': dict(self.metrics['backend_usage']),
                'errors': list(self.metrics['errors']),
                'throughput': list(self.metrics['throughput']),
                'audio_sizes': list(self.metrics['audio_sizes'])
            }
            
            # Sauvegarde
            metrics_file = Path(f"monitoring_phase3_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
            with open(metrics_file, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, indent=2, ensure_ascii=False)
            
            print(f"üíæ M√©triques sauvegard√©es: {metrics_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sauvegarde m√©triques: {e}")

async def main():
    """Point d'entr√©e principal"""
    print("üìä SuperWhisper V6 - Monitoring Phase 3")
    print("üöÄ Surveillance en temps r√©el des performances TTS")
    
    # Dur√©e de monitoring (par d√©faut 5 minutes)
    duration = 5
    
    monitor = Phase3Monitor(monitoring_duration_minutes=duration)
    await monitor.start_monitoring()

if __name__ == "__main__":
    asyncio.run(main()) 