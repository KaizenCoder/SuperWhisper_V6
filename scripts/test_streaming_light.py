#!/usr/bin/env python3
"""
Test streaming microphone lÃ©ger - SuperWhisper V6
Utilise le modÃ¨le small pour un test rapide

ğŸš¨ CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# ğŸš€ PORTABILITÃ‰ AUTOMATIQUE - EXÃ‰CUTABLE DEPUIS N'IMPORTE OÃ™
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour exÃ©cution portable"""
    # DÃ©terminer le rÃ©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le rÃ©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"ğŸ® GPU Configuration: RTX 3090 (CUDA:1) forcÃ©e")
    print(f"ğŸ“ Project Root: {project_root}")
    print(f"ğŸ’» Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import asyncio
import time
from pathlib import Path

# =============================================================================
# ğŸš¨ CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation mÃ©moire

print("ğŸ® Test Streaming LÃ©ger - Configuration GPU RTX 3090 (CUDA:1)")
print(f"ğŸ”’ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajouter le rÃ©pertoire parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Imports
import torch
import sounddevice as sd
import webrtcvad
import numpy as np

class LightStreamingTest:
    """Test streaming lÃ©ger sans modÃ¨les lourds"""
    
    def __init__(self):
        self.frame_count = 0
        self.speech_detected = 0
        
    def test_audio_capture(self, duration=5):
        """Test simple de capture audio"""
        print(f"ğŸ¤ Test capture audio ({duration}s)...")
        
        sample_rate = 16000
        frames_collected = []
        
        def callback(indata, frames, time, status):
            if status:
                print(f"âš ï¸ Status: {status}")
            frames_collected.append(indata.copy())
        
        try:
            with sd.InputStream(
                samplerate=sample_rate,
                channels=1,
                dtype='int16',
                callback=callback
            ):
                print("ğŸ”´ Enregistrement... parlez maintenant!")
                time.sleep(duration)
                
            total_frames = len(frames_collected)
            print(f"âœ… Capture terminÃ©e: {total_frames} frames collectÃ©es")
            return True
            
        except Exception as e:
            print(f"âŒ Erreur capture: {e}")
            return False
    
    def test_vad_processing(self):
        """Test traitement VAD simple"""
        print("ğŸ” Test VAD...")
        
        try:
            vad = webrtcvad.Vad(2)
            
            # Test avec silence
            silence = np.zeros(320, dtype=np.int16)  # 20ms Ã  16kHz
            is_speech_silence = vad.is_speech(silence.tobytes(), 16000)
            
            # Test avec bruit simulÃ©
            noise = (np.random.random(320) * 1000).astype(np.int16)
            is_speech_noise = vad.is_speech(noise.tobytes(), 16000)
            
            print(f"âœ… VAD silence: {is_speech_silence} (doit Ãªtre False)")
            print(f"âœ… VAD bruit: {is_speech_noise}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Erreur VAD: {e}")
            return False
    
    def test_streaming_simulation(self, duration=10):
        """Simulation streaming sans STT"""
        print(f"ğŸ”„ Simulation streaming ({duration}s)...")
        
        sample_rate = 16000
        frame_duration_ms = 20
        frame_size = sample_rate * frame_duration_ms // 1000
        
        try:
            vad = webrtcvad.Vad(2)
            speech_frames = []
            silence_count = 0
            max_silence = 20  # 400ms de silence
            
            def process_frame(indata, frames, time, status):
                self.frame_count += 1
                
                # Convertir en int16
                frame_int16 = (indata[:, 0] * 32767).astype(np.int16)
                
                # VAD
                is_speech = vad.is_speech(frame_int16.tobytes(), sample_rate)
                
                if is_speech:
                    speech_frames.append(frame_int16)
                    silence_count = 0
                    self.speech_detected += 1
                    print(f"ğŸ—£ï¸ Parole dÃ©tectÃ©e (frame {self.frame_count})")
                else:
                    silence_count += 1
                    
                    # Fin d'Ã©noncÃ© dÃ©tectÃ©e
                    if speech_frames and silence_count >= max_silence:
                        total_audio = np.concatenate(speech_frames)
                        duration_ms = len(total_audio) / sample_rate * 1000
                        print(f"ğŸ“ Ã‰noncÃ© terminÃ©: {duration_ms:.0f}ms, {len(speech_frames)} frames")
                        
                        # Reset pour prochain Ã©noncÃ©
                        speech_frames.clear()
                        silence_count = 0
            
            with sd.InputStream(
                samplerate=sample_rate,
                blocksize=frame_size,
                channels=1,
                dtype='float32',
                callback=process_frame
            ):
                print("ğŸ”´ Streaming actif... parlez!")
                time.sleep(duration)
            
            print(f"âœ… Streaming terminÃ©: {self.frame_count} frames, {self.speech_detected} avec parole")
            return True
            
        except Exception as e:
            print(f"âŒ Erreur streaming: {e}")
            return False

def test_device_list():
    """Liste les pÃ©riphÃ©riques audio"""
    print("ğŸ¤ PÃ©riphÃ©riques audio:")
    try:
        devices = sd.query_devices()
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:
                print(f"  {i}: {device['name']} ({device['max_input_channels']} ch)")
        return True
    except Exception as e:
        print(f"âŒ Erreur liste pÃ©riphÃ©riques: {e}")
        return False

def test_gpu_basic():
    """Test GPU basique"""
    print("ğŸ” Test GPU...")
    try:
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ… GPU: {gpu_name} ({gpu_memory:.1f}GB)")
            return True
        else:
            print("âŒ CUDA non disponible")
            return False
    except Exception as e:
        print(f"âŒ Erreur GPU: {e}")
        return False

async def main():
    """Test principal lÃ©ger"""
    print("ğŸš€ Test Streaming Microphone LÃ©ger - SuperWhisper V6")
    print("=" * 50)
    
    # Tests sÃ©quentiels
    tests = [
        ("GPU", test_gpu_basic),
        ("PÃ©riphÃ©riques", test_device_list),
        ("VAD", lambda: LightStreamingTest().test_vad_processing()),
        ("Capture Audio", lambda: LightStreamingTest().test_audio_capture(3)),
        ("Streaming Simulation", lambda: LightStreamingTest().test_streaming_simulation(10))
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nğŸ§ª Test {test_name}...")
        try:
            result = test_func()
            results.append((test_name, result))
            
            if result:
                print(f"âœ… {test_name}: RÃ‰USSI")
            else:
                print(f"âŒ {test_name}: Ã‰CHOUÃ‰")
                
        except Exception as e:
            print(f"ğŸ’¥ {test_name}: ERREUR - {e}")
            results.append((test_name, False))
    
    # RÃ©sultats finaux
    print("\nğŸ“Š RÃ©sultats finaux:")
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ…" if result else "âŒ"
        print(f"  {status} {test_name}")
    
    print(f"\nğŸ¯ Score: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ TOUS LES TESTS LÃ‰GERS RÃ‰USSIS!")
        print("âœ… PrÃªt pour test avec STT complet")
        return True
    else:
        print("âš ï¸ Certains tests ont Ã©chouÃ©")
        print("ğŸ”§ Correction nÃ©cessaire avant STT")
        return False

if __name__ == "__main__":
    try:
        result = asyncio.run(main())
        
        if result:
            print("\nğŸ‰ VALIDATION LÃ‰GÃˆRE RÃ‰USSIE!")
            print("ğŸš€ ProcÃ©dez au test complet avec: python scripts/run_streaming_microphone_demo.py")
        else:
            print("\nâŒ VALIDATION LÃ‰GÃˆRE Ã‰CHOUÃ‰E")
            print("ğŸ”§ Corrigez les problÃ¨mes avant de continuer")
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ Test interrompu")
    except Exception as e:
        print(f"\nğŸ’¥ Erreur fatale: {e}")
        import traceback
        traceback.print_exc() 