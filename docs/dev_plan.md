# ğŸ“… PLAN DE DÃ‰VELOPPEMENT - CONSOLIDATION TTS PHASE 2 ENTERPRISE

**Date :** 2025-06-12  
**Version :** v2.0 Enterprise  
**DurÃ©e Totale :** 5.5 jours  
**Ã‰quipe :** SuperWhisper V6 Core Team  

---

## ğŸ¯ **VUE D'ENSEMBLE STRATÃ‰GIQUE**

### **Philosophie de DÃ©veloppement :**
- **Validation Continue :** Checkpoints bloquants Ã  chaque phase
- **PrÃ©servation des Acquis :** Architecture fonctionnelle maintenue
- **Approche Enterprise :** Robustesse + monitoring + performance

### **Architecture Cible :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 UnifiedTTSManager                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PiperNativeHandler â”‚ PiperCliHandler â”‚ SapiFrenchHandler â”‚ SilentEmergencyHandler â”‚
â”‚   <120ms GPU    â”‚   <1000ms CPU   â”‚   <2000ms SAPI    â”‚     <5ms Silence       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                 â”‚                 â”‚
         â–¼                 â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Circuit Breakersâ”‚   TTSCache      â”‚   Prometheus Metrics    â”‚
â”‚ 3 Ã©checs/30s    â”‚   100MB LRU     â”‚   Temps rÃ©el           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ **PHASE 0 : PRÃ‰PARATION (0.5 JOUR)**

### **ğŸ•’ Timing :** J0 - 09h00 â†’ 13h00 (4h)

#### **0.1 - Initialisation Git (1h) :**
```bash
# CrÃ©ation branche feature
git checkout -b feature/tts-enterprise-consolidation

# Tag de sauvegarde
git tag pre-tts-enterprise-consolidation
git push origin pre-tts-enterprise-consolidation

# Validation Ã©tat initial
git status
git log --oneline -5
```

#### **0.2 - Archivage Handlers ObsolÃ¨tes (2h) :**
```bash
# CrÃ©ation rÃ©pertoire archive
mkdir -p TTS/legacy_handlers_20250612

# Documentation rollback
cat > TTS/legacy_handlers_20250612/README_ROLLBACK.md << 'EOF'
# Archive Handlers TTS - 12 juin 2025

## Contexte
Consolidation 15â†’4 handlers suite Phase 2 Enterprise.
Handlers archivÃ©s car non-fonctionnels/redondants.

## Handlers ArchivÃ©s (13 fichiers)
- tts_handler_piper_native.py (dÃ©faillant)
- tts_handler_piper_rtx3090.py (dÃ©faillant)
- tts_handler_piper_simple.py (non testÃ©)
- tts_handler_piper_french.py (non testÃ©)
- tts_handler_piper_original.py (legacy)
- tts_handler_piper_direct.py (legacy)
- tts_handler_piper_espeak.py (legacy)
- tts_handler_piper_fixed.py (legacy)
- tts_handler_piper_cli.py (legacy)
- tts_handler_piper.py (legacy)
- tts_handler_coqui.py (alternatif)
- tts_handler_mvp.py (basique)
- tts_handler_fallback.py (interface manquante)

## Rollback Complet
```bash
# Restauration handlers
mv TTS/legacy_handlers_20250612/*.py TTS/
rm -rf TTS/legacy_handlers_20250612/

# Restauration Git
git checkout pre-tts-enterprise-consolidation
git branch -D feature/tts-enterprise-consolidation
```

## Rollback Partiel
```bash
# Restauration handler spÃ©cifique
cp TTS/legacy_handlers_20250612/tts_handler_X.py TTS/
```
EOF

# Migration handlers obsolÃ¨tes
mv TTS/tts_handler_piper_native.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper_rtx3090.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper_simple.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper_french.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper_original.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper_direct.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper_espeak.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper_fixed.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper_cli.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_piper.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_coqui.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_mvp.py TTS/legacy_handlers_20250612/
mv TTS/tts_handler_fallback.py TTS/legacy_handlers_20250612/
```

#### **0.3 - Script Rollback AutomatisÃ© (1h) :**
```bash
# CrÃ©ation script rollback
cat > scripts/rollback_tts_enterprise.sh << 'EOF'
#!/bin/bash
# Script de rollback automatisÃ© TTS Enterprise

echo "ğŸ”„ Rollback TTS Enterprise en cours..."

# VÃ©rification tag existe
if ! git tag -l | grep -q "pre-tts-enterprise-consolidation"; then
    echo "âŒ Tag de sauvegarde introuvable"
    exit 1
fi

# Sauvegarde Ã©tat actuel
git stash push -m "Rollback TTS Enterprise $(date)"

# Restauration tag
git checkout pre-tts-enterprise-consolidation

# Nettoyage branche feature
git branch -D feature/tts-enterprise-consolidation 2>/dev/null || true

# Restauration handlers archivÃ©s
if [ -d "TTS/legacy_handlers_20250612" ]; then
    mv TTS/legacy_handlers_20250612/*.py TTS/ 2>/dev/null || true
    rm -rf TTS/legacy_handlers_20250612/
fi

# Nettoyage fichiers nouveaux
rm -f config/tts.yaml
rm -f TTS/tts_manager_unified.py
rm -rf TTS/handlers/
rm -rf TTS/components/
rm -f tests/test_unified_tts_manager.py

echo "âœ… Rollback TTS Enterprise terminÃ©"
echo "ğŸ“‹ Ã‰tat restaurÃ© au tag pre-tts-enterprise-consolidation"
EOF

chmod +x scripts/rollback_tts_enterprise.sh
```

### **âœ… Livrables Phase 0 :**
- [x] Branche feature crÃ©Ã©e
- [x] Tag sauvegarde posÃ©
- [x] 13 handlers archivÃ©s
- [x] Documentation rollback
- [x] Script rollback automatisÃ©

---

## ğŸ“‹ **PHASE 1 : RÃ‰PARATION PIPERNATIVEHANDLER (2 JOURS)**

### **ğŸ•’ Timing :** J1-J2 - 09h00 â†’ 17h00 (16h)

#### **1.1 - Diagnostic Handler DÃ©faillant (J1 - 4h) :**

##### **Analyse Erreurs Existantes :**
```python
# Examen tts_handler_piper_native.py archivÃ©
# Identification causes Ã©chec :
# - DÃ©pendances manquantes ?
# - Chemin modÃ¨le incorrect ?
# - Configuration GPU dÃ©faillante ?
# - Interface API obsolÃ¨te ?
```

##### **Validation Environnement :**
```bash
# Test dÃ©pendances
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}')"

# Test modÃ¨les disponibles sur D:\
Get-ChildItem "D:\TTS_Voices\piper" -Name
# âœ… Confirmer : fr_FR-siwis-medium.onnx (63MB) + .json

# Test piper-python
pip list | grep piper
```

##### **Benchmark Baseline :**
```python
# Test handler CLI actuel (rÃ©fÃ©rence)
python test_tts_handler.py  # Validation <1000ms
```

#### **1.2 - ImplÃ©mentation PiperNativeHandler (J1-J2 - 8h) :**

##### **Structure Handler GPU :**
```python
# TTS/handlers/piper_native.py
#!/usr/bin/env python3
"""
PiperNativeHandler - GPU RTX 3090 <120ms
ğŸš¨ CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys

# =============================================================================
# ğŸš¨ CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'

import time
import asyncio
from typing import Optional
import torch
import numpy as np

# Import piper-python (Ã  installer)
# from piper import PiperVoice

class PiperNativeHandler:
    def __init__(self, config: dict):
        self.config = config
        self._validate_rtx3090_configuration()
        self._initialize_piper_voice()
        
    def _validate_rtx3090_configuration(self):
        """Validation obligatoire RTX 3090"""
        if not torch.cuda.is_available():
            raise RuntimeError("ğŸš« CUDA non disponible - RTX 3090 requise")
        
        device_name = torch.cuda.get_device_name(0)
        if "3090" not in device_name:
            raise RuntimeError(f"ğŸš« GPU invalide: {device_name} - RTX 3090 requise")
        
        # Allocation VRAM limitÃ©e (10% max)
        torch.cuda.set_per_process_memory_fraction(0.1, 0)
        
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… RTX 3090 validÃ©e: {device_name} ({gpu_memory:.1f}GB)")
        
    def _initialize_piper_voice(self):
        """Initialisation voix Piper native"""
        model_path = self.config['model_path']
        # self.voice = PiperVoice.load(model_path, use_cuda=True)
        print(f"âœ… PiperNativeHandler initialisÃ©: {model_path}")
        
    async def synthesize(self, text: str, voice: Optional[str] = None, 
                        speed: Optional[float] = None) -> bytes:
        """SynthÃ¨se TTS GPU <120ms"""
        start_time = time.perf_counter()
        
        # SynthÃ¨se via piper-python GPU
        # audio_bytes = await asyncio.to_thread(self.voice.synthesize, text)
        
        # SIMULATION pour dÃ©veloppement
        await asyncio.sleep(0.08)  # Simule 80ms
        audio_bytes = b"fake_gpu_audio_data"
        
        latency_ms = (time.perf_counter() - start_time) * 1000
        
        if latency_ms > 120:
            raise RuntimeError(f"Performance dÃ©gradÃ©e: {latency_ms:.0f}ms > 120ms")
            
        print(f"âœ… PiperNative synthÃ¨se: {latency_ms:.0f}ms")
        return audio_bytes
```

#### **1.3 - Tests Performance <120ms (J2 - 4h) :**

##### **Benchmarks Validation :**
```python
# tests/test_piper_native_performance.py
import pytest
import asyncio
import time
from TTS.handlers.piper_native import PiperNativeHandler

@pytest.mark.asyncio
async def test_piper_native_latency():
    """Test latence <120ms obligatoire"""
    config = {
        'model_path': 'models/TTS/fr_FR-siwis-medium.onnx',
        'device': 'cuda:0',
        'target_latency_ms': 120
    }
    
    handler = PiperNativeHandler(config)
    
    # Test 10 synthÃ¨ses
    latencies = []
    for i in range(10):
        start = time.perf_counter()
        await handler.synthesize(f"Test synthÃ¨se numÃ©ro {i+1}")
        latency_ms = (time.perf_counter() - start) * 1000
        latencies.append(latency_ms)
    
    # Validation P95 <120ms
    p95_latency = sorted(latencies)[int(0.95 * len(latencies))]
    assert p95_latency < 120, f"P95 latence {p95_latency:.0f}ms > 120ms"
    
    print(f"âœ… P95 latence: {p95_latency:.0f}ms")
    print(f"ğŸ“Š Latences: {[f'{l:.0f}ms' for l in latencies]}")

@pytest.mark.asyncio 
async def test_gpu_memory_usage():
    """Test utilisation VRAM â‰¤10%"""
    import torch
    
    # Mesure VRAM avant
    torch.cuda.empty_cache()
    memory_before = torch.cuda.memory_allocated(0)
    
    # SynthÃ¨se
    handler = PiperNativeHandler(config)
    await handler.synthesize("Test utilisation mÃ©moire GPU")
    
    # Mesure VRAM aprÃ¨s
    memory_after = torch.cuda.memory_allocated(0)
    memory_used_mb = (memory_after - memory_before) / 1024**2
    
    # Validation â‰¤10% de 24GB = 2.4GB
    assert memory_used_mb <= 2400, f"VRAM utilisÃ©e {memory_used_mb:.0f}MB > 2400MB"
    
    print(f"âœ… VRAM utilisÃ©e: {memory_used_mb:.0f}MB")
```

### **ğŸš¨ Checkpoint 1 - PiperNativeHandler :**
- [ ] Handler GPU fonctionnel sans erreur
- [ ] Latence P95 <120ms validÃ©e
- [ ] VRAM â‰¤10% RTX 3090 confirmÃ©e
- [ ] Tests automatisÃ©s passants
- [ ] **TEST RÃ‰EL OBLIGATOIRE :** `python test_tts_real.py` â†’ Audio gÃ©nÃ©rÃ© audible
- [ ] **VALIDATION MANUELLE :** QualitÃ© voix franÃ§aise acceptable
- [ ] **MODÃˆLES D:\ VALIDÃ‰S :** fr_FR-siwis-medium.onnx (63MB) utilisÃ©

**âŒ STOP si Ã©chec â†’ Fallback architecture actuelle**

### **âœ… Livrables Phase 1 :**
- [x] PiperNativeHandler fonctionnel
- [x] Tests performance <120ms
- [x] Validation VRAM â‰¤10%
- [x] Benchmarks automatisÃ©s

---

## ğŸ“‹ **PHASE 2 : UNIFIEDTTSMANAGER COMPLET (2 JOURS)**

### **ğŸ•’ Timing :** J3-J4 - 09h00 â†’ 17h00 (16h)

#### **2.1 - Configuration YAML CentralisÃ©e (J3 - 2h) :**

```yaml
# config/tts.yaml
# Configuration unifiÃ©e TTS SuperWhisper V6

# ===================================================================
# SECTION PRINCIPALE
# ===================================================================
enable_piper_native: true

# ===================================================================
# CONFIGURATION BACKENDS
# ===================================================================
backends:
  # PrioritÃ© 1: Performance optimale GPU
  piper_native:
    enabled: true
    model_path: "D:/TTS_Voices/piper/fr_FR-siwis-medium.onnx"
    model_config_path: "D:/TTS_Voices/piper/fr_FR-siwis-medium.onnx.json"
    device: "cuda:0"  # Pointera RTX 3090 aprÃ¨s CUDA_VISIBLE_DEVICES
    speaker_id: 0
    target_latency_ms: 120

  # PrioritÃ© 2: Fallback robuste CPU
  piper_cli:
    enabled: true
    model_path: "D:/TTS_Voices/piper/fr_FR-siwis-medium.onnx"
    executable_path: "piper/piper.exe"
    speaker_id: 0
    target_latency_ms: 1000

  # PrioritÃ© 3: Fallback systÃ¨me Windows
  sapi_french:
    enabled: true
    voice_name: "Microsoft Hortense Desktop"
    rate: 0
    volume: 100
    target_latency_ms: 2000

  # PrioritÃ© 4: SÃ©curitÃ© ultime
  silent_emergency:
    enabled: true
    log_level: "CRITICAL"
    alert_webhook: null
    target_latency_ms: 5

# ===================================================================
# COMPOSANTS ROBUSTESSE
# ===================================================================
cache:
  enabled: true
  max_size_mb: 100
  ttl_seconds: 3600
  eviction_policy: "LRU"

circuit_breaker:
  failure_threshold: 3
  reset_timeout_seconds: 30

monitoring:
  prometheus_enabled: true
  prometheus_port: 9090
  log_performance_metrics: true
  alert_on_fallback: true

# ===================================================================
# PARAMÃˆTRES AVANCÃ‰S
# ===================================================================
advanced:
  gpu_memory_fraction: 0.1
  async_workers: 2
  max_text_length: 1000
  sanitize_text: true

# ===================================================================
# FEATURE FLAGS
# ===================================================================
feature_flags:
  use_unified_tts: true
  enable_legacy_mode: false
```

#### **2.2 - Composants Robustesse (J3 - 6h) :**

##### **Circuit Breaker :**
```python
# TTS/components/circuit_breaker.py
import time
import logging
from enum import Enum

class CircuitState(Enum):
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"

class CircuitBreaker:
    """Isolation handlers dÃ©faillants"""
    
    def __init__(self, failure_threshold: int = 3, reset_timeout: float = 30):
        self.failure_threshold = failure_threshold
        self.reset_timeout = reset_timeout
        self.failure_count = 0
        self.last_failure_time = 0
        self.state = CircuitState.CLOSED
        
    def is_open(self) -> bool:
        """VÃ©rifie si circuit ouvert"""
        if self.state == CircuitState.OPEN:
            if time.time() - self.last_failure_time > self.reset_timeout:
                self.state = CircuitState.HALF_OPEN
                logging.info("Circuit breaker passage en semi-ouvert")
                return False
            return True
        return False
        
    def record_success(self):
        """Enregistre succÃ¨s"""
        self.failure_count = 0
        if self.state == CircuitState.HALF_OPEN:
            self.state = CircuitState.CLOSED
            logging.info("Circuit breaker refermÃ©")
            
    def record_failure(self):
        """Enregistre Ã©chec"""
        self.failure_count += 1
        if self.failure_count >= self.failure_threshold:
            if self.state != CircuitState.OPEN:
                self.state = CircuitState.OPEN
                self.last_failure_time = time.time()
                logging.warning(f"Circuit breaker ouvert pour {self.reset_timeout}s")
```

##### **Cache LRU :**
```python
# TTS/components/cache.py
import hashlib
import time
from typing import Dict, Optional, Any
from collections import OrderedDict

class TTSCache:
    """Cache LRU pour synthÃ¨ses frÃ©quentes"""
    
    def __init__(self, max_size_mb: int = 100, ttl_seconds: int = 3600):
        self.max_size = max_size_mb * 1024 * 1024  # Conversion MB
        self.ttl = ttl_seconds
        self.cache: OrderedDict[str, Dict[str, Any]] = OrderedDict()
        self.current_size = 0
        
    def generate_key(self, text: str, config: Dict) -> str:
        """GÃ©nÃ¨re clÃ© cache"""
        key_str = f"{text}_{config.get('voice', 'default')}_{config.get('speed', 1.0)}"
        return hashlib.sha256(key_str.encode()).hexdigest()
        
    async def get(self, key: str) -> Optional[bytes]:
        """RÃ©cupÃ¨re du cache"""
        if key in self.cache:
            entry = self.cache[key]
            # VÃ©rification TTL
            if time.time() - entry['timestamp'] < self.ttl:
                # DÃ©placement en fin (LRU)
                self.cache.move_to_end(key)
                return entry['audio_data']
            else:
                # Expiration TTL
                self._remove_entry(key)
        return None
        
    async def set(self, key: str, audio_data: bytes):
        """Stocke en cache"""
        size = len(audio_data)
        
        # Ã‰viction si nÃ©cessaire
        while self.current_size + size > self.max_size and self.cache:
            self._evict_lru()
            
        # Stockage
        if self.current_size + size <= self.max_size:
            self.cache[key] = {
                'audio_data': audio_data,
                'timestamp': time.time(),
                'size': size
            }
            self.current_size += size
            
    def _evict_lru(self):
        """Ã‰viction LRU"""
        if self.cache:
            key, entry = self.cache.popitem(last=False)
            self.current_size -= entry['size']
            
    def _remove_entry(self, key: str):
        """Supprime entrÃ©e"""
        if key in self.cache:
            entry = self.cache.pop(key)
            self.current_size -= entry['size']
```

#### **2.3 - UnifiedTTSManager Principal (J4 - 8h) :**

```python
# TTS/tts_manager_unified.py
#!/usr/bin/env python3
"""
UnifiedTTSManager - Gestionnaire TTS Enterprise
ğŸš¨ CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys

# =============================================================================
# ğŸš¨ CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'

import asyncio
import time
import logging
import yaml
from dataclasses import dataclass
from enum import Enum
from typing import Dict, Optional, List
from pathlib import Path

from TTS.handlers.piper_native import PiperNativeHandler
from TTS.handlers.piper_cli import PiperCliHandler  
from TTS.handlers.sapi_french import SapiFrenchHandler
from TTS.handlers.silent_emergency import SilentEmergencyHandler
from TTS.components.circuit_breaker import CircuitBreaker
from TTS.components.cache import TTSCache

class TTSBackendType(Enum):
    PIPER_NATIVE = "piper_native"
    PIPER_CLI = "piper_cli"
    SAPI_FRENCH = "sapi_french"
    SILENT_EMERGENCY = "silent_emergency"
    CACHE = "cache"

@dataclass
class TTSResult:
    success: bool
    backend_used: str
    latency_ms: float
    audio_data: Optional[bytes] = None
    error: Optional[str] = None

class UnifiedTTSManager:
    """Gestionnaire TTS Enterprise avec fallback 4 niveaux"""
    
    def __init__(self, config_path: str = "config/tts.yaml"):
        self.config = self._load_config(config_path)
        self._validate_rtx3090_configuration()
        
        # Initialisation composants
        self.cache = TTSCache(
            max_size_mb=self.config['cache']['max_size_mb'],
            ttl_seconds=self.config['cache']['ttl_seconds']
        )
        
        cb_config = self.config['circuit_breaker']
        self.circuit_breakers = {
            backend: CircuitBreaker(
                failure_threshold=cb_config['failure_threshold'],
                reset_timeout=cb_config['reset_timeout_seconds']
            )
            for backend in TTSBackendType
        }
        
        self.handlers: Dict[TTSBackendType, Any] = {}
        self._initialize_handlers()
        
        logging.info("âœ… UnifiedTTSManager initialisÃ©")
        
    def _load_config(self, config_path: str) -> dict:
        """Charge configuration YAML"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
            
    def _validate_rtx3090_configuration(self):
        """Validation GPU RTX 3090 obligatoire"""
        import torch
        
        if not torch.cuda.is_available():
            raise RuntimeError("ğŸš« CUDA non disponible - RTX 3090 requise")
            
        device_name = torch.cuda.get_device_name(0)
        if "3090" not in device_name:
            raise RuntimeError(f"ğŸš« GPU invalide: {device_name} - RTX 3090 requise")
            
        # Allocation VRAM limitÃ©e
        gpu_mem_fraction = self.config['advanced']['gpu_memory_fraction']
        torch.cuda.set_per_process_memory_fraction(gpu_mem_fraction, 0)
        
        logging.info(f"âœ… RTX 3090 validÃ©e: {device_name}")
        
    def _initialize_handlers(self):
        """Initialise handlers selon configuration"""
        handler_map = {
            TTSBackendType.PIPER_NATIVE: PiperNativeHandler,
            TTSBackendType.PIPER_CLI: PiperCliHandler,
            TTSBackendType.SAPI_FRENCH: SapiFrenchHandler,
            TTSBackendType.SILENT_EMERGENCY: SilentEmergencyHandler
        }
        
        for backend_type, handler_class in handler_map.items():
            backend_name = backend_type.value
            backend_config = self.config['backends'].get(backend_name, {})
            
            if backend_config.get('enabled', False):
                try:
                    # VÃ©rification feature flag pour piper_native
                    if (backend_type == TTSBackendType.PIPER_NATIVE and 
                        not self.config.get('enable_piper_native', True)):
                        continue
                        
                    self.handlers[backend_type] = handler_class(backend_config)
                    logging.info(f"âœ… Handler {backend_name} initialisÃ©")
                    
                except Exception as e:
                    logging.error(f"âŒ Ã‰chec initialisation {backend_name}: {e}")
                    
    async def synthesize(self, text: str, voice: Optional[str] = None,
                        speed: Optional[float] = None, 
                        reuse_cache: bool = True) -> TTSResult:
        """
        SynthÃ¨se TTS unifiÃ©e avec fallback automatique
        
        Args:
            text: Texte Ã  synthÃ©tiser
            voice: Voix optionnelle
            speed: Vitesse optionnelle
            reuse_cache: Utiliser cache si disponible
            
        Returns:
            TTSResult avec succÃ¨s, backend utilisÃ©, latence et audio
        """
        start_time_total = time.perf_counter()
        
        # 1. Validation input
        max_len = self.config['advanced']['max_text_length']
        if not text or len(text) > max_len:
            return TTSResult(
                success=False, 
                backend_used="none", 
                latency_ms=0,
                error=f"Texte invalide (vide ou > {max_len} chars)"
            )
            
        # 2. VÃ©rification cache
        cache_key = self.cache.generate_key(text, {'voice': voice, 'speed': speed})
        if reuse_cache and (cached_audio := await self.cache.get(cache_key)):
            latency_ms = (time.perf_counter() - start_time_total) * 1000
            return TTSResult(
                success=True,
                backend_used=TTSBackendType.CACHE.value,
                latency_ms=latency_ms,
                audio_data=cached_audio
            )
            
        # 3. Fallback hiÃ©rarchique
        backend_priority = {
            TTSBackendType.PIPER_NATIVE: 1,
            TTSBackendType.PIPER_CLI: 2,
            TTSBackendType.SAPI_FRENCH: 3,
            TTSBackendType.SILENT_EMERGENCY: 4
        }
        
        sorted_backends = sorted(
            self.handlers.keys(), 
            key=lambda x: backend_priority[x]
        )
        
        for backend_type in sorted_backends:
            # VÃ©rification circuit breaker
            if self.circuit_breakers[backend_type].is_open():
                logging.warning(f"Circuit breaker ouvert: {backend_type.value}")
                continue
                
            try:
                start_time_handler = time.perf_counter()
                handler = self.handlers[backend_type]
                
                # SynthÃ¨se
                audio_data = await handler.synthesize(text, voice, speed)
                latency_ms = (time.perf_counter() - start_time_handler) * 1000
                
                # SuccÃ¨s
                self.circuit_breakers[backend_type].record_success()
                await self.cache.set(cache_key, audio_data)
                
                # Validation performance
                target_latency = self.config['backends'][backend_type.value]['target_latency_ms']
                if latency_ms > target_latency:
                    logging.warning(
                        f"Performance dÃ©gradÃ©e: {backend_type.value} "
                        f"{latency_ms:.0f}ms > {target_latency}ms"
                    )
                    
                return TTSResult(
                    success=True,
                    backend_used=backend_type.value,
                    latency_ms=latency_ms,
                    audio_data=audio_data
                )
                
            except Exception as e:
                logging.error(f"Ã‰chec {backend_type.value}: {e}")
                self.circuit_breakers[backend_type].record_failure()
                continue
                
        # Tous handlers Ã©chouÃ©
        return TTSResult(
            success=False,
            backend_used="none",
            latency_ms=0,
            error="Tous backends TTS Ã©chouÃ©"
        )
```

### **ğŸš¨ Checkpoint 2 - UnifiedTTSManager :**
- [ ] 4 handlers intÃ©grÃ©s et fonctionnels
- [ ] Fallback automatique testÃ©
- [ ] Configuration YAML opÃ©rationnelle
- [ ] Tests unitaires 100% passants
- [ ] **TEST FALLBACK RÃ‰EL :** `python test_fallback_real.py` â†’ 4 niveaux validÃ©s
- [ ] **Ã‰COUTE COMPARATIVE :** Audio de chaque backend (piper_native vs piper_cli vs sapi)
- [ ] **BENCHMARK PERFORMANCE :** `python test_performance_real.py` â†’ P95 <120ms confirmÃ©

### **âœ… Livrables Phase 2 :**
- [x] Configuration YAML centralisÃ©e
- [x] Circuit Breakers + Cache LRU
- [x] UnifiedTTSManager complet
- [x] Tests unitaires + intÃ©gration

---

## ğŸ“‹ **PHASE 3 : DÃ‰PLOIEMENT & VALIDATION (1 JOUR)**

### **ğŸ•’ Timing :** J5 - 09h00 â†’ 17h00 (8h)

#### **3.1 - Tests Validation ComplÃ¨te (4h) :**

##### **Tests Programmatiques :**
```python
# tests/test_unified_tts_manager.py
import pytest
import asyncio
from unittest.mock import patch, MagicMock
from TTS.tts_manager_unified import UnifiedTTSManager, TTSResult

@pytest.mark.asyncio
async def test_fallback_automatique():
    """Test fallback automatique complet"""
    manager = UnifiedTTSManager("config/tts.yaml")
    
    # Simulation panne PiperNative
    with patch.object(manager.handlers[TTSBackendType.PIPER_NATIVE], 
                     'synthesize', side_effect=Exception("GPU failed")):
        result = await manager.synthesize("Test fallback")
        
        # Doit utiliser PiperCLI
        assert result.success == True
        assert result.backend_used == "piper_cli"
        assert result.latency_ms < 1000

@pytest.mark.asyncio
async def test_circuit_breaker():
    """Test circuit breaker isolation"""
    manager = UnifiedTTSManager("config/tts.yaml")
    
    # 3 Ã©checs consÃ©cutifs
    for i in range(3):
        with patch.object(manager.handlers[TTSBackendType.PIPER_NATIVE],
                         'synthesize', side_effect=Exception("Fail")):
            await manager.synthesize(f"Test Ã©chec {i+1}")
    
    # Circuit breaker doit Ãªtre ouvert
    assert manager.circuit_breakers[TTSBackendType.PIPER_NATIVE].is_open()

@pytest.mark.asyncio
async def test_cache_performance():
    """Test performance cache"""
    manager = UnifiedTTSManager("config/tts.yaml")
    
    # Premier appel (mise en cache)
    result1 = await manager.synthesize("Test cache")
    
    # DeuxiÃ¨me appel (depuis cache)
    result2 = await manager.synthesize("Test cache")
    
    assert result2.backend_used == "cache"
    assert result2.latency_ms < 5  # <5ms depuis cache

@pytest.mark.asyncio
async def test_performance_regression():
    """Test absence rÃ©gression performance"""
    manager = UnifiedTTSManager("config/tts.yaml")
    
    # Benchmark 10 synthÃ¨ses
    latencies = []
    for i in range(10):
        result = await manager.synthesize(f"Test performance {i}")
        latencies.append(result.latency_ms)
    
    # P95 doit respecter targets
    p95_latency = sorted(latencies)[int(0.95 * len(latencies))]
    assert p95_latency < 120  # Target PiperNative
```

##### **ğŸ§ Tests RÃ©els Pratiques OBLIGATOIRES :**
```bash
# 1. VALIDATION MODÃˆLES DISPONIBLES
Get-ChildItem "D:\TTS_Voices\piper" -Name
# âœ… Confirmer : fr_FR-siwis-medium.onnx (63MB) + .json

# 2. TEST FONCTIONNEL RÃ‰EL
python test_tts_real.py
# âœ… GÃ©nÃ¨re 4 fichiers audio dans test_output/
# âœ… Ã‰couter manuellement chaque fichier
# âœ… Valider qualitÃ© voix franÃ§aise

# 3. TEST FALLBACK RÃ‰EL  
python test_fallback_real.py
# âœ… Valide 4 niveaux fallback avec audio gÃ©nÃ©rÃ©
# âœ… Confirmer basculement automatique

# 4. BENCHMARK PERFORMANCE RÃ‰EL
python test_performance_real.py
# âœ… 10 mesures par cas (court/moyen/long)
# âœ… Validation P95 <120ms pour piper_native
# âœ… Statistiques dÃ©taillÃ©es

# 5. Ã‰COUTE VALIDATION MANUELLE
start test_output\test_1_piper_native.wav
start test_output\test_2_piper_cli.wav
start test_output\test_3_sapi_french.wav
# âœ… Confirmer audio audible et comprÃ©hensible
```

##### **ğŸš¨ CritÃ¨res d'Acceptation Pratiques :**
- âœ… **Audio gÃ©nÃ©rÃ© audible** : 4 fichiers test Ã©coutÃ©s
- âœ… **QualitÃ© voix franÃ§aise** : ComprÃ©hensible et naturelle
- âœ… **Performance mesurÃ©e** : <120ms P95 confirmÃ©
- âœ… **Fallback fonctionnel** : 4 niveaux testÃ©s avec audio
- âœ… **Aucune rÃ©gression** : Comparaison avant/aprÃ¨s

#### **3.2 - IntÃ©gration run_assistant.py (2h) :**

```python
# Modification run_assistant.py
from TTS.tts_manager_unified import UnifiedTTSManager

# Remplacement handler TTS
# OLD: from TTS.tts_handler import TTSHandler
# NEW: tts_manager = UnifiedTTSManager("config/tts.yaml")

async def process_tts(text: str):
    """Traitement TTS unifiÃ©"""
    result = await tts_manager.synthesize(text)
    
    if result.success:
        # Lecture audio
        play_audio(result.audio_data)
        
        # MÃ©triques
        print(f"âœ… TTS: {result.backend_used} ({result.latency_ms:.0f}ms)")
    else:
        print(f"âŒ TTS Ã©chec: {result.error}")
```

#### **3.3 - Feature Flags & Monitoring (2h) :**

```python
# Feature flag activation progressive
if config['feature_flags']['use_unified_tts']:
    tts_manager = UnifiedTTSManager("config/tts.yaml")
else:
    # Fallback ancien systÃ¨me
    tts_manager = LegacyTTSHandler()

# MÃ©triques Prometheus basiques
from prometheus_client import Counter, Histogram

tts_requests_total = Counter('tts_requests_total', 'Total TTS requests', ['backend', 'status'])
tts_duration_seconds = Histogram('tts_duration_seconds', 'TTS latency', ['backend'])

# Export mÃ©triques
def record_tts_metrics(result: TTSResult):
    status = 'success' if result.success else 'error'
    tts_requests_total.labels(backend=result.backend_used, status=status).inc()
    tts_duration_seconds.labels(backend=result.backend_used).observe(result.latency_ms / 1000)
```

### **ğŸš¨ Checkpoint 3 - DÃ©ploiement :**
- [ ] Feature flag activation rÃ©ussie
- [ ] MÃ©triques Prometheus fonctionnelles
- [ ] Performance â‰¥ baseline
- [ ] Archivage sÃ©curisÃ© + rollback testÃ©

### **âœ… Livrables Phase 3 :**
- [x] Tests validation 100% passants
- [x] IntÃ©gration run_assistant.py
- [x] Feature flags opÃ©rationnels
- [x] Monitoring Prometheus basique

---

## ğŸ–ï¸ **CRITÃˆRES D'ACCEPTATION FINALE**

### **âœ… Performance :**
- [ ] Latence PiperNative <120ms (P95)
- [ ] Latence PiperCLI <1000ms
- [ ] Latence SAPI <2000ms
- [ ] Cache hit <5ms

### **âœ… Robustesse :**
- [ ] DisponibilitÃ© 99.9% (fallback)
- [ ] Circuit breakers fonctionnels
- [ ] Recovery automatique
- [ ] Monitoring temps rÃ©el

### **âœ… QualitÃ© Code :**
- [ ] Type hints 100%
- [ ] Docstrings complÃ¨tes
- [ ] Tests coverage >90%
- [ ] Configuration externalisÃ©e

### **âœ… Validation Pratique :**
- [ ] **Tests rÃ©els exÃ©cutÃ©s** : test_tts_real.py, test_fallback_real.py, test_performance_real.py
- [ ] **Audio gÃ©nÃ©rÃ© audible** : 4 fichiers test Ã©coutÃ©s et validÃ©s
- [ ] **QualitÃ© voix franÃ§aise** : ComprÃ©hensible et acceptable
- [ ] **Performance mesurÃ©e** : <120ms P95 pour piper_native confirmÃ©
- [ ] **Fallback testÃ©** : 4 niveaux validÃ©s avec audio gÃ©nÃ©rÃ©
- [ ] **ModÃ¨les D:\ validÃ©s** : fr_FR-siwis-medium.onnx (63MB) utilisÃ©

### **âœ… DÃ©ploiement :**
- [ ] Feature flags opÃ©rationnels
- [ ] Rollback script testÃ©
- [ ] Documentation complÃ¨te
- [ ] MÃ©triques exportÃ©es

---

## ğŸ“Š **MÃ‰TRIQUES DE SUCCÃˆS**

### **ğŸ¯ KPIs Post-DÃ©ploiement :**

#### **Performance :**
- **Latence moyenne** : <120ms (vs <1000ms)
- **P95 latence** : <150ms
- **Cache hit rate** : >80%
- **Throughput** : >10 synthÃ¨ses/s

#### **Robustesse :**
- **Uptime** : >99.9%
- **MTBF** : >168h
- **MTTR** : <5s
- **Fallback rate** : <1%

#### **Maintenance :**
- **ComplexitÃ© code** : -87% fichiers
- **Time to fix** : -50%
- **Deployment time** : <5min
- **Rollback time** : <2min

---

## ğŸš€ **COMMANDES DE DÃ‰MARRAGE**

```bash
# Phase 0 - PrÃ©paration
git checkout -b feature/tts-enterprise-consolidation
git tag pre-tts-enterprise-consolidation
./scripts/rollback_tts_enterprise.sh --test

# Phase 1 - PiperNativeHandler
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name(0)}')"
Get-ChildItem "D:\TTS_Voices\piper" -Name
pytest tests/test_piper_native_performance.py -v

# Phase 2 - UnifiedTTSManager
pytest tests/test_unified_tts_manager.py -v
python -m TTS.tts_manager_unified --test

# Phase 3 - Tests RÃ©els Pratiques
python test_tts_real.py
python test_fallback_real.py  
python test_performance_real.py
start test_output\test_1_piper_native.wav

# Phase 3 - DÃ©ploiement
pytest tests/ -v --cov=TTS --cov-report=html
python run_assistant.py --feature-flag=unified_tts

echo "ğŸš€ Phase 2 Enterprise - Consolidation TTS terminÃ©e !"
```

**ğŸ¯ PrÃªt pour implÃ©mentation architecture enterprise UnifiedTTSManager !** 