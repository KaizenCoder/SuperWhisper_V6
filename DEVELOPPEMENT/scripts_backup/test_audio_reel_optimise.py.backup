#!/usr/bin/env python3
"""
Test Audio R√©el - Solution STT Optimis√©e
üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
Test avec fichier audio r√©el (lecture texte complexe au micro Rode)
‚ö†Ô∏è ATTENTION: R√©sultats faussement flatteurs vs conditions r√©elles microphone live
"""

import os
import sys

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajout du chemin STT au PYTHONPATH
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
sys.path.insert(0, project_root)

import asyncio
import time
import json
import numpy as np
import torch
import librosa
from pathlib import Path
from datetime import datetime
import logging

# Configuration logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    if not torch.cuda.is_available():
        raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 = ~24GB
        raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
    
    gpu_name = torch.cuda.get_device_name(0)
    print(f"‚úÖ RTX 3090 valid√©e: {gpu_name} ({gpu_memory:.1f}GB)")

def load_audio_file(file_path: str):
    """Chargement et pr√©paration du fichier audio"""
    print(f"\nüéµ CHARGEMENT FICHIER AUDIO")
    print("-" * 50)
    
    try:
        # Chargement avec librosa (16kHz requis pour Whisper)
        audio, sr = librosa.load(file_path, sr=16000, mono=True)
        
        duration = len(audio) / sr
        file_size = Path(file_path).stat().st_size / (1024*1024)  # MB
        
        print(f"‚úÖ Fichier charg√©: {Path(file_path).name}")
        print(f"   Dur√©e: {duration:.2f}s")
        print(f"   Taille: {file_size:.1f}MB")
        print(f"   Sample rate: {sr}Hz")
        print(f"   √âchantillons: {len(audio):,}")
        
        return audio, duration
        
    except Exception as e:
        print(f"‚ùå Erreur chargement audio: {e}")
        return None, 0

async def test_backend_optimise_avec_audio(audio: np.ndarray, duration: float):
    """Test du backend optimis√© avec audio r√©el"""
    print(f"\n‚öôÔ∏è TEST BACKEND OPTIMIS√â - AUDIO R√âEL")
    print("-" * 50)
    
    try:
        from STT.backends.prism_stt_backend_optimized import OptimizedPrismSTTBackend
        
        config = {
            'model': 'large-v2',
            'compute_type': 'float16',
            'language': 'fr',  # For√ßage fran√ßais
            'beam_size': 10,   # Beam search optimis√©
            'vad_filter': True,
            'vad_parameters': {
                'threshold': 0.3,
                'min_speech_duration_ms': 100,
                'max_speech_duration_s': float('inf'),
                'min_silence_duration_ms': 2000,
                'speech_pad_ms': 400
            }
        }
        
        print("üöÄ Initialisation backend optimis√©...")
        backend = OptimizedPrismSTTBackend(config)
        
        print("üéØ Transcription audio r√©el...")
        start_time = time.perf_counter()
        
        result = await backend.transcribe(audio)
        
        processing_time = time.perf_counter() - start_time
        
        if result['success']:
            print(f"\nüìù R√âSULTATS TRANSCRIPTION:")
            print(f"   Texte: \"{result['text']}\"")
            print(f"   Confiance: {result['confidence']:.3f}")
            print(f"   Segments: {len(result['segments'])}")
            print(f"   Temps traitement: {processing_time:.2f}s")
            print(f"   RTF: {result['rtf']:.3f}")
            print(f"   Mots estim√©s: {len(result['text'].split())}")
            
            return result
        else:
            print(f"‚ùå Transcription √©chou√©e: {result.get('error', 'Erreur inconnue')}")
            return None
            
    except Exception as e:
        print(f"‚ùå Erreur test backend: {e}")
        import traceback
        traceback.print_exc()
        return None

async def test_post_processor_avec_transcription(transcription: str):
    """Test du post-processeur avec la transcription obtenue"""
    print(f"\nüß™ TEST POST-PROCESSEUR - TRANSCRIPTION R√âELLE")
    print("-" * 50)
    
    try:
        from STT.stt_postprocessor import STTPostProcessor
        
        processor = STTPostProcessor()
        
        print(f"üìù Texte original: \"{transcription}\"")
        
        start_time = time.time()
        processed, metrics = processor.process(transcription, 0.8)
        processing_time = (time.time() - start_time) * 1000  # ms
        
        print(f"üìù Texte corrig√©: \"{processed}\"")
        print(f"   Corrections appliqu√©es: {metrics['corrections_applied']}")
        print(f"   Boost confiance: +{metrics['confidence_boost']:.3f}")
        print(f"   Temps traitement: {processing_time:.1f}ms")
        
        # Comparaison longueur
        mots_avant = len(transcription.split())
        mots_apr√®s = len(processed.split())
        
        print(f"   Mots avant: {mots_avant}")
        print(f"   Mots apr√®s: {mots_apr√®s}")
        print(f"   Diff√©rence: {mots_apr√®s - mots_avant:+d} mots")
        
        return processed, metrics
        
    except Exception as e:
        print(f"‚ùå Erreur post-processeur: {e}")
        return transcription, {}

async def test_manager_optimise_avec_audio(audio: np.ndarray):
    """Test du manager optimis√© avec audio r√©el"""
    print(f"\nüß† TEST MANAGER OPTIMIS√â - AUDIO R√âEL")
    print("-" * 50)
    
    try:
        from STT.unified_stt_manager_optimized import OptimizedUnifiedSTTManager
        
        config = {
            'model': 'large-v2',
            'compute_type': 'float16'
        }
        
        print("üöÄ Initialisation manager optimis√©...")
        manager = OptimizedUnifiedSTTManager(config)
        
        print("üéØ Transcription via manager...")
        start_time = time.perf_counter()
        
        # Note: Le manager optimis√© pourrait ne pas avoir la m√©thode transcribe_audio
        # On teste juste l'initialisation pour ce test
        processing_time = time.perf_counter() - start_time
        
        print(f"‚úÖ Manager initialis√© en {processing_time:.2f}s")
        print("‚ö†Ô∏è Test transcription via manager n√©cessite impl√©mentation compl√®te")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur test manager: {e}")
        return False

def generate_test_report(audio_duration: float, backend_result: dict, post_processed: str, metrics: dict):
    """G√©n√©ration du rapport de test audio r√©el"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"test_audio_reel_optimise_report_{timestamp}.json"
    
    report = {
        'timestamp': timestamp,
        'test_type': 'audio_reel_fichier',
        'warning': 'R√©sultats faussement flatteurs vs microphone live',
        'audio_info': {
            'duration_seconds': audio_duration,
            'file': 'enregistrement_avec_lecture_texte_complet_depuis_micro_rode.wav'
        },
        'gpu_config': {
            'device': torch.cuda.get_device_name(0),
            'memory_gb': torch.cuda.get_device_properties(0).total_memory / 1024**3,
            'cuda_version': torch.version.cuda
        },
        'backend_result': backend_result,
        'post_processing': {
            'original_text': backend_result.get('text', '') if backend_result else '',
            'processed_text': post_processed,
            'metrics': metrics
        },
        'performance': {
            'rtf': backend_result.get('rtf', 0) if backend_result else 0,
            'processing_time': backend_result.get('processing_time', 0) if backend_result else 0,
            'confidence': backend_result.get('confidence', 0) if backend_result else 0
        }
    }
    
    # Sauvegarde rapport
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÑ Rapport sauvegard√©: {report_file}")
    return report_file

async def main():
    """Test principal avec audio r√©el"""
    print("üéØ TEST AUDIO R√âEL - SOLUTION STT OPTIMIS√âE")
    print("üö® GPU RTX 3090 OBLIGATOIRE")
    print("‚ö†Ô∏è ATTENTION: Fichier pr√©-enregistr√© ‚â† conditions r√©elles microphone")
    print("=" * 80)
    
    try:
        # 1. Validation GPU
        validate_rtx3090_configuration()
        
        # 2. Chargement fichier audio
        audio_file = "tests/test_input/enregistrement_avec_lecture_texte_complet_depuis_micro_rode.wav"
        
        if not Path(audio_file).exists():
            print(f"‚ùå Fichier audio non trouv√©: {audio_file}")
            return False
        
        audio, duration = load_audio_file(audio_file)
        if audio is None:
            return False
        
        # 3. Test backend optimis√© avec audio r√©el
        backend_result = await test_backend_optimise_avec_audio(audio, duration)
        
        if not backend_result:
            print("‚ùå Test backend √©chou√© - arr√™t")
            return False
        
        # 4. Test post-processeur avec transcription
        post_processed, metrics = await test_post_processor_avec_transcription(backend_result['text'])
        
        # 5. Test manager optimis√©
        manager_ok = await test_manager_optimise_avec_audio(audio)
        
        # 6. R√©sum√© global
        print("\n" + "="*80)
        print("üìä R√âSUM√â TEST AUDIO R√âEL")
        print("="*80)
        
        print(f"‚úÖ Fichier audio: {duration:.2f}s trait√©")
        print(f"‚úÖ Backend optimis√©: Transcription r√©ussie")
        print(f"‚úÖ Post-processeur: {metrics.get('corrections_applied', 0)} corrections")
        print(f"{'‚úÖ' if manager_ok else '‚ö†Ô∏è'} Manager optimis√©: {'Initialis√©' if manager_ok else 'Probl√®me'}")
        
        # M√©triques cl√©s
        print(f"\nüìà M√âTRIQUES CL√âS:")
        print(f"   RTF: {backend_result['rtf']:.3f}")
        print(f"   Confiance: {backend_result['confidence']:.3f}")
        print(f"   Temps traitement: {backend_result['processing_time']:.2f}s")
        print(f"   Mots transcrits: {len(backend_result['text'].split())}")
        print(f"   Corrections post-proc: {metrics.get('corrections_applied', 0)}")
        
        # 7. G√©n√©ration rapport
        report_file = generate_test_report(duration, backend_result, post_processed, metrics)
        
        # 8. Avertissement important
        print(f"\n‚ö†Ô∏è AVERTISSEMENT IMPORTANT:")
        print("   ‚Üí Ce test utilise un fichier pr√©-enregistr√©")
        print("   ‚Üí Les r√©sultats sont FAUSSEMENT FLATTEURS")
        print("   ‚Üí Le VRAI test sera la lecture au microphone live")
        print("   ‚Üí Conditions r√©elles = bruit, distance, accent, etc.")
        
        print(f"\nüéØ PROCHAINE √âTAPE CRITIQUE:")
        print("   ‚Üí Test microphone live avec lecture texte complexe")
        print("   ‚Üí Validation humaine de la pr√©cision")
        print("   ‚Üí Mesure WER en conditions r√©elles")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur test audio r√©el: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # Ex√©cution test
    success = asyncio.run(main())
    
    if success:
        print(f"\n‚úÖ Test audio r√©el termin√© avec succ√®s")
        print("‚ö†Ô∏è Rappel: R√©sultats faussement flatteurs vs microphone live")
    else:
        print(f"\n‚ùå Test audio r√©el √©chou√©") 