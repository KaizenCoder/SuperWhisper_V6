#!/usr/bin/env python3
"""
Script de Validation ComplÃ¨te - Luxa SuperWhisper V6
===================================================

DÃ©monstrateur des amÃ©liorations de sÃ©curitÃ©, robustesse et performance.
Ce script illustre toutes les corrections apportÃ©es suite au peer review.

ğŸš¨ CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# ğŸš€ PORTABILITÃ‰ AUTOMATIQUE - EXÃ‰CUTABLE DEPUIS N'IMPORTE OÃ™
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour exÃ©cution portable"""
    # DÃ©terminer le rÃ©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le rÃ©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"ğŸ® GPU Configuration: RTX 3090 (CUDA:1) forcÃ©e")
    print(f"ğŸ“ Project Root: {project_root}")
    print(f"ğŸ’» Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import asyncio
import numpy as np
import time
import json
import logging
from pathlib import Path
import sys

# Imports des modules amÃ©liorÃ©s
sys.path.append(str(Path(__file__).parent))

from config.security_config import SecurityConfig
from utils.error_handler import RobustErrorHandler
from Orchestrator.master_handler_robust import RobustMasterHandler

# Configuration logging colorÃ©
class ColoredFormatter(logging.Formatter):
    """Formatter avec couleurs pour dÃ©monstration"""
    
    COLORS = {
        'DEBUG': '\033[36m',    # Cyan
        'INFO': '\033[32m',     # Vert
        'WARNING': '\033[33m',  # Jaune
        'ERROR': '\033[31m',    # Rouge
        'CRITICAL': '\033[35m', # Magenta
    }
    RESET = '\033[0m'
    
    def format(self, record):
        log_color = self.COLORS.get(record.levelname, self.RESET)
        record.levelname = f"{log_color}{record.levelname}{self.RESET}"
        return super().format(record)

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

# Appliquer formatter colorÃ©
for handler in logging.root.handlers:
    handler.setFormatter(ColoredFormatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))

logger = logging.getLogger(__name__)

class LuxaSecurityDemo:
    """DÃ©monstration des amÃ©liorations de sÃ©curitÃ©"""
    
    def __init__(self):
        self.security_config = SecurityConfig(config_dir="demo_config")
        
    def demo_api_key_management(self):
        """DÃ©montre la gestion sÃ©curisÃ©e des clÃ©s API"""
        
        print("\nğŸ” === DÃ‰MONSTRATION SÃ‰CURITÃ‰ - GESTION CLÃ‰S API ===")
        
        # 1. GÃ©nÃ©ration clÃ© API sÃ©curisÃ©e
        print("\n1ï¸âƒ£ GÃ©nÃ©ration clÃ© API sÃ©curisÃ©e:")
        api_key = self.security_config.generate_api_key("demo_user")
        print(f"   âœ… ClÃ© gÃ©nÃ©rÃ©e: {api_key[:20]}... (truncated)")
        print(f"   ğŸ”’ Hash stockÃ© de faÃ§on sÃ©curisÃ©e")
        
        # 2. Validation clÃ© API
        print("\n2ï¸âƒ£ Validation clÃ© API:")
        user = self.security_config.validate_api_key(api_key)
        print(f"   âœ… Validation rÃ©ussie pour: {user}")
        
        # Test clÃ© invalide
        invalid_result = self.security_config.validate_api_key("clÃ©_invalide")
        print(f"   âŒ ClÃ© invalide rejetÃ©e: {invalid_result}")
        
        # 3. GÃ©nÃ©ration et validation JWT
        print("\n3ï¸âƒ£ Gestion JWT:")
        token = self.security_config.generate_jwt_token({
            "username": user,
            "permissions": ["audio_processing", "model_access"],
            "role": "user"
        })
        print(f"   âœ… Token JWT gÃ©nÃ©rÃ© (longueur: {len(token)} chars)")
        
        # Validation JWT
        decoded = self.security_config.validate_jwt_token(token)
        print(f"   âœ… Token validÃ©: {decoded['username']} - {decoded['permissions']}")
        
        return api_key, token
    
    def demo_input_validation(self):
        """DÃ©montre la validation sÃ©curisÃ©e des entrÃ©es"""
        
        print("\nğŸ›¡ï¸ === DÃ‰MONSTRATION VALIDATION ENTRÃ‰ES ===")
        
        # 1. Audio valide
        print("\n1ï¸âƒ£ Validation audio valide:")
        valid_audio = self._create_wav_audio(16000)  # 1 seconde
        validation = self.security_config.validate_audio_input(valid_audio, "test.wav")
        print(f"   âœ… Audio valide: {validation['valid']}")
        print(f"   ğŸ“Š Taille: {len(valid_audio)/1024:.1f} KB")
        
        # 2. Audio trop volumineux
        print("\n2ï¸âƒ£ Rejet audio trop volumineux:")
        large_audio = b"x" * (15 * 1024 * 1024)  # 15MB
        validation = self.security_config.validate_audio_input(large_audio, "large.wav")
        print(f"   âŒ Audio rejetÃ©: {validation['valid']}")
        print(f"   ğŸš« Erreur: {validation['errors'][0]}")
        
        # 3. Format non supportÃ©
        print("\n3ï¸âƒ£ Rejet format non supportÃ©:")
        validation = self.security_config.validate_audio_input(b"test", "malware.exe")
        print(f"   âŒ Format rejetÃ©: {validation['valid']}")
        print(f"   ğŸš« Erreur: {validation['errors'][0]}")
        
        # 4. DÃ©tection contenu suspect
        print("\n4ï¸âƒ£ DÃ©tection contenu suspect:")
        suspicious_data = b"MZ\x90\x00" + b"fake_audio_data" * 100
        validation = self.security_config.validate_audio_input(suspicious_data, "suspicious.wav")
        print(f"   âŒ Contenu suspect dÃ©tectÃ©: {not validation['valid']}")
        
        # 5. Nettoyage texte
        print("\n5ï¸âƒ£ Nettoyage entrÃ©es texte:")
        dirty_text = "Hello\x00\x07world\x1f avec caractÃ¨res\x0c de contrÃ´le"
        clean_text = self.security_config.sanitize_text_input(dirty_text)
        print(f"   ğŸ“ Texte original: {repr(dirty_text)}")
        print(f"   âœ¨ Texte nettoyÃ©: {repr(clean_text)}")
    
    def _create_wav_audio(self, samples: int) -> bytes:
        """CrÃ©e un fichier WAV valide pour tests"""
        # Header WAV minimal
        header = (
            b'RIFF' + (samples * 2 + 36).to_bytes(4, 'little') +
            b'WAVEfmt ' + (16).to_bytes(4, 'little') +
            (1).to_bytes(2, 'little') + (1).to_bytes(2, 'little') +
            (16000).to_bytes(4, 'little') + (32000).to_bytes(4, 'little') +
            (2).to_bytes(2, 'little') + (16).to_bytes(2, 'little') +
            b'data' + (samples * 2).to_bytes(4, 'little')
        )
        
        # DonnÃ©es audio (silence)
        audio_data = np.zeros(samples, dtype=np.int16).tobytes()
        
        return header + audio_data

class LuxaRobustnessDemo:
    """DÃ©monstration des amÃ©liorations de robustesse"""
    
    def __init__(self):
        self.error_handler = RobustErrorHandler()
        
    async def demo_circuit_breaker(self):
        """DÃ©montre le fonctionnement des circuit breakers"""
        
        print("\nâš¡ === DÃ‰MONSTRATION CIRCUIT BREAKERS ===")
        
        # Enregistrer un composant de test
        self.error_handler.register_component("demo_service", failure_threshold=3, max_retries=2)
        
        # Simuler service dÃ©faillant
        failure_count = 0
        
        async def unreliable_service():
            nonlocal failure_count
            failure_count += 1
            
            if failure_count <= 5:  # 5 premiÃ¨res tentatives Ã©chouent
                raise Exception(f"Service failure #{failure_count}")
            
            return f"Success after {failure_count} attempts"
        
        print("\n1ï¸âƒ£ Test avec service dÃ©faillant:")
        
        # PremiÃ¨re sÃ©rie d'appels - doit ouvrir le circuit
        for i in range(6):
            try:
                result = await self.error_handler.execute_safe("demo_service", unreliable_service)
                print(f"   âœ… Tentative {i+1}: {result}")
            except Exception as e:
                print(f"   âŒ Tentative {i+1}: {str(e)}")
            
            # Afficher Ã©tat du circuit
            circuit = self.error_handler.circuit_breakers["demo_service"]
            print(f"      ğŸ”„ Ã‰tat circuit: {circuit.state.value} (erreurs: {circuit.metrics.consecutive_errors})")
            
            if circuit.state.value == "open":
                print(f"      ğŸš¨ Circuit ouvert aprÃ¨s {circuit.metrics.consecutive_errors} erreurs!")
                break
            
            await asyncio.sleep(0.1)
        
        print("\n2ï¸âƒ£ Ã‰tat du circuit breaker:")
        status = self.error_handler.get_health_status()
        print(f"   ğŸ“Š Composants sains: {status['healthy_components']}/{status['total_components']}")
        print(f"   ğŸ“ˆ Taux d'erreur global: {status['global_metrics']['error_rate']:.2%}")
    
    async def demo_retry_mechanism(self):
        """DÃ©montre le mÃ©canisme de retry"""
        
        print("\nğŸ”„ === DÃ‰MONSTRATION RETRY ===")
        
        # Service qui rÃ©ussit au 3Ã¨me essai
        attempt_count = 0
        
        async def flaky_service():
            nonlocal attempt_count
            attempt_count += 1
            
            if attempt_count < 3:
                raise Exception(f"Temporary failure (attempt {attempt_count})")
            
            return f"Success on attempt {attempt_count}!"
        
        print("\n1ï¸âƒ£ Service avec Ã©checs temporaires:")
        
        try:
            result = await self.error_handler.execute_safe("demo_service", flaky_service)
            print(f"   âœ… RÃ©sultat final: {result}")
            print(f"   ğŸ”„ Nombre total d'essais: {attempt_count}")
        except Exception as e:
            print(f"   âŒ Ã‰chec dÃ©finitif: {e}")

class LuxaPerformanceDemo:
    """DÃ©monstration des amÃ©liorations de performance"""
    
    async def demo_pipeline_performance(self):
        """DÃ©montre les performances du pipeline amÃ©liorÃ©"""
        
        print("\nğŸš€ === DÃ‰MONSTRATION PERFORMANCE ===")
        
        # Initialiser le handler robuste
        handler = RobustMasterHandler()
        await handler.initialize()
        
        print("\n1ï¸âƒ£ Test latence avec diffÃ©rents types d'audio:")
        
        audio_types = {
            "silence": np.zeros(16000, dtype=np.float32),
            "speech_sim": self._generate_speech_signal(16000),
            "noise": np.random.normal(0, 0.1, 16000).astype(np.float32)
        }
        
        for audio_type, audio_data in audio_types.items():
            latencies = []
            
            # 5 mesures par type
            for i in range(5):
                start_time = time.perf_counter()
                
                result = await handler.process_audio_secure(
                    audio_chunk=audio_data,
                    jwt_token=handler.security_config.generate_jwt_token({"username": "perf_demo"})
                )
                
                end_time = time.perf_counter()
                latency_ms = (end_time - start_time) * 1000
                latencies.append(latency_ms)
            
            avg_latency = sum(latencies) / len(latencies)
            min_latency = min(latencies)
            max_latency = max(latencies)
            
            print(f"   ğŸ“Š {audio_type:12s}: Î¼={avg_latency:5.1f}ms min={min_latency:5.1f}ms max={max_latency:5.1f}ms")
            
            # VÃ©rifier objectifs
            if audio_type == "silence":
                assert avg_latency < 100, f"Silence trop lent: {avg_latency:.1f}ms"
            else:
                assert avg_latency < 3000, f"{audio_type} trop lent: {avg_latency:.1f}ms"
        
        print("\n2ï¸âƒ£ Test charge concurrente:")
        
        async def concurrent_request(req_id: int):
            """RequÃªte concurrente"""
            audio = self._generate_speech_signal(8000)  # Audio court
            
            start = time.perf_counter()
            result = await handler.process_audio_secure(
                audio_chunk=audio,
                jwt_token=handler.security_config.generate_jwt_token({"username": f"concurrent_{req_id}"})
            )
            end = time.perf_counter()
            
            return {
                "req_id": req_id,
                "latency_ms": (end - start) * 1000,
                "success": result["success"]
            }
        
        # Test avec 5 requÃªtes concurrentes
        concurrent_tasks = [concurrent_request(i) for i in range(5)]
        results = await asyncio.gather(*concurrent_tasks)
        
        successful = [r for r in results if r["success"]]
        success_rate = len(successful) / len(results)
        
        if successful:
            avg_concurrent_latency = sum(r["latency_ms"] for r in successful) / len(successful)
            print(f"   âš¡ RequÃªtes concurrentes: {len(successful)}/{len(results)} rÃ©ussies")
            print(f"   ğŸ“Š Latence moyenne: {avg_concurrent_latency:.1f}ms")
            print(f"   ğŸ¯ Taux de succÃ¨s: {success_rate:.1%}")
        
        print("\n3ï¸âƒ£ Ã‰tat de santÃ© systÃ¨me:")
        health = handler.get_health_status()
        print(f"   ğŸ¥ Statut: {health['status']}")
        print(f"   ğŸ“ˆ RequÃªtes traitÃ©es: {health['performance']['requests_processed']}")
        print(f"   âš¡ Latence moyenne: {health['performance']['avg_latency_ms']:.1f}ms")
        print(f"   âœ… Taux de succÃ¨s: {health['performance']['success_rate']:.1%}")
    
    def _generate_speech_signal(self, length: int) -> np.ndarray:
        """GÃ©nÃ¨re un signal similaire Ã  la parole"""
        t = np.linspace(0, length/16000, length)
        
        # Formants typiques
        f1 = 800 + 200 * np.sin(2 * np.pi * 3 * t)
        f2 = 1200 + 300 * np.sin(2 * np.pi * 2 * t)
        
        signal = (
            0.4 * np.sin(2 * np.pi * f1 * t) +
            0.3 * np.sin(2 * np.pi * f2 * t)
        )
        
        envelope = 0.5 * (1 + np.sin(2 * np.pi * 1.5 * t))
        
        return (signal * envelope * 0.7).astype(np.float32)

class LuxaIntegrationDemo:
    """DÃ©monstration d'intÃ©gration complÃ¨te"""
    
    async def demo_complete_workflow(self):
        """DÃ©montre le workflow complet sÃ©curisÃ©"""
        
        print("\nğŸ¯ === DÃ‰MONSTRATION WORKFLOW COMPLET ===")
        
        # 1. Configuration sÃ©curitÃ©
        print("\n1ï¸âƒ£ Configuration sÃ©curitÃ©:")
        security = SecurityConfig(config_dir="integration_demo")
        api_key = security.generate_api_key("integration_user")
        print(f"   ğŸ”‘ ClÃ© API gÃ©nÃ©rÃ©e pour integration_user")
        
        # 2. Initialisation handler robuste
        print("\n2ï¸âƒ£ Initialisation handler robuste:")
        handler = RobustMasterHandler()
        await handler.initialize()
        print(f"   âœ… Handler initialisÃ© avec protection complÃ¨te")
        
        # 3. Validation et traitement audio sÃ©curisÃ©
        print("\n3ï¸âƒ£ Traitement audio sÃ©curisÃ©:")
        
        # CrÃ©er audio de test
        audio_data = np.random.normal(0, 0.1, 16000).astype(np.float32)
        
        # Traitement avec authentification
        result = await handler.process_audio_secure(
            audio_chunk=audio_data,
            api_key=api_key,
            filename="integration_test.wav"
        )
        
        print(f"   âœ… Traitement rÃ©ussi: {result['success']}")
        print(f"   ğŸ” Utilisateur authentifiÃ©: {result['security']['user']}")
        print(f"   ğŸ›¡ï¸ MÃ©thode auth: {result['security']['auth_method']}")
        print(f"   ğŸ“Š Latence: {result['latency_ms']:.1f}ms")
        print(f"   ğŸ¤ Composants utilisÃ©s: {list(result['components_used'].keys())}")
        
        # 4. MÃ©triques et monitoring
        print("\n4ï¸âƒ£ MÃ©triques et monitoring:")
        health = handler.get_health_status()
        
        print(f"   ğŸ“Š RequÃªtes totales: {health['performance']['requests_processed']}")
        print(f"   âš¡ Latence moyenne: {health['performance']['avg_latency_ms']:.1f}ms")
        print(f"   ğŸ”’ Circuits breakers: {len(health['security']['circuit_breakers']['components'])} actifs")
        
        # 5. Export mÃ©triques Prometheus
        print("\n5ï¸âƒ£ Export mÃ©triques Prometheus:")
        prometheus_metrics = handler.error_handler.export_metrics_prometheus()
        metrics_lines = prometheus_metrics.split('\n')[:5]  # PremiÃ¨res lignes
        for line in metrics_lines:
            if line.strip():
                print(f"   ğŸ“ˆ {line}")
        print(f"   ... (+{len(prometheus_metrics.split()) - 5} mÃ©triques)")

async def main():
    """Fonction principale de dÃ©monstration"""
    
    print("ğŸ¨" + "="*70)
    print("ğŸ¨  LUXA SUPERWHISPER V6 - DÃ‰MONSTRATION AMÃ‰LIORATIONS")
    print("ğŸ¨  Suite aux recommandations du Peer Review")
    print("ğŸ¨" + "="*70)
    
    try:
        # 1. DÃ©monstration sÃ©curitÃ©
        security_demo = LuxaSecurityDemo()
        api_key, jwt_token = security_demo.demo_api_key_management()
        security_demo.demo_input_validation()
        
        # 2. DÃ©monstration robustesse
        robustness_demo = LuxaRobustnessDemo()
        await robustness_demo.demo_circuit_breaker()
        await robustness_demo.demo_retry_mechanism()
        
        # 3. DÃ©monstration performance
        performance_demo = LuxaPerformanceDemo()
        await performance_demo.demo_pipeline_performance()
        
        # 4. DÃ©monstration intÃ©gration
        integration_demo = LuxaIntegrationDemo()
        await integration_demo.demo_complete_workflow()
        
        print("\nğŸ‰" + "="*70)
        print("ğŸ‰  DÃ‰MONSTRATION TERMINÃ‰E AVEC SUCCÃˆS!")
        print("ğŸ‰  Toutes les amÃ©liorations sont fonctionnelles:")
        print("ğŸ‰  âœ… SÃ©curitÃ© renforcÃ©e (auth, validation)")
        print("ğŸ‰  âœ… Robustesse amÃ©liorÃ©e (circuit breakers, retry)")
        print("ğŸ‰  âœ… Performance optimisÃ©e (latence, dÃ©bit)")
        print("ğŸ‰  âœ… Monitoring complet (mÃ©triques, santÃ©)")
        print("ğŸ‰" + "="*70)
        
    except Exception as e:
        logger.error(f"âŒ Erreur durant la dÃ©monstration: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # Nettoyer les dossiers de test prÃ©cÃ©dents
    import shutil
    for demo_dir in ["demo_config", "integration_demo"]:
        if Path(demo_dir).exists():
            shutil.rmtree(demo_dir)
    
    # Lancer la dÃ©monstration
    asyncio.run(main())
