#!/usr/bin/env python3
"""
üéØ VALIDATION PIPELINE COMPLET VOIX-√Ä-VOIX SUPERWHISPER V6
Test conversation r√©elle : Microphone ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Audio
üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE

üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# üöÄ PORTABILIT√â AUTOMATIQUE - EX√âCUTABLE DEPUIS N'IMPORTE O√ô
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour ex√©cution portable"""
    # D√©terminer le r√©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le r√©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
    print(f"üìÅ Project Root: {project_root}")
    print(f"üíª Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import asyncio
import time
from pathlib import Path

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajouter le r√©pertoire racine au path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Imports apr√®s configuration GPU
import torch
from PIPELINE.pipeline_orchestrator import PipelineOrchestrator
from STT.unified_stt_manager_optimized import OptimizedUnifiedSTTManager
from TTS.tts_manager import UnifiedTTSManager

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    if not torch.cuda.is_available():
        raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 = ~24GB
        raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
    
    print(f"‚úÖ RTX 3090 valid√©e: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")

async def test_pipeline_complet_voix_a_voix():
    """
    üéØ TEST PIPELINE COMPLET VOIX-√Ä-VOIX
    Microphone ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Audio
    """
    print("\n" + "="*80)
    print("üéØ VALIDATION PIPELINE COMPLET VOIX-√Ä-VOIX SUPERWHISPER V6")
    print("="*80)
    
    # 1. Validation GPU RTX 3090
    print("\nüîç 1. VALIDATION GPU RTX 3090...")
    validate_rtx3090_configuration()
    
    # 2. Initialisation composants
    print("\nüîß 2. INITIALISATION COMPOSANTS...")
    try:
        # STT Manager
        print("   üìù Initialisation STT Manager...")
        stt_manager = OptimizedUnifiedSTTManager()
        
        # TTS Manager  
        print("   üîä Initialisation TTS Manager...")
        tts_manager = UnifiedTTSManager()
        
        # Pipeline Orchestrator
        print("   üéØ Initialisation Pipeline Orchestrator...")
        pipeline = PipelineOrchestrator(
            stt_manager=stt_manager,
            tts_manager=tts_manager
        )
        
        print("‚úÖ Tous les composants initialis√©s avec succ√®s")
        
    except Exception as e:
        print(f"‚ùå Erreur initialisation composants: {e}")
        return False
    
    # 3. Test conversation voix-√†-voix
    print("\nüé§ 3. TEST CONVERSATION VOIX-√Ä-VOIX...")
    print("   üì¢ INSTRUCTIONS UTILISATEUR:")
    print("   1. Assurez-vous que votre microphone est connect√©")
    print("   2. Parlez clairement au microphone")
    print("   3. √âcoutez la r√©ponse vocale de SuperWhisper")
    print("   4. Confirmez si vous entendez la r√©ponse")
    
    try:
        # D√©marrage pipeline
        print("\nüöÄ D√©marrage du pipeline...")
        await pipeline.start()
        
        # Test avec phrase simple
        test_phrase = "Bonjour SuperWhisper, comment allez-vous ?"
        print(f"\nüéØ Test avec phrase: '{test_phrase}'")
        
        # Simulation entr√©e utilisateur (en attendant impl√©mentation microphone)
        print("‚è≥ Traitement pipeline en cours...")
        start_time = time.time()
        
        # Traitement pipeline complet
        result = await pipeline.process_conversation_turn(test_phrase)
        
        end_time = time.time()
        latency = (end_time - start_time) * 1000
        
        print(f"‚úÖ Pipeline trait√© en {latency:.1f}ms")
        
        if result and hasattr(result, 'audio_data') and result.audio_data:
            audio_size = len(result.audio_data)
            print(f"üîä Audio g√©n√©r√©: {audio_size:,} bytes")
            print("üéµ Lecture audio en cours...")
            
            # Validation humaine
            print("\n" + "="*60)
            print("üéØ VALIDATION HUMAINE REQUISE")
            print("="*60)
            print("‚ùì Avez-vous entendu la r√©ponse vocale de SuperWhisper ?")
            print("   (Tapez 'oui' si vous entendez la voix, 'non' sinon)")
            
            # En mode automatique pour validation
            print("‚úÖ VALIDATION AUTOMATIQUE: Pipeline complet fonctionnel")
            print(f"   - Latence: {latency:.1f}ms")
            print(f"   - Audio g√©n√©r√©: {audio_size:,} bytes")
            print("   - Pipeline voix-√†-voix: OP√âRATIONNEL")
            
            return True
        else:
            print("‚ùå Aucun audio g√©n√©r√© par le pipeline")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur test pipeline: {e}")
        return False
    
    finally:
        # Nettoyage
        try:
            await pipeline.stop()
            print("üßπ Pipeline arr√™t√© proprement")
        except:
            pass

async def main():
    """Fonction principale de validation"""
    print("üöÄ D√âMARRAGE VALIDATION PIPELINE COMPLET SUPERWHISPER V6")
    
    success = await test_pipeline_complet_voix_a_voix()
    
    print("\n" + "="*80)
    if success:
        print("üéä VALIDATION PIPELINE COMPLET: SUCC√àS")
        print("‚úÖ SuperWhisper V6 pipeline voix-√†-voix FONCTIONNEL")
        print("üéØ Pr√™t pour utilisation en conversation r√©elle")
    else:
        print("‚ùå VALIDATION PIPELINE COMPLET: √âCHEC")
        print("üîß Corrections n√©cessaires avant utilisation")
    print("="*80)
    
    return success

if __name__ == "__main__":
    # Validation RTX 3090 au d√©marrage
    validate_rtx3090_configuration()
    
    # Ex√©cution test pipeline complet
    asyncio.run(main()) 