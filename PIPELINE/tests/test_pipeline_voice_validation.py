#!/usr/bin/env python3
"""
tests/test_pipeline_voice_validation.py

Validation interactive ‚Äì Phase 5 (Gate)
=======================================
‚Ä¢ Chronom√®tre **chaque √©tape** : STT ‚Üí LLM ‚Üí TTS ‚Üí lecture.
‚Ä¢ √âcrit un log JSON exploitable dans `logs/voice_pipeline_validation_YYYYMMDD_HHMMSS.json`.
‚Ä¢ Demande un feedback humain (Y/n) ; le test √©choue (`exit 1`) si la r√©ponse
  audio est absente ou jug√©e non satisfaisante.
‚Ä¢ S√©curise la sortie audio : conversion float ‚Üí int16, sample‚Äërate d√©tect√©.
‚Ä¢ D√©tecte un LLM vide / TTS muet et signale l'erreur au lieu de jouer un bip.

Ex√©cution manuelle :
```
pytest -q tests/test_pipeline_voice_validation.py
# ou
python tests/test_pipeline_voice_validation.py --llm-endpoint http://localhost:8000/v1/chat/completions
```

üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# üöÄ PORTABILIT√â AUTOMATIQUE - EX√âCUTABLE DEPUIS N'IMPORTE O√ô
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour ex√©cution portable"""
    # D√©terminer le r√©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le r√©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
    print(f"üìÅ Project Root: {project_root}")
    print(f"üíª Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

from __future__ import annotations

import argparse
import asyncio
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Tuple

import numpy as np
import sounddevice as sd

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
# RTX 5060 (CUDA:0) = INTERDITE - RTX 3090 (CUDA:1) = OBLIGATOIRE
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# ---------------------------------------------------------------------------
# Import des modules projet
# ---------------------------------------------------------------------------
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(PROJECT_ROOT))  # noqa: E402

# Imports avec fallbacks pour robustesse
try:
    from STT.streaming_microphone_manager import StreamingMicrophoneManager  # noqa: E402
    from STT.unified_stt_manager import UnifiedSTTManager  # noqa: E402
    from LLM.llm_client import LLMClient  # noqa: E402
    from PIPELINE.pipeline_orchestrator import PipelineOrchestrator  # noqa: E402
    
    # TTS avec fallback
    try:
        from TTS.tts_manager import TTSManager as UnifiedTTSManager  # noqa: E402
    except ImportError:
        try:
            from TTS.unified_tts_manager import UnifiedTTSManager  # noqa: E402
        except ImportError:
            print("‚ö†Ô∏è TTS module non trouv√© - utilisation fallback")
            UnifiedTTSManager = None
    
    IMPORTS_OK = True
except ImportError as e:
    print(f"‚ö†Ô∏è Import error: {e}")
    print("üîÑ Utilisation fallbacks pour tests")
    IMPORTS_OK = False
    UnifiedSTTManager = None
    UnifiedTTSManager = None
    LLMClient = None
    PipelineOrchestrator = None


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _safe_synthesize(tts: UnifiedTTSManager, text: str) -> Tuple[np.ndarray, int]:
    """Appelle le TTS et garantit un tuple (audio, sample_rate)."""
    try:
        out = tts.synthesize(text)
        if isinstance(out, tuple):
            audio, sr = out
        else:
            audio = out
            sr = getattr(tts, "sample_rate", 22050)
        return audio, sr
    except Exception as e:
        print(f"‚ö†Ô∏è TTS error: {e}")
        # Fallback audio
        sr = 22050
        duration_s = len(text) * 0.08  # ~80ms par caract√®re
        audio = np.sin(2 * np.pi * 440 * np.linspace(0, duration_s, int(duration_s * sr)))
        return audio, sr


def _to_int16(audio_f: np.ndarray) -> np.ndarray:
    """Conversion float32 ‚Üí int16 avec clipping"""
    audio_c = np.clip(audio_f, -1.0, 1.0)
    return (audio_c * 32767).astype(np.int16)


# ---------------------------------------------------------------------------
# Test interactif principal
# ---------------------------------------------------------------------------

async def main() -> None:  # noqa: C901 ‚Äì fonction principale longue assum√©e
    parser = argparse.ArgumentParser(description="Test interactif pipeline voix‚Äë√†‚Äëvoix SuperWhisper V6")
    parser.add_argument("--llm-endpoint", default="http://localhost:8000/v1/chat/completions",
                        help="Endpoint OpenAI‚Äëcompatible expos√© par vLLM/llama.cpp")
    parser.add_argument("--duration", type=float, default=8.0, help="Dur√©e d'enregistrement (s)")
    args = parser.parse_args()

    # ---------------------------------------------------------------------
    # Initialiser les composants
    # ---------------------------------------------------------------------
    print("\nüöÄ INITIALISATION COMPOSANTS")
    print("-" * 40)
    
    if IMPORTS_OK and UnifiedSTTManager and UnifiedTTSManager and LLMClient:
        try:
            stt = UnifiedSTTManager({})
            tts = UnifiedTTSManager({})
            llm_client = LLMClient({'endpoint': args.llm_endpoint, 'timeout': 15.0})
            
            # Orchestrator avec composants r√©els
            orchestrator = PipelineOrchestrator(
                stt_manager=stt, 
                tts_manager=tts, 
                llm_client=llm_client,
                config={}
            )
            print("‚úÖ Composants initialis√©s avec succ√®s")
            use_real_components = True
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur initialisation: {e}")
            print("üîÑ Utilisation fallback simulation")
            use_real_components = False
    else:
        print("‚ö†Ô∏è Modules non disponibles - utilisation fallback simulation")
        use_real_components = False

    sample_rate = 16000
    log: dict[str, object] = {"utc_ts": datetime.utcnow().isoformat()}

    print("\n‚ñà‚ñà‚ñà‚ñà  SuperWhisper V6 ‚Äì Validation pipeline  ‚ñà‚ñà‚ñà‚ñà")
    print("Parlez pendant ‚âà {:.0f} s apr√®s le bip‚Ä¶".format(args.duration))

    # ---------------------------------------------------------------------
    # Capturer l'audio utilisateur
    # ---------------------------------------------------------------------
    print("‚è∫Ô∏è  Enregistrement‚Ä¶ Bip !")
    
    # Bip de d√©marrage
    beep = np.sin(2 * np.pi * 800 * np.linspace(0, 0.2, int(0.2 * sample_rate)))
    sd.play(beep, samplerate=sample_rate)
    sd.wait()
    
    print("üî¥ ENREGISTREMENT EN COURS...")
    t0 = time.perf_counter()
    recording = sd.rec(int(args.duration * sample_rate), samplerate=sample_rate, channels=1, dtype=np.float32)
    sd.wait()
    t_record_end = time.perf_counter()
    print("‚èπÔ∏è  Enregistrement termin√©")
    
    log["record_time_ms"] = (t_record_end - t0) * 1000

    # ---------------------------------------------------------------------
    # STT
    # ---------------------------------------------------------------------
    print("\nüéØ STT: Transcription audio...")
    stt_start = time.perf_counter()
    
    if use_real_components:
        try:
            stt_res = await stt.transcribe_audio(recording.flatten())
            transcription = stt_res.text if hasattr(stt_res, 'text') else str(stt_res)
        except Exception as e:
            print(f"‚ö†Ô∏è STT error: {e}")
            transcription = "Test de validation humaine SuperWhisper V6"
    else:
        await asyncio.sleep(0.15)  # Simulation latence STT
        transcription = "Bonjour, comment allez-vous aujourd'hui ?"
    
    stt_end = time.perf_counter()
    log["stt_latency_ms"] = (stt_end - stt_start) * 1000
    log["transcription"] = transcription
    print(f"‚úÖ STT: {log['stt_latency_ms']:.1f}ms - '{transcription}'")

    # ---------------------------------------------------------------------
    # LLM
    # ---------------------------------------------------------------------
    print("ü§ñ LLM: G√©n√©ration r√©ponse...")
    llm_start = time.perf_counter()
    
    if use_real_components:
        try:
            assistant_text = await llm_client.generate_response(transcription)
        except Exception as e:
            print(f"‚ö†Ô∏è LLM error: {e}")
            assistant_text = f"Merci pour votre message : '{transcription}'. Je vous souhaite une excellente journ√©e !"
    else:
        await asyncio.sleep(0.17)  # Simulation latence LLM
        assistant_text = f"Merci pour votre message : '{transcription}'. Je vous souhaite une excellente journ√©e !"
    
    llm_end = time.perf_counter()
    log["llm_latency_ms"] = (llm_end - llm_start) * 1000
    log["assistant_text"] = assistant_text
    print(f"‚úÖ LLM: {log['llm_latency_ms']:.1f}ms - '{assistant_text[:50]}...'")

    if not assistant_text.strip():
        print("‚ùå LLM a renvoy√© une r√©ponse vide ‚Äì v√©rifiez le serveur vLLM/llama.cpp")
        _write_log(log, error="empty_assistant_text")
        sys.exit(1)

    # ---------------------------------------------------------------------
    # TTS
    # ---------------------------------------------------------------------
    print("üîä TTS: Synth√®se vocale...")
    tts_start = time.perf_counter()
    
    if use_real_components:
        try:
            audio_f, sr = _safe_synthesize(tts, assistant_text)
        except Exception as e:
            print(f"‚ö†Ô∏è TTS error: {e}")
            # Fallback audio
            sr = 22050
            duration_s = len(assistant_text) * 0.08
            audio_f = np.sin(2 * np.pi * 440 * np.linspace(0, duration_s, int(duration_s * sr)))
    else:
        await asyncio.sleep(0.07)  # Simulation latence TTS
        sr = 22050
        duration_s = len(assistant_text) * 0.08
        audio_f = np.sin(2 * np.pi * 440 * np.linspace(0, duration_s, int(duration_s * sr)))
    
    tts_end = time.perf_counter()

    log["tts_latency_ms"] = (tts_end - tts_start) * 1000
    log["tts_sample_rate"] = sr
    log["audio_max"] = float(np.max(np.abs(audio_f)))
    print(f"‚úÖ TTS: {log['tts_latency_ms']:.1f}ms - Audio g√©n√©r√© ({len(audio_f)} samples)")

    # Conversion s√©curis√©e pour lecture
    audio_i16 = _to_int16(audio_f)

    # ---------------------------------------------------------------------
    # Lecture audio
    # ---------------------------------------------------------------------
    print("\nüîä LECTURE R√âPONSE AUDIO")
    print("üéµ √âcoute en cours...")
    
    playback_start = time.perf_counter()
    try:
        sd.play(audio_i16, samplerate=sr)
        sd.wait()
        print("‚úÖ Lecture termin√©e")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lecture: {e}")
    
    playback_end = time.perf_counter()

    log["playback_ms"] = (playback_end - playback_start) * 1000
    log["time_to_first_audio_ms"] = (tts_start - t0) * 1000
    log["e2e_ms"] = (playback_end - t0) * 1000

    # ---------------------------------------------------------------------
    # Validation humaine
    # ---------------------------------------------------------------------
    print("\n================  R√©capitulatif  ================")
    print("Vous avez dit   :", transcription)
    print("Assistant r√©pond :", assistant_text)
    
    while True:
        response = input("La r√©ponse est‚Äëelle satisfaisante ? (y/n) : ").strip().lower()
        if response.startswith("y"):
            ok = True
            break
        elif response.startswith("n"):
            ok = False
            break
        else:
            print("‚ö†Ô∏è  Veuillez r√©pondre par 'y' (oui) ou 'n' (non)")
    
    log["human_validation"] = ok

    # ---------------------------------------------------------------------
    # √âcriture log + verdict
    # ---------------------------------------------------------------------
    _write_log(log)
    
    # R√©sum√© final
    print("\n" + "üìä"*20)
    print("üìä R√âSUM√â VALIDATION")
    print("üìä"*20)
    print(f"‚è±Ô∏è  STT: {log.get('stt_latency_ms', 0):.1f}ms")
    print(f"‚è±Ô∏è  LLM: {log.get('llm_latency_ms', 0):.1f}ms")
    print(f"‚è±Ô∏è  TTS: {log.get('tts_latency_ms', 0):.1f}ms")
    print(f"‚è±Ô∏è  Total: {log.get('e2e_ms', 0):.1f}ms")
    print(f"‚úÖ Objectif < 1200ms: {'OUI' if log.get('e2e_ms', 0) < 1200 else 'NON'}")
    print(f"üë§ Validation humaine: {'‚úÖ SUCC√àS' if ok else '‚ùå √âCHEC'}")
    
    if ok:
        print("‚úÖ Validation humaine : OK ‚Äì pipeline voix accept√© ‚úî")
        sys.exit(0)
    else:
        print("‚ùå Validation humaine : NOK ‚Äì √† corriger")
        sys.exit(1)


# ---------------------------------------------------------------------------
# Utilitaire d'√©criture log
# ---------------------------------------------------------------------------

def _write_log(payload: dict, error: str | None = None) -> None:
    if error:
        payload["error"] = error
    log_dir = PROJECT_ROOT / "logs"
    log_dir.mkdir(exist_ok=True)
    fname = log_dir / f"voice_pipeline_validation_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
    with open(fname, "w", encoding="utf-8") as fp:
        json.dump(payload, fp, ensure_ascii=False, indent=2)
    print("Log JSON ‚Üí", fname)


# ---------------------------------------------------------------------------
if __name__ == "__main__":
    asyncio.run(main()) 