#!/usr/bin/env python3
"""
Test Microphone OptimisÃ© - SuperWhisper V6 Phase 4
ğŸ¯ VALIDATION: Transcription VAD avec gestion robuste erreurs

Mission: Tester transcription complÃ¨te avec timeout adaptÃ© pour texte long
"""

import os
import sys
import time
import asyncio
import json
import sounddevice as sd
import numpy as np
from pathlib import Path

# =============================================================================
# ğŸš¨ CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation mÃ©moire

print("ğŸ® SuperWhisper V6 Phase 4 STT - Test Microphone OptimisÃ©")
print(f"ğŸ”’ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Ajouter STT au path
sys.path.append(str(Path(__file__).parent.parent))

from STT.backends.prism_stt_backend import PrismSTTBackend

def validate_rtx3090_stt():
    """Validation systÃ©matique RTX 3090 pour STT"""
    import torch
    if not torch.cuda.is_available():
        raise RuntimeError("ğŸš« CUDA non disponible - RTX 3090 requise pour STT")
    
    cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
    if cuda_devices != '1':
        raise RuntimeError(f"ğŸš« CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit Ãªtre '1'")
    
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    if gpu_memory < 20:  # RTX 3090 = ~24GB
        raise RuntimeError(f"ğŸš« GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
    
    print(f"âœ… RTX 3090 validÃ©e pour STT: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")

async def test_microphone_simple():
    """Test microphone avec backend direct pour Ã©viter timeouts"""
    
    print("\n" + "="*60)
    print("ğŸ¤ TEST MICROPHONE SIMPLE - BACKEND DIRECT")
    print("="*60)
    
    # Validation GPU
    validate_rtx3090_stt()
    
    # Configuration Backend direct (plus robuste)
    config = {
        'model': 'large-v2',
        'compute_type': 'float16',
        'language': 'fr',
        'beam_size': 5,
        'vad_filter': True
    }
    
    print(f"ğŸš€ Initialisation Backend Prism direct...")
    backend = PrismSTTBackend(config)
    print(f"âœ… Backend initialisÃ©")
    
    # Configuration audio
    SAMPLE_RATE = 16000
    CHUNK_SIZE = 1024
    
    print(f"\nğŸ“‹ INSTRUCTIONS:")
    print(f"   1. Parlez clairement pendant 10-15 secondes")
    print(f"   2. Testez une phrase complÃ¨te et complexe")
    print(f"   3. CTRL+C pour arrÃªter quand terminÃ©")
    
    input(f"\nğŸ¤ Appuyez sur ENTRÃ‰E pour dÃ©marrer l'enregistrement...")
    
    print(f"\nğŸ”´ ENREGISTREMENT EN COURS")
    print(f"   â¹ï¸ CTRL+C pour arrÃªter")
    
    # Enregistrement avec arrÃªt manuel
    frames = []
    try:
        # Configuration stream
        stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype=np.float32,
            blocksize=CHUNK_SIZE
        )
        
        with stream:
            start_recording = time.time()
            while True:
                # Lire chunk audio
                audio_chunk, overflowed = stream.read(CHUNK_SIZE)
                frames.append(audio_chunk.flatten())
                
                # Affichage temps Ã©coulÃ©
                temps_ecoule = time.time() - start_recording
                print(f"\râ±ï¸ Temps Ã©coulÃ©: {temps_ecoule:.1f}s", end="", flush=True)
                
                # ArrÃªt automatique aprÃ¨s 60s
                if temps_ecoule > 60:
                    print(f"\nâ° ArrÃªt automatique aprÃ¨s 60s")
                    break
                    
    except KeyboardInterrupt:
        duree_enregistrement = time.time() - start_recording
        print(f"\nâœ… Enregistrement arrÃªtÃ© aprÃ¨s {duree_enregistrement:.1f}s")
    
    # Construire audio final
    if not frames:
        print(f"âŒ Aucun audio enregistrÃ©")
        return
    
    audio_complet = np.concatenate(frames)
    duree_audio = len(audio_complet) / SAMPLE_RATE
    niveau_audio = np.max(np.abs(audio_complet))
    
    print(f"\nğŸ“Š AUDIO ENREGISTRÃ‰:")
    print(f"   â±ï¸ DurÃ©e: {duree_audio:.1f}s")
    print(f"   ğŸ“Š Niveau: {niveau_audio:.3f}")
    print(f"   ğŸ“ Ã‰chantillons: {len(audio_complet)}")
    
    if niveau_audio < 0.01:
        print(f"âš ï¸ Niveau audio trÃ¨s faible, vÃ©rifiez votre microphone")
        return
    
    # Transcription STT DIRECTE avec timeout adaptÃ©
    print(f"\nğŸ¤– TRANSCRIPTION STT AVEC VAD CORRIGÃ‰...")
    print(f"   ğŸ”§ Backend direct pour plus de robustesse")
    print(f"   â±ï¸ Timeout adaptÃ©: {duree_audio * 5:.1f}s")
    
    start_transcription = time.time()
    
    try:
        # Utilisation directe du backend pour Ã©viter timeouts UnifiedSTTManager
        result = await backend.transcribe(audio_complet)
        
        duree_transcription = time.time() - start_transcription
        rtf = duree_transcription / duree_audio
        
        print(f"âœ… Transcription terminÃ©e en {duree_transcription:.2f}s")
        
        # Analyser rÃ©sultats
        texte_transcrit = result.text
        nb_mots_transcrit = len(texte_transcrit.split()) if texte_transcrit else 0
        
        print(f"\n" + "="*60)
        print(f"ğŸ“Š RÃ‰SULTATS TRANSCRIPTION VAD CORRIGÃ‰")
        print(f"="*60)
        
        print(f"\nğŸ“ TRANSCRIPTION OBTENUE:")
        print(f"   '{texte_transcrit}'")
        
        print(f"\nğŸ“Š MÃ‰TRIQUES:")
        print(f"   â±ï¸ DurÃ©e transcription: {duree_transcription:.2f}s")
        print(f"   âš¡ RTF: {rtf:.3f}")
        print(f"   ğŸ¯ SuccÃ¨s: {result.success}")
        print(f"   ğŸ’ª Confiance: {result.confidence:.3f}")
        print(f"   ğŸ® Backend: {result.backend_used}")
        print(f"   ğŸ“ Mots transcrits: {nb_mots_transcrit}")
        
        print(f"\nğŸ”§ ANALYSE VAD:")
        print(f"   ğŸ“Š Segments dÃ©tectÃ©s: {len(result.segments)}")
        
        if result.segments:
            print(f"   ğŸ” DÃ©tail segments (premiers 3):")
            for i, segment in enumerate(result.segments[:3]):
                start = segment.get('start', 0)
                end = segment.get('end', 0)
                duree_seg = end - start
                texte_seg = segment.get('text', '')
                print(f"      Seg {i+1}: {start:.1f}s â†’ {end:.1f}s ({duree_seg:.1f}s) - '{texte_seg[:50]}...'")
        
        # Ã‰valuation correction VAD
        print(f"\nğŸ”§ Ã‰VALUATION CORRECTION VAD:")
        
        correction_ok = True
        
        if not texte_transcrit.strip():
            print(f"âŒ Transcription vide")
            correction_ok = False
        else:
            print(f"âœ… Transcription non vide")
        
        if nb_mots_transcrit < 5:
            print(f"âŒ Trop peu de mots: {nb_mots_transcrit}")
            correction_ok = False
        else:
            print(f"âœ… Nombre de mots significatif: {nb_mots_transcrit}")
        
        if len(result.segments) < 2:
            print(f"âš ï¸ Peu de segments VAD: {len(result.segments)}")
        else:
            print(f"âœ… Segments VAD multiples: {len(result.segments)}")
        
        if rtf > 1.5:
            print(f"âš ï¸ RTF Ã©levÃ©: {rtf:.3f}")
        else:
            print(f"âœ… RTF acceptable: {rtf:.3f}")
        
        # RÃ©sultat final
        print(f"\nğŸ¯ RÃ‰SULTAT:")
        if correction_ok:
            print(f"âœ… CORRECTION VAD FONCTIONNE")
            print(f"   Transcription complÃ¨te obtenue")
        else:
            print(f"âš ï¸ PROBLÃˆME DÃ‰TECTÃ‰")
            print(f"   Transcription incomplÃ¨te ou vide")
        
        # Sauvegarde
        resultats = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "duree_audio": duree_audio,
            "niveau_audio": niveau_audio,
            "texte_transcrit": texte_transcrit,
            "nb_mots_transcrit": nb_mots_transcrit,
            "duree_transcription": duree_transcription,
            "rtf": rtf,
            "confiance": result.confidence,
            "backend_used": result.backend_used,
            "nb_segments": len(result.segments),
            "correction_vad_ok": correction_ok
        }
        
        os.makedirs('test_output', exist_ok=True)
        output_file = f"test_output/test_microphone_optimise_{time.strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(resultats, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s: {output_file}")
        
        return correction_ok
        
    except Exception as e:
        print(f"âŒ Erreur transcription: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Point d'entrÃ©e principal"""
    print("ğŸ¤ TEST MICROPHONE OPTIMISÃ‰ - SUPERWHISPER V6 PHASE 4")
    print("Mission: Validation robuste correction VAD")
    
    try:
        success = await test_microphone_simple()
        
        if success:
            print(f"\nğŸŠ TEST RÃ‰USSI - CORRECTION VAD VALIDÃ‰E !")
        else:
            print(f"\nâš ï¸ TEST PARTIEL - Ã€ INVESTIGUER")
            
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ Test interrompu par l'utilisateur")
    except Exception as e:
        print(f"\nâŒ Erreur test: {e}")
    
    print(f"\nâœ… Test microphone optimisÃ© terminÃ©")

if __name__ == "__main__":
    asyncio.run(main()) 