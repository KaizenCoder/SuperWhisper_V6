#!/usr/bin/env python3
"""
Post-Processeur STT Modulaire - SuperWhisper V6
üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
Pipeline: Normalisation ‚Üí Corrections techniques ‚Üí Phon√©tiques ‚Üí Ponctuation

üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# üöÄ PORTABILIT√â AUTOMATIQUE - EX√âCUTABLE DEPUIS N'IMPORTE O√ô
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour ex√©cution portable"""
    # D√©terminer le r√©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le r√©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
    print(f"üìÅ Project Root: {project_root}")
    print(f"üíª Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import re
import json
import logging
import unicodedata
from typing import Dict, Any, List, Tuple, Optional
import time

class STTPostProcessor:
    """Post-processeur modulaire pour optimiser les transcriptions STT"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.logger = self._setup_logging()
        self.config = self._load_default_config()
        
        if config_path:
            self._load_external_config(config_path)
        
        self.stats = {
            "total_processed": 0,
            "total_corrections": 0,
            "corrections_by_type": {
                "technical": 0,
                "phonetic": 0,
                "punctuation": 0,
                "normalization": 0
            }
        }
    
    def _load_default_config(self):
        return {
            "enabled": True,
            "confidence_boost": 0.05,
            
            # Corrections techniques sp√©cifiques √† vos tests
            "technical_corrections": {
                "gpu": "GPU",
                "rtx": "RTX",
                "rtx 3090": "RTX 3090",
                "faster whisper": "faster-whisper",
                "faster whispers": "faster-whisper",
                "after whisper": "faster-whisper",
                "machine learning": "machine learning",
                "intelligence artificielle": "intelligence artificielle",
                "super whispers": "SuperWhisper",
                "super whisper": "SuperWhisper"
            },
            
            # Corrections phon√©tiques fran√ßaises
            "phonetic_corrections": {
                "char √†": "chat,",
                "cr√©sentemps": "chrysanth√®me",
                "cr√©sent√®me": "chrysanth√®me",
                "kakemono": "kak√©mono",
                "identifiant": "int8",
                "in√©dite": "int8",
                "sainte vitesse": "fin du test",
                "sacrement": "cinqui√®mement",
                "dixi√®mement": "sixi√®mement",
                "modificieurs": "mots difficiles",
                "agorique": "algorithme",
                "la tige artificielle": "l'intelligence artificielle",
                "monde monarme": "monde moderne"
            }
        }
    
    def _load_external_config(self, config_path: str):
        """Charge configuration externe depuis fichier JSON"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                external_config = json.load(f)
            
            # Merge avec config par d√©faut
            for key, value in external_config.items():
                if key in self.config and isinstance(self.config[key], dict):
                    self.config[key].update(value)
                else:
                    self.config[key] = value
                    
            self.logger.info(f"‚úÖ Configuration externe charg√©e depuis {config_path}")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Impossible de charger config externe: {e}")
    
    def process(self, text: str, confidence: float = 1.0) -> Tuple[str, Dict[str, Any]]:
        """Traite le texte avec le pipeline complet"""
        if not self.config.get("enabled", True):
            return text, {"corrections_applied": 0}
        
        start_time = time.perf_counter()
        original_text = text
        corrections_count = 0
        
        try:
            self.stats["total_processed"] += 1
            processed_text = text
            
            # 1. Normalisation Unicode
            processed_text, norm_corrections = self._normalize_unicode(processed_text)
            corrections_count += norm_corrections
            self.stats["corrections_by_type"]["normalization"] += norm_corrections
            
            # 2. Corrections techniques
            processed_text, tech_corrections = self._apply_technical_corrections(processed_text)
            corrections_count += tech_corrections
            self.stats["corrections_by_type"]["technical"] += tech_corrections
            
            # 3. Corrections phon√©tiques
            processed_text, phon_corrections = self._apply_phonetic_corrections(processed_text)
            corrections_count += phon_corrections
            self.stats["corrections_by_type"]["phonetic"] += phon_corrections
            
            # 4. Corrections de ponctuation
            processed_text, punct_corrections = self._fix_punctuation(processed_text)
            corrections_count += punct_corrections
            self.stats["corrections_by_type"]["punctuation"] += punct_corrections
            
            # 5. Nettoyage final
            processed_text = self._final_cleanup(processed_text)
            
            # Boost de confiance si corrections appliqu√©es
            confidence_boost = 0.0
            if corrections_count > 0 and confidence < 0.9:
                confidence_boost = min(self.config.get("confidence_boost", 0.05), 0.9 - confidence)
            
            processing_time = time.perf_counter() - start_time
            self.stats["total_corrections"] += corrections_count
            
            metrics = {
                "corrections_applied": corrections_count,
                "confidence_boost": confidence_boost,
                "processing_time_ms": processing_time * 1000,
                "corrections_by_type": {
                    "technical": tech_corrections,
                    "phonetic": phon_corrections,
                    "punctuation": punct_corrections,
                    "normalization": norm_corrections
                }
            }
            
            if corrections_count > 0:
                self.logger.info(f"üìù {corrections_count} corrections appliqu√©es")
            
            return processed_text, metrics
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur post-processing: {e}")
            return original_text, {"corrections_applied": 0, "error": str(e)}
    
    def _normalize_unicode(self, text: str) -> Tuple[str, int]:
        """Normalisation Unicode"""
        try:
            original = text
            normalized = unicodedata.normalize("NFKC", text)
            corrections = 1 if normalized != original else 0
            return normalized, corrections
        except Exception:
            return text, 0
    
    def _apply_technical_corrections(self, text: str) -> Tuple[str, int]:
        """Applique les corrections techniques"""
        corrections_count = 0
        corrected_text = text
        
        technical_dict = self.config.get("technical_corrections", {})
        
        for wrong, correct in technical_dict.items():
            pattern = re.compile(re.escape(wrong), re.IGNORECASE)
            matches = pattern.findall(corrected_text)
            
            if matches:
                corrected_text = pattern.sub(correct, corrected_text)
                corrections_count += len(matches)
                self.logger.debug(f"   Correction technique: '{wrong}' ‚Üí '{correct}' ({len(matches)}x)")
        
        return corrected_text, corrections_count
    
    def _apply_phonetic_corrections(self, text: str) -> Tuple[str, int]:
        """Applique les corrections phon√©tiques fran√ßaises"""
        corrections_count = 0
        corrected_text = text
        
        phonetic_dict = self.config.get("phonetic_corrections", {})
        
        for wrong, correct in phonetic_dict.items():
            if wrong.lower() in corrected_text.lower():
                pattern = re.compile(re.escape(wrong), re.IGNORECASE)
                matches = pattern.findall(corrected_text)
                
                if matches:
                    corrected_text = pattern.sub(correct, corrected_text)
                    corrections_count += len(matches)
                    self.logger.debug(f"   Correction phon√©tique: '{wrong}' ‚Üí '{correct}' ({len(matches)}x)")
        
        return corrected_text, corrections_count
    
    def _fix_punctuation(self, text: str) -> Tuple[str, int]:
        """Corrige la ponctuation fran√ßaise"""
        corrections_count = 0
        corrected_text = text
        
        try:
            # Ajouter points en fin de phrase
            if corrected_text and not corrected_text.rstrip().endswith(('.', '!', '?', ':')):
                corrected_text = corrected_text.rstrip() + '.'
                corrections_count += 1
                self.logger.debug("   Ajout point final")
            
            # Espaces multiples
            before = corrected_text
            corrected_text = re.sub(r'\s+', ' ', corrected_text)
            if corrected_text != before:
                corrections_count += 1
                self.logger.debug("   Correction espaces multiples")
            
            # Majuscules en d√©but de phrase
            before = corrected_text
            corrected_text = re.sub(r'^([a-z])', lambda m: m.group(1).upper(), corrected_text)
            corrected_text = re.sub(r'([.!?]\s+)([a-z])', 
                                  lambda m: m.group(1) + m.group(2).upper(), 
                                  corrected_text)
            if corrected_text != before:
                corrections_count += 1
                self.logger.debug("   Correction majuscules")
            
            # Espaces avant ponctuation fran√ßaise
            before = corrected_text
            corrected_text = re.sub(r'\s+([,;.!?])', r'\1', corrected_text)
            corrected_text = re.sub(r'([^:\s])\s*:\s*', r'\1 : ', corrected_text)
            if corrected_text != before:
                corrections_count += 1
                self.logger.debug("   Correction ponctuation fran√ßaise")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur correction ponctuation: {e}")
        
        return corrected_text, corrections_count
    
    def _final_cleanup(self, text: str) -> str:
        """Nettoyage final du texte"""
        try:
            cleaned = text.strip()
            cleaned = re.sub(r'\n\s*\n', '\n', cleaned)
            cleaned = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', cleaned)
            return cleaned
        except Exception:
            return text
    
    def get_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques du post-processeur"""
        stats = dict(self.stats)
        
        if self.stats["total_processed"] > 0:
            stats["avg_corrections_per_text"] = (
                self.stats["total_corrections"] / self.stats["total_processed"]
            )
            stats["correction_rate"] = (
                (self.stats["total_processed"] - (self.stats["total_processed"] - self.stats["total_corrections"])) 
                / self.stats["total_processed"] * 100
            )
        
        return stats
    
    def reset_statistics(self):
        """Remet √† z√©ro les statistiques"""
        self.stats = {
            "total_processed": 0,
            "total_corrections": 0,
            "corrections_by_type": {
                "technical": 0,
                "phonetic": 0,
                "punctuation": 0,
                "normalization": 0
            }
        }
        self.logger.info("üìä Statistiques r√©initialis√©es")
    
    def _setup_logging(self):
        logger = logging.getLogger('STTPostProcessor')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger

# Test rapide du post-processeur
if __name__ == "__main__":
    # Test avec exemples de vos transcriptions
    processor = STTPostProcessor()
    
    test_texts = [
        "super whispers utilise after whisper sur gpu rtx",
        "char √† la maison cr√©sentemps agorique",
        "sacrement modification dixi√®mement",
        "la tige artificielle dans le monde monarme"
    ]
    
    print("üß™ Test Post-Processeur STT")
    print("=" * 50)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\n{i}. Original: '{text}'")
        processed, metrics = processor.process(text, 0.8)
        print(f"   Trait√©: '{processed}'")
        print(f"   Corrections: {metrics['corrections_applied']}")
        print(f"   Boost confiance: +{metrics['confidence_boost']:.3f}")
    
    print(f"\nüìä Statistiques globales:")
    stats = processor.get_statistics()
    for key, value in stats.items():
        print(f"   {key}: {value}") 