#!/usr/bin/env python3
"""
Validation Humaine Pipeline - TTS EXISTANT INCHANG√â
üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE

UTILISE LE TTS EXISTANT TEL QUEL - AUCUNE MODIFICATION
Pipeline complet : Mic ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Audio

üö® CONFIGURATION GPU: RTX 3090 (CUDA:1) OBLIGATOIRE
"""

import os
import sys
import pathlib

# =============================================================================
# üöÄ PORTABILIT√â AUTOMATIQUE - EX√âCUTABLE DEPUIS N'IMPORTE O√ô
# =============================================================================
def _setup_portable_environment():
    """Configure l'environnement pour ex√©cution portable"""
    # D√©terminer le r√©pertoire racine du projet
    current_file = pathlib.Path(__file__).resolve()
    
    # Chercher le r√©pertoire racine (contient .git ou marqueurs projet)
    project_root = current_file
    for parent in current_file.parents:
        if any((parent / marker).exists() for marker in ['.git', 'pyproject.toml', 'requirements.txt', '.taskmaster']):
            project_root = parent
            break
    
    # Ajouter le projet root au Python path
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    # Changer le working directory vers project root
    os.chdir(project_root)
    
    # Configuration GPU RTX 3090 obligatoire
    os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
    
    print(f"üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
    print(f"üìÅ Project Root: {project_root}")
    print(f"üíª Working Directory: {os.getcwd()}")
    
    return project_root

# Initialiser l'environnement portable
_PROJECT_ROOT = _setup_portable_environment()

# Maintenant imports normaux...

import asyncio
import time
import json
from pathlib import Path

# =============================================================================
# üö® CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT 
# =============================================================================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # RTX 3090 24GB EXCLUSIVEMENT
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ordre stable des GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation m√©moire

print("üéÆ GPU Configuration: RTX 3090 (CUDA:1) forc√©e")
print(f"üîí CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# Imports
sys.path.insert(0, '.')

def validate_rtx3090_configuration():
    """Validation obligatoire de la configuration RTX 3090"""
    try:
        import torch
        if not torch.cuda.is_available():
            raise RuntimeError("üö´ CUDA non disponible - RTX 3090 requise")
        
        cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES', '')
        if cuda_devices != '1':
            raise RuntimeError(f"üö´ CUDA_VISIBLE_DEVICES='{cuda_devices}' incorrect - doit √™tre '1'")
        
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if gpu_memory < 20:  # RTX 3090 = ~24GB
            raise RuntimeError(f"üö´ GPU ({gpu_memory:.1f}GB) trop petite - RTX 3090 requise")
        
        print(f"‚úÖ RTX 3090 valid√©e: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Validation GPU √©chou√©e: {e}")
        return False

async def test_pipeline_complet_existant():
    """Test pipeline complet avec TTS existant inchang√©"""
    print("\nüöÄ VALIDATION HUMAINE PIPELINE COMPLET")
    print("üîß UTILISE TTS EXISTANT TEL QUEL - AUCUNE MODIFICATION")
    print("=" * 60)
    
    # Validation GPU obligatoire
    if not validate_rtx3090_configuration():
        print("üö´ √âCHEC: Configuration GPU RTX 3090 invalide")
        return False
    
    try:
        # Import du pipeline existant
        from PIPELINE.pipeline_orchestrator import PipelineOrchestrator
        
        print("‚úÖ Import PipelineOrchestrator r√©ussi")
        
        # Configuration pipeline existante
        config_path = Path("PIPELINE/config/pipeline.yaml")
        if not config_path.exists():
            print(f"‚ö†Ô∏è Config pipeline non trouv√©e: {config_path}")
            # Utilisation config par d√©faut
            config = {}
        else:
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"‚úÖ Configuration charg√©e: {config_path}")
        
        # Import TTS existant INCHANG√â
        from TTS.tts_manager import UnifiedTTSManager
        
        # Configuration TTS existante
        tts_config_path = Path("config/tts.yaml")
        if tts_config_path.exists():
            with open(tts_config_path, 'r', encoding='utf-8') as f:
                tts_config = yaml.safe_load(f)
        else:
            # Config minimale pour TTS existant
            tts_config = {}
        
        print("üîß Initialisation TTS existant...")
        tts_manager = UnifiedTTSManager(tts_config)
        
        # Initialisation pipeline avec TTS existant
        print("üîß Initialisation PipelineOrchestrator avec TTS existant...")
        pipeline = PipelineOrchestrator(config, tts_manager)
        
        # Test simple TTS via pipeline
        test_text = "Bonjour, test de validation humaine SuperWhisper V6."
        print(f"üìù Texte test: {test_text}")
        
        print("üéµ Test TTS via pipeline...")
        start_time = time.time()
        
        # Utilisation TTS existant via pipeline
        print("üéµ Synth√®se TTS via TTS existant...")
        tts_result = await tts_manager.synthesize(test_text)
        
        end_time = time.time()
        latency_ms = (end_time - start_time) * 1000
        
        # Validation r√©sultat
        if tts_result and tts_result.success and tts_result.audio_data:
            print(f"‚úÖ TTS PIPELINE SUCC√àS!")
            print(f"üéØ Backend utilis√©: {tts_result.backend_used}")
            print(f"‚ö° Latence: {latency_ms:.1f}ms")
            print(f"üîä Audio g√©n√©r√©: {len(tts_result.audio_data):,} bytes")
            
            # Sauvegarde audio pour validation humaine
            output_file = Path("PIPELINE/test_output/validation_humaine_pipeline.wav")
            output_file.parent.mkdir(exist_ok=True)
            
            with open(output_file, 'wb') as f:
                f.write(tts_result.audio_data)
            
            print(f"üíæ Audio sauvegard√©: {output_file}")
            
            # Lecture audio automatique
            try:
                import pygame
                pygame.mixer.init()
                pygame.mixer.music.load(str(output_file))
                pygame.mixer.music.play()
                print("üîä Lecture audio automatique...")
                
                # Attendre fin lecture
                while pygame.mixer.music.get_busy():
                    await asyncio.sleep(0.1)
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Lecture automatique √©chou√©e: {e}")
                print("üîä Veuillez lire manuellement le fichier audio")
            
            # Validation humaine
            print("\n" + "="*60)
            print("üéß VALIDATION HUMAINE PIPELINE COMPLET")
            print("="*60)
            print(f"üìÅ Fichier audio: {output_file}")
            print("üîä Audio lu automatiquement (ou manuellement)")
            print("‚ùì Avez-vous entendu une vraie voix fran√ßaise ?")
            print("‚ùì Le pipeline TTS fonctionne-t-il correctement ?")
            
            response = input("‚úÖ Validation pipeline (o/n): ").strip().lower()
            
            if response in ['o', 'oui', 'y', 'yes']:
                print("üéä VALIDATION HUMAINE PIPELINE R√âUSSIE!")
                
                # M√©triques finales
                metrics = {
                    "validation_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "pipeline_test": "SUCCESS",
                    "backend_used": tts_result.backend_used,
                    "latency_ms": latency_ms,
                    "audio_size_bytes": len(tts_result.audio_data),
                    "gpu_config": "RTX 3090 (CUDA:1)",
                    "human_validation": "SUCCESS",
                    "tts_modified": False,  # TTS non modifi√©
                    "pipeline_integration": True
                }
                
                metrics_file = Path("PIPELINE/reports/validation_humaine_pipeline.json")
                metrics_file.parent.mkdir(exist_ok=True)
                
                with open(metrics_file, 'w', encoding='utf-8') as f:
                    json.dump(metrics, f, indent=2, ensure_ascii=False)
                
                print(f"üìä M√©triques sauvegard√©es: {metrics_file}")
                return True
            else:
                print("‚ùå VALIDATION HUMAINE PIPELINE √âCHOU√âE")
                return False
                
        else:
            print("üö´ √âCHEC TTS PIPELINE: Aucun audio g√©n√©r√©")
            if tts_result:
                print(f"‚ùå Erreur: {tts_result.error}")
            return False
            
    except Exception as e:
        print(f"üí• ERREUR PIPELINE: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Point d'entr√©e principal"""
    print("üéØ VALIDATION HUMAINE PIPELINE COMPLET")
    print("üö® RTX 3090 (CUDA:1) OBLIGATOIRE")
    print("üîß TTS EXISTANT INCHANG√â - AUCUNE MODIFICATION")
    print()
    
    success = await test_pipeline_complet_existant()
    
    if success:
        print("\nüéä SUCC√àS COMPLET - PIPELINE VALID√â!")
        print("‚úÖ TTS existant fonctionne via pipeline")
        print("‚úÖ Validation humaine confirm√©e")
        print("‚úÖ T√¢che 4 peut √™tre marqu√©e termin√©e")
    else:
        print("\n‚ùå √âCHEC - Pipeline non valid√©")
        print("üîß Probl√®me d'int√©gration pipeline/TTS")
    
    return success

if __name__ == "__main__":
    asyncio.run(main()) 